<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Ultra Messaging Concepts</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REL="STYLESHEET"
TYPE="text/css"
HREF="docbook.css"><META
HTTP-EQUIV="Content-Type"
CONTENT="text/html; charset=iso-8859-1"></HEAD
><BODY
CLASS="ARTICLE"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="ARTICLE"
><DIV
CLASS="TITLEPAGE"
><H1
CLASS="TITLE"
><A
NAME="AEN2"
><B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
>&reg;</B
> Concepts</A
></H1
><P
CLASS="COPYRIGHT"
>Copyright &copy; 2004 - 2014 Informatica Corporation</P
><P
CLASS="PUBDATE"
>March 2014<BR></P
><DIV
CLASS="LEGALNOTICE"
><P
></P
><A
NAME="INFACOPYRIGHT"
></A
><P
>Informatica Ultra Messaging</P
><P
>Version 5.3</P
><P
>March 2014</P
><P
>Copyright (c) 1998-2014 Informatica Corporation. All rights reserved.</P
><P
> This software and documentation contain proprietary information of Informatica Corporation 
	and are provided under a license agreement containing restrictions on use and disclosure and are also 
	protected by copyright law. Reverse engineering of the software is prohibited. No part of this document 
	may be reproduced or transmitted in any form, by any means (electronic, photocopying, recording or otherwise) 
	without prior consent of Informatica Corporation. This Software may be protected by U.S. and/or 
	international Patents and other Patents Pending. 
	 </P
><P
> Use, duplication, or disclosure of the Software by the U.S. Government is subject to the 
	 restrictions set forth in the applicable software license agreement and as provided in DFARS 227.7202-1(a) 
	 and 227.7702-3(a) (1995), DFARS 252.227-7013(c)(1)(ii) (OCT 1988), FAR 12.212(a) (1995), FAR 52.227-19, 
	 or FAR 52.227-14 (ALT III), as applicable. 
	 </P
><P
> The information in this product or documentation is subject to change without notice. If you find 
	 any problems in this product or documentation, please report them to us in writing. 
	 </P
><P
> Informatica, Informatica Platform, Informatica Data Services, PowerCenter, PowerCenterRT, 
	 PowerCenter Connect, PowerCenter Data Analyzer, PowerExchange, PowerMart, Metadata Manager, 
	 Informatica Data Quality, Informatica Data Explorer, Informatica B2B Data Transformation, 
	 Informatica B2B Data Exchange Informatica On Demand, Informatica Identity Resolution, 
	 Informatica Application Information Lifecycle Management, Informatica Complex Event Processing, 
	 Ultra Messaging and Informatica Master Data Management are trademarks or registered trademarks of 
	 Informatica Corporation in the United States and in jurisdictions throughout the world. All other company 
	 and product names may be trade names or trademarks of their respective owners. 
	 </P
><P
> Portions of this software and/or documentation are subject to copyright held by third parties, 
	 including without limitation: Copyright DataDirect Technologies. All rights reserved. Copyright (c) Sun Microsystems. All rights reserved. Copyright (c) RSA Security Inc. All Rights Reserved. Copyright (c) Ordinal Technology Corp. All rights reserved.Copyright (c) Aandacht c.v. All rights reserved. Copyright Genivia, Inc. All rights reserved. Copyright Isomorphic Software. All rights reserved. Copyright (c) Meta Integration Technology, Inc. All rights reserved. Copyright (c) Intalio. All rights reserved. Copyright (c) Oracle. All rights reserved. Copyright (c) Adobe Systems Incorporated. All rights reserved. Copyright (c) DataArt, Inc. All rights reserved. Copyright (c) ComponentSource. All rights reserved. Copyright (c) Microsoft Corporation. All rights reserved. Copyright (c) Rogue Wave Software, Inc. All rights reserved. Copyright (c) Teradata Corporation. All rights reserved. Copyright (c) Yahoo! Inc. All rights reserved. Copyright (c) Glyph &amp; Cog, LLC. All rights reserved. Copyright (c) Thinkmap, Inc. All rights reserved. Copyright (c) Clearpace Software Limited. All rights reserved. Copyright (c) Information Builders, Inc. All rights reserved. Copyright (c) OSS Nokalva, Inc. All rights reserved. Copyright Edifecs, Inc. All rights reserved. Copyright Cleo Communications, Inc. All rights reserved. Copyright (c) International Organization for Standardization 1986. All rights reserved. Copyright (c) ej-technologies GmbH. All rights reserved. Copyright (c) Jaspersoft Corporation. All rights reserved. Copyright (c) is International Business Machines Corporation. All rights reserved. Copyright (c) yWorks GmbH. All rights reserved. Copyright (c) Lucent Technologies. All rights reserved. Copyright (c) University of Toronto. All rights reserved. Copyright (c) Daniel Veillard. All rights reserved. Copyright (c) Unicode, Inc. Copyright IBM Corp. All rights reserved. Copyright (c) MicroQuill Software Publishing, Inc. All rights reserved. Copyright (c) PassMark Software Pty Ltd. All rights reserved. Copyright (c) LogiXML, Inc. All rights reserved. Copyright (c) 2003-2010 Lorenzi Davide, All rights reserved. Copyright (c) Red Hat, Inc. All rights reserved. Copyright (c) The Board of Trustees of the Leland Stanford Junior University. All rights reserved. Copyright (c) EMC Corporation. All rights reserved. Copyright (c) Flexera Software. All rights reserved. Copyright (c) Jinfonet Software. All rights reserved. Copyright (c) Apple Inc. All rights reserved. Copyright (c) Telerik Inc. All rights reserved. 
	 </P
><P
> This product includes software developed by the Apache Software Foundation (http://www.apache.org/), 
	 and/or other software which is licensed under various versions of the Apache License (the "License"). 
	 You may obtain a copy of these Licenses at http://www.apache.org/licenses/. Unless required by applicable 
	 law or agreed to in writing, software distributed under these Licenses is distributed on an "AS IS" BASIS, 
	 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the Licenses for the 
	 specific language governing permissions and limitations under the Licenses. 
	 </P
><P
> This product includes software which was developed by Mozilla (http://www.mozilla.org/), software 
	 copyright The JBoss Group, LLC, all rights reserved; software copyright (c) 1999-2006 by Bruno Lowagie and 
	 Paulo Soares and other software which is licensed under various versions of the GNU Lesser General Public 
	 License Agreement, which may be found at http:// www.gnu.org/licenses/lgpl.html. The materials are provided 
	 free of charge by Informatica, "as-is", without warranty of any kind, either express or implied, including but 
	 not limited to the implied warranties of merchantability and fitness for a particular purpose. 
	 </P
><P
> The product includes ACE(TM) and TAO(TM) software copyrighted by Douglas C. Schmidt and his 
	 research group at Washington University, University of California, Irvine, and Vanderbilt University, 
	 Copyright (c) 1993-2006, all rights reserved. 
	 </P
><P
>This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit 
	 (copyright The OpenSSL Project. All Rights Reserved) and redistribution of this software is subject to terms 
	 available at http://www.openssl.org and http://www.openssl.org/source/license.html. 
	 </P
><P
> This product includes Curl software which is Copyright 1996-2007, Daniel Stenberg, 
	 &lt;daniel@haxx.se&gt;. All Rights Reserved. Permissions and limitations regarding this software are subject to 
	 terms available at http://curl.haxx.se/docs/copyright.html. Permission to use, copy, modify, and distribute this 
	 software for any purpose with or without fee is hereby granted, provided that the above copyright notice and 
	 this permission notice appear in all copies. 
	 </P
><P
> The product includes software copyright 2001-2005 (c) MetaStuff, Ltd. All Rights Reserved. Permissions 
	 and limitations regarding this software are subject to terms available at http://www.dom4j.org/ license.html. 
	 </P
><P
> The product includes software copyright (c) 2004-2007, The Dojo Foundation. All Rights Reserved. 
	 Permissions and limitations regarding this software are subject to terms available at http://dojotoolkit.org/license. 
	 </P
><P
> This product includes ICU software which is copyright International Business Machines Corporation and others. 
	 All rights reserved. Permissions and limitations regarding this software are subject to terms available at 
	 http://source.icu-project.org/repos/icu/icu/trunk/license.html. 
	 </P
><P
> This product includes software copyright (c) 1996-2006 Per Bothner. All rights reserved. Your right to use 
	 such materials is set forth in the license which may be found at 
	 http:// www.gnu.org/software/ kawa/Software-License.html. 
	 </P
><P
> This product includes OSSP UUID software which is Copyright (c) 2002 Ralf S. Engelschall, Copyright (c) 2002 
	 The OSSP Project Copyright (c) 2002 Cable &amp; Wireless Deutschland. Permissions and limitations regarding this 
	 software are subject to terms available at http://www.opensource.org/licenses/mit-license.php. 
	 </P
><P
> This product includes software developed by Boost (http://www.boost.org/) or under the Boost software 
	 license. Permissions and limitations regarding this software are subject to terms available at 
	 http:/ /www.boost.org/LICENSE_1_0.txt. 
	 </P
><P
> This product includes software copyright (c) 1997-2007 University of Cambridge. Permissions and limitations 
	 regarding this software are subject to terms available at http:// www.pcre.org/license.txt. 
	 </P
><P
> This product includes software copyright (c) 2007 The Eclipse Foundation. All Rights Reserved. Permissions 
	 and limitations regarding this software are subject to terms available at 
	 http:// www.eclipse.org/org/documents/epl-v10.php. 
	 </P
><P
>This product includes software licensed under the terms at 
	 http://www.tcl.tk/software/tcltk/license.html, 
	 http://www.bosrup.com/web/overlib/?License, 
	 http://www.stlport.org/doc/ license.html, 
	 http:// asm.ow2.org/license.html, 
	 http://www.cryptix.org/LICENSE.TXT, 
	 http://hsqldb.org/web/hsqlLicense.html, 
	 http://httpunit.sourceforge.net/doc/ license.html, 
	 http://jung.sourceforge.net/license.txt , 
	 http://www.gzip.org/zlib/zlib_license.html, 
	 http://www.openldap.org/software/release/license.html, 
	 http://www.libssh2.org, 
	 http://slf4j.org/license.html, 
	 http://www.sente.ch/software/OpenSourceLicense.html, 
	 http://fusesource.com/downloads/license-agreements/fuse-message-broker-v-5-3- license-agreement; 
	 http://antlr.org/license.html; 
	 http://aopalliance.sourceforge.net/; 
	 http://www.bouncycastle.org/licence.html; 
	 http://www.jgraph.com/jgraphdownload.html; 
	 http://www.jcraft.com/jsch/LICENSE.txt; 
	 http://jotm.objectweb.org/bsd_license.html; . 
	 http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231; 
	 http://www.slf4j.org/license.html; 
	 http://nanoxml.sourceforge.net/orig/copyright.html; 
	 http://www.json.org/license.html; 
	 http://forge.ow2.org/projects/javaservice/, 
	 http://www.postgresql.org/about/licence.html, 
	 http://www.sqlite.org/copyright.html, 
	 http://www.tcl.tk/software/tcltk/license.html, 
	 http://www.jaxen.org/faq.html, 
	 http://www.jdom.org/docs/faq.html, 
	 http://www.slf4j.org/license.html; 
	 http://www.iodbc.org/dataspace/iodbc/wiki/iODBC/License; 
	 http://www.keplerproject.org/md5/license.html; 
	 http://www.toedter.com/en/jcalendar/license.html; 
	 http://www.edankert.com/bounce/index.html; 
	 http://www.net-snmp.org/about/license.html; 
	 http://www.openmdx.org/#FAQ; 
	 http://www.php.net/license/3_01.txt; 
	 http://srp.stanford.edu/license.txt; 
	 http://www.schneier.com/blowfish.html; 
	 http://www.jmock.org/license.html; 
	 http://xsom.java.net; and 
	 http://benalman.com/about/license/; 
	 https://github.com/CreateJS/EaselJS/blob/master/src/easeljs/display/Bitmap.js; 
	 http://www.h2database.com/html/license.html#summary; and 
	 http://jsoncpp.sourceforge.net/LICENSE. 
	 </P
><P
> This product includes software licensed under the Academic Free License 
	 http://www.opensource.org/licenses/afl-3.0.php), the Common Development and Distribution License 
	 (http://www.opensource.org/licenses/cddl1.php) the Common Public License 
	 (http://www.opensource.org/licenses/cpl1.0.php), the Sun Binary Code License Agreement Supplemental License 
	 Terms, the BSD License (http:// www.opensource.org/licenses/bsd-license.php) the MIT License 
	 (http://www.opensource.org/licenses/mit-license.php) and the Artistic License 
	 (http://www.opensource.org/licenses/artistic-license-1.0). 
	 </P
><P
>This product includes software copyright (c) 2003-2006 Joe WaInes, 2006-2007 XStream Committers. 
	 All rights reserved. Permissions and limitations regarding this software are subject to terms available at 
	 http://xstream.codehaus.org/license.html. This product includes software developed by the 
	 Indiana University Extreme! Lab. For further information please visit http://www.extreme.indiana.edu/. 
	 </P
><P
> This Software is protected by U.S. Patent Numbers 5,794,246; 6,014,670; 6,016,501; 6,029,178; 6,032,158; 
	 6,035,307; 6,044,374; 6,092,086; 6,208,990; 6,339,775; 6,640,226; 6,789,096; 6,820,077; 6,823,373; 6,850,947; 
	 6,895,471; 7,117,215; 7,162,643; 7,243,110, 7,254,590; 7,281,001; 7,421,458; 7,496,588; 7,523,121; 7,584,422; 
	 7676516; 7,720,842; 7,721,270; and 7,774,791, international Patents and other Patents Pending. 
	 </P
><P
> DISCLAIMER: Informatica Corporation provides this documentation "as is" without warranty of any kind, 
	 either express or implied, including, but not limited to, the implied warranties of noninfringement, merchantability, 
	 or use for a particular purpose. Informatica Corporation does not warrant that this software or documentation is 
	 error free. The information provided in this software or documentation may include technical inaccuracies or 
	 typographical errors. The information in this software and documentation is subject to change at any time 
	 without notice. 
	 </P
><P
>NOTICES</P
><P
> This Informatica product (the "Software") includes certain drivers (the "DataDirect Drivers") from 
	DataDirect Technologies, an operating company of Progress Software Corporation ("DataDirect") which are 
	subject to the following terms and conditions:</P
><P
>1. THE DATADIRECT DRIVERS ARE PROVIDED "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER 
	EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, 
	FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. </P
><P
>2. IN NO EVENT WILL DATADIRECT OR ITS THIRD PARTY SUPPLIERS BE LIABLE TO THE END-USER 
	CUSTOMER FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL OR OTHER DAMAGES ARISING 
	OUT OF THE USE OF THE ODBC DRIVERS, WHETHER OR NOT INFORMED OF THE POSSIBILITIES OF DAMAGES 
	IN ADVANCE. THESE LIMITATIONS APPLY TO ALL CAUSES OF ACTION, INCLUDING, WITHOUT LIMITATION, 
	BREACH OF CONTRACT, BREACH OF WARRANTY, NEGLIGENCE, STRICT LIABILITY, MISREPRESENTATION AND 
	OTHER TORTS. </P
><P
></P
></DIV
><DIV
CLASS="DOCFORAMTNAVI"
>[ <A
href="./index.html"
>Split HTML</A
> / <A
href="design.html"
>Single HTML</A
> / <A
href="design.pdf"
>Single PDF</A
> ]</DIV
><HR></DIV
><DIV
CLASS="TOC"
><DL
><DT
><B
>Table of Contents</B
></DT
><DT
>1. <A
HREF="#INTRODUCTION"
>Introduction</A
></DT
><DT
>2. <A
HREF="#FUNDAMENTAL-CONCEPTS"
>Fundamental Concepts</A
></DT
><DT
>3. <A
HREF="#LBM-OBJECTS"
><B
CLASS="APPLICATION"
>UM</B
> Objects</A
></DT
><DT
>4. <A
HREF="#ARCHITECTURE"
>Architecture</A
></DT
><DT
>5. <A
HREF="#LBM-FEATURES"
>UMS Features</A
></DT
><DT
>6. <A
HREF="#MONITORING"
>Monitoring UMS</A
></DT
><DT
>7. <A
HREF="#LBMRD-MANPAGE"
>Manpage for lbmrd</A
></DT
></DL
></DIV
><BLOCKQUOTE
CLASS="ABSTRACT"
><DIV
CLASS="ABSTRACT"
><P
></P
><A
NAME="AEN42"
></A
><P
>This document introduces important fundamental design concepts behind 
<B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
>&reg;</B
> high performance message streaming. Understanding these concepts is important 
to software developers designing and writing application code that uses the <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> 
Application Programming Interface (API). For information about <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Parallel Persistence</SPAN
>&reg;</B
>
and queuing, 
see <A
HREF="../UME/index.html"
TARGET="_top"
>The Ultra Messaging Guide for Persistence
and Queuing</A
>.</P
><P
></P
></DIV
></BLOCKQUOTE
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="INTRODUCTION"
>1. Introduction</A
></H2
><P
><B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> comprises a software layer, supplied in the form of a dynamic library 
(shared object), plus a daemon that implements persistence 
and queuing  
capabilities. 
These components provide applications with
message delivery functionality that adds considerable
value to the basic networking services contained in the host
operating system. Applications access <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> features through the
<B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> Application Programming Interface (API).</P
><P
>There are actually four APIs: the
<A
HREF="../API/index.html"
TARGET="_top"
>UM C API</A
>, the
<A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>UM Java API</A
>, the
<A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
>UM .NET API</A
>
and the <A
HREF="../JMSAPI/html/index.html"
TARGET="_top"
>JMS API</A
>
. These APIs are very similar, and for the most part this document
concentrates on the C API.
The translation from C functions to Java or .NET methods should be
reasonably straightforward; see the 
<A
HREF="../QuickStart/lbm-programming-quick-start.html"
TARGET="_top"
>UM 
Quick Start Guide</A
> for sample applications in Java and .NET.</P
><P
>The three most important design goals of <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> 
are to minimize message
latency (the time that a given message spends "in transit"), maximize
throughput, and insure delivery of all messages under a wide variety
of operational and failure scenarios.
<B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> achieves these goals by not duplicating services provided 
by the underlying network whenever possible. Instead of implementing special 
messaging servers and daemons to receive and re-transmit messages, 
<B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> routes messages primarily with the network infrastructure at wire speed. 
Placing little or nothing in between the sender and receiver is an important 
and unique design principle of <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
>.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="FUNDAMENTAL-CONCEPTS"
>2. Fundamental Concepts</A
></H2
><P
>A <B
CLASS="APPLICATION"
>UM</B
> application can function either as a
<I
CLASS="FIRSTTERM"
>source</I
> or a <I
CLASS="FIRSTTERM"
>receiver</I
>.
A source application sends messages, and a receiver application receives them.
(It is also common for an application to function as
<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>both</I
></SPAN
> source and receiver; we separate the
concepts for organizational purposes.)</P
><P
>	 This section discusses the following concepts.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#TOPICS"
><I
>Topic Structure and Management</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#PERSISTENCE"
><I
>Persistence</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#QUEUING"
><I
>Queuing</I
></A
> 
		</P
></LI
><LI
><P
>	 <A
HREF="#LATE-JOIN"
><I
>Late Join</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#REQUEST-RESPONSE"
><I
>Request/Response</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TRANSPORTS"
><I
>Transports</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#EVENT-DELIVERY"
><I
>Event Delivery</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#RATE-CONTROLS"
><I
>Rate Controls</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#OPERATIONAL-STATISTICS"
><I
>Operational Statistics</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="TOPICS"
>2.1. Topic Structure and Management</A
></H3
><P
><B
CLASS="APPLICATION"
>UM</B
> offers the <I
CLASS="FIRSTTERM"
>Publish/Subscribe</I
> model
for messaging ("Pub/Sub"), whereby one or more receiver programs
express interest in a <I
CLASS="FIRSTTERM"
>topic</I
>, and one or more
source programs send to that topic.
So, a topic can be thought of as a data stream that can have multiple producers
and multiple consumers.
One of the functions of the messaging layer is to make sure that all messages
sent to a given topic are distributed to all receivers listening to that topic.
<B
CLASS="APPLICATION"
>UM</B
> does this through an automatic process known as <I
CLASS="FIRSTTERM"
>topic
resolution</I
>.</P
><P
>A topic is just an arbitrary string.  For example:</P
><P
></P
><TABLE
BORDER="0"
><TBODY
><TR
><TD
>Deals</TD
></TR
><TR
><TD
>Market/US/DJIA/Sym1</TD
></TR
></TBODY
></TABLE
><P
></P
><P
>It is not unusual for an application system to have many thousands of
topics, perhaps even more than a million, with each one carrying a very
specific range of information (e.g. quotes for a single
stock symbol).</P
><P
>It is also possible to configure receiving programs to match multiple
topics using wildcards.
<B
CLASS="APPLICATION"
>UM</B
> uses powerful regular expression pattern matching to allow
applications to match topics in a very flexible way.
At the present time, messages cannot be <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>sent</I
></SPAN
> to
wildcarded topic names.
See <A
HREF="#WILDCARD-RECEIVER"
><I
>Wildcard Receiver</I
></A
>.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="PERSISTENCE"
>2.2. Persistence</A
></H3
><P
><B
CLASS="APPLICATION"
>UMP</B
> - which contains the <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> <B
CLASS="APPLICATION"
>Streaming Edition</B
> (<B
CLASS="APPLICATION"
>UMS</B
>) functionality - 
includes a component known as the
<I
CLASS="FIRSTTERM"
>persistent store</I
>, which provides stable storage
(disk or memory) of message streams.  <B
CLASS="APPLICATION"
>UMP</B
> delivers a
persisted message stream to receiving applications with no additional latency
in the vast majority of cases.  This offers the functionality of durable
subscriptions and confirmed message delivery. 
<B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> streaming applications 
build and run with the <B
CLASS="APPLICATION"
>UMP</B
> persistence feature without modification. 
See <A
HREF="../UME/index.html"
TARGET="_top"
>The Ultra Messaging Guide for Persistence
and Queuing</A
> for more information.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="QUEUING"
>2.3. Queuing</A
></H3
><P
><B
CLASS="APPLICATION"
>UMQ</B
> - which contains both the <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> <B
CLASS="APPLICATION"
>Streaming Edition</B
> (<B
CLASS="APPLICATION"
>UMS</B
>) functionality 
and the <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> <B
CLASS="APPLICATION"
>Persistence Edition</B
> (<B
CLASS="APPLICATION"
>UMP</B
>) functionality - includes message 
queuing capabilities that allows sources 
to submit messages asynchronously to a queue and permits receivers to retrieve 
messages from a queue in an entirely different asynchronous manner. <B
CLASS="APPLICATION"
>UMQ</B
> 
also supports Once and Only Once (OAOO) delivery and Application Sets 
that allow you to load balance processing or support multiple processing purposes 
for single topics. 
See <A
HREF="../UME/index.html"
TARGET="_top"
>The Ultra Messaging Guide for Persistence
and Queuing</A
> 
for more information.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="LATE-JOIN"
>2.4. Late Join</A
></H3
><P
>In many applications, a new receiver may be interested in messages that were sent before 
it existed. <B
CLASS="APPLICATION"
>UM</B
> provides a late join feature that allows a new receiver to join a group of 
others already listening to a source. Without the late join feature, the joining receiver would 
only receive messages sent after the time it joined. With late join, the source stores sent 
messages according to its Late Join configuration options so a joining receiver can receive 
any of these messages that were sent before it joined the group. 
See <A
HREF="#USING-LATE-JOIN"
><I
>Using Late Join</I
></A
>.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="REQUEST-RESPONSE"
>2.5. Request/Response</A
></H3
><P
><B
CLASS="APPLICATION"
>UM</B
> also offers a <I
CLASS="FIRSTTERM"
>Request/Response</I
> messaging model.
A sending application (the requester) sends a message to a topic. 
Every receiving application listening to that topic gets a copy of 
the request. One or more of those receiving applications (responder) 
can then send one or more responses back to the original requester.  
<B
CLASS="APPLICATION"
>UM</B
> sends the request message via the normal pub/sub method, 
whereas <B
CLASS="APPLICATION"
>UM</B
> delivers the response message directly to the requester.
  </P
><P
>An important aspect of <B
CLASS="APPLICATION"
>UM</B
>'s Request/Response model is that it 
allows the application to keep track of which request corresponds to 
a given response. Due to the asynchronous nature of <B
CLASS="APPLICATION"
>UM</B
> requests, 
any number of requests can be outstanding, and as the responses come in, 
they can be matched to their corresponding requests.
  </P
><P
>Request/Response can be used in many ways and is often used during the 
initialization of <B
CLASS="APPLICATION"
>UM</B
> receiver objects. When an application starts 
a receiver, it can issue a request on the topic the receiver is 
interested in. Source objects for the topic can respond and begin 
publishing data. This method prevents the <B
CLASS="APPLICATION"
>UM</B
> source objects 
from publishing to a topic without subscribers. 
  </P
><P
>Be careful not to be confused with the sending/receiving terminology. 
Any application can send a request, including one that creates and manages 
<B
CLASS="APPLICATION"
>UM</B
> receiver objects. And any application can receive and respond to 
a request, including one that creates and manages <B
CLASS="APPLICATION"
>UM</B
> source objects.
  </P
><P
>See <A
HREF="#REQUEST-RESPONSE-MESSAGES"
><I
>Request/Response Model</I
></A
>.
  </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="TRANSPORTS"
>2.6. Transports</A
></H3
><P
>A source application uses an <I
CLASS="FIRSTTERM"
>UMS transport</I
> to send 
messages to a receiver application.
A <B
CLASS="APPLICATION"
>UM</B
> transport is built on top of a standard IP protocol.
The different <B
CLASS="APPLICATION"
>UM</B
> transport types have different tradeoffs in
terms of
latency, scalability, throughput, bandwidth sharing, and flexibility.
The sending application chooses the transport type that is most
appropriate for the data being sent, at the topic level.
A programmer might choose different transport types for different
topics within the same application.</P
><P
>A <B
CLASS="APPLICATION"
>UM</B
> sending application can make use of very many topics
(over a million).  <B
CLASS="APPLICATION"
>UM</B
> maps those topics onto a much smaller
number of <I
CLASS="FIRSTTERM"
>transport sessions</I
>.  A transport
session can be thought of as a specific instance of a transport type.
A given transport session might carry a single topic, or might carry
hundreds of thousands of topics.  A receiving application may express
interest in a small set of those topics, in which case <B
CLASS="APPLICATION"
>UM</B
> will
join the transport session, receiving messages for <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>all</I
></SPAN
>
topics carried on that transport session.  <B
CLASS="APPLICATION"
>UM</B
> will then discard
any messages for topics that the application is not interested in.
This <I
CLASS="FIRSTTERM"
>user-space filtering</I
> does consume system
resources (primarily CPU and bandwidth), and can be minimized by
carefully mapping topics onto transport sessions according to
receiving application interest.</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>Non-multicast <B
CLASS="APPLICATION"
>UM</B
> transport
types can also use <I
CLASS="FIRSTTERM"
>source-side filtering</I
> to
decrease user-space filtering on the receiving side by doing the
filtering on the sending side.  However, while this might sound
attractive at first glance, be aware that system resources
consumed on the source side affect <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>all</I
></SPAN
>
receivers, and that the filtering for multiple receivers must be
done serially, whereas letting the receivers do the filtering allows
that filtering to be done in parallel, only affecting those receivers
that need the filtering.</P
></BLOCKQUOTE
></DIV
><P
>See <A
HREF="#TRANSPORT-OBJECTS"
><I
>Transport Objects</I
></A
>.
	</P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="MULTITHREADED-TRANSPORTS"
>2.6.1. Multi-Transport Threads</A
></H4
><P
>	 Part of <B
CLASS="APPLICATION"
>UM</B
>'s design is a single threaded model for message data delivery which 
	 reduces latency in the receiving CPU. <B
CLASS="APPLICATION"
>UM</B
>, however, also has the ability to 
	 distribute data delivery across multiple CPUs by using a receiving thread pool. Receivers 
	 created with the configuration option, 
	 <A
HREF="../Config/majoroptions.html#RECEIVERUSETRANSPORTTHREAD"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>use_transport_thread</TT
></A
> set to <B
CLASS="APPLICATION"
>1</B
> use 
	 a thread from the thread pool instead of the context thread. The option, 
	 <A
HREF="../Config/majoroptions.html#CONTEXTRECEIVETHREADPOOLSIZE"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>receive_thread_pool_size</TT
></A
> controls the pool size.
	 </P
><P
>	As receivers discover new sources through Topic Resolution, <B
CLASS="APPLICATION"
>UM</B
> assigns 
	the network sockets created for the receivers to receive data to either the context 
	thread (default) or to a thread from the pool if 
	<A
HREF="../Config/majoroptions.html#RECEIVERUSETRANSPORTTHREAD"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>use_transport_thread</TT
></A
> is set for the receiver. 
	 It is important to understand that thread assignment occurs at the socket level - 
	 not the transport level. Transports aggregated on to the same network socket 
	 use the same thread.
		</P
><P
>	<B
CLASS="APPLICATION"
>UM</B
> distributes data from different sockets to different threads allowing 
	better process distribution and higher aggregate throughput. Distributing transports 
	across threads also ensures that activity on each transport has no impact on transports 
	assigned to other threads leading to lower latencies in some traffic patterns, 
	e.g. heavy loss conditions.
		</P
><P
>	The following lists restrictions to using multi-transport threads. 
		</P
><P
></P
><UL
><LI
><P
>	Only <A
HREF="../Design/lbm-objects.html#TRANSPORT-LBT-RM"
TARGET="_top"
>LBT-RM</A
>, 
	<A
HREF="../Design/lbm-objects.html#TRANSPORT-LBT-RU"
TARGET="_top"
>LBT-RU</A
>, 
	<A
HREF="../Design/lbm-objects.html#TRANSPORT-TCP"
TARGET="_top"
>TCP</A
> and  
	<A
HREF="../Design/lbm-objects.html#TRANSPORT-TCP-LB"
TARGET="_top"
>TCP-LB</A
>
	transport types may be distributed to threads.
		</P
></LI
><LI
><P
>	Multi-Transport threads are not supported under 
	<A
HREF="../Config/majoroptions.html#CONTEXTOPERATIONALMODE"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>sequential mode</TT
></A
>. 
		</P
></LI
><LI
><P
>	<B
CLASS="APPLICATION"
>UM</B
> processes sources using the same transport socket, e.g. multicast address 
	and port, on the same thread (regardless of the 
	<A
HREF="../Config/majoroptions.html#RECEIVERUSETRANSPORTTHREAD"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>use_transport_thread</TT
></A
> setting.  To leverage threading of 
	different sources, assign each source to a different transport destination, e.g. 
	multicast address/port.
		</P
></LI
><LI
><P
>	Hot failover sources using LBT-RM on the same topic must not be distributed across 
	threads because they must share the same multicast address and port.  
		</P
></LI
><LI
><P
>	Hot failover sources using other transport types may not be distributed across 
	threads and must use the context thread.
		</P
></LI
><LI
><P
>	Each transport thread has its own Unicast Listener (request) port. <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> 
	recommends that you expand the range 
	<A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPPORTLOW"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>request_tcp_port_low</TT
></A
> - 
	<A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPPORTHIGH"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>request_tcp_port_high</TT
></A
> to a larger range when using 
	transport threads. When late join is occurring, <B
CLASS="APPLICATION"
>UM</B
> creates a TCP connection 
	from the transport thread to the source.   
		</P
></LI
><LI
><P
>	Multi-transport threads are not recommended for use over the UM Gateway.   
		</P
></LI
><LI
><P
>	Multi-Transport Threads do not support persistent stores (<B
CLASS="APPLICATION"
>UMP</B
>) or persistent receivers 
		</P
></LI
><LI
><P
>	Multi-Transport Threads do not support queues (<B
CLASS="APPLICATION"
>UMQ</B
>) or queing receivers.
		</P
></LI
><LI
><P
>	Multi-Transport Threads are not compatible with UMDS Server or <B
CLASS="APPLICATION"
>UMCache</B
>		</P
></LI
></UL
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="EVENT-DELIVERY"
>2.7. Event Delivery</A
></H3
><P
>There are many different <I
CLASS="FIRSTTERM"
>events</I
> that <B
CLASS="APPLICATION"
>UM</B
>
may want to deliver to the application.  Many events carry data with
them (e.g. received messages); some do not (e.g. end-of-stream events).
Some examples of <B
CLASS="APPLICATION"
>UM</B
> events:</P
><P
></P
><OL
TYPE="1"
><LI
><P
>A received message on a topic that the application has
expressed interest in.</P
></LI
><LI
><P
>A timer expiring.  Applications can schedule timers to expire
in a desired number of milliseconds (although the OS may not deliver them
with millisecond precision).</P
></LI
><LI
><P
>An application-managed file descriptor event.  The application
can register its own file descriptors with <B
CLASS="APPLICATION"
>UM</B
> to be monitored for state
changes (readable, writable, error, etc).</P
></LI
><LI
><P
>New source notification.  <B
CLASS="APPLICATION"
>UM</B
> can inform the application
when sources are discovered by topic resolution.</P
></LI
><LI
><P
>Receiver loss.  <B
CLASS="APPLICATION"
>UM</B
> can inform the application when
a data gap is detected that could not be recovered through the normal
retransmission mechanism.</P
></LI
><LI
><P
>End of Stream.  <B
CLASS="APPLICATION"
>UM</B
> can inform a receiving application
when a data stream (transport session) has terminated.</P
></LI
></OL
><P
><B
CLASS="APPLICATION"
>UM</B
> delivers events to the application by
<I
CLASS="FIRSTTERM"
>callbacks</I
>.  The application explicitly gives
<B
CLASS="APPLICATION"
>UM</B
> a pointer to one of its functions to be the handler for a
particular event, and <B
CLASS="APPLICATION"
>UM</B
> calls that function to deliver the event,
passing it the parameters that the application requires to process the
event.  In particular, the last parameter of each callback type is a
<I
CLASS="FIRSTTERM"
>client data pointer</I
> (<CODE
CLASS="PARAMETER"
>clientdp</CODE
>).
This pointer can be used at the application's discretion for any purpose.
It's value is specified by the application when the callback function is
identified to <B
CLASS="APPLICATION"
>UM</B
> (typically when <B
CLASS="APPLICATION"
>UM</B
> objects are created), and
that same value is passed back to the application when the callback
function is called.</P
><P
>There are two methods that <B
CLASS="APPLICATION"
>UM</B
> can use to call the application
callbacks: through <I
CLASS="FIRSTTERM"
>context thread callback</I
>, or
<I
CLASS="FIRSTTERM"
>event queue dispatch</I
>.</P
><P
>In the context thread callback method (sometimes called <I
CLASS="FIRSTTERM"
>direct
callback</I
>), the <B
CLASS="APPLICATION"
>UM</B
> context thread calls the
application function directly.  This offers the lowest latency, but
imposes significant restrictions on the application function.
See <A
HREF="#EVENT-QUEUE-OBJECT"
><I
>Event Queue Object</I
></A
>. </P
><P
>The event queue dispatch of application callback introduces a dynamic
buffer into which the <B
CLASS="APPLICATION"
>UM</B
> context thread writes events.  The
application then uses a thread of its own to dispatch the buffered
events.  Thus, the application callback functions are called from
the application thread, not directly from the context thread.</P
><P
>With event queue dispatching, the use of the application thread to make the
callback allows the
application function to make full, unrestricted use of the <B
CLASS="APPLICATION"
>UM</B
>
API.  It also allows parallel execution of <B
CLASS="APPLICATION"
>UM</B
> processing and
application processing, which can significantly improve throughput
on multi-processor hardware.
The dynamic buffering provides resilience between the rate of event
generation and the rate of event consumption (e.g. message arrival
rate v.s. message processing rate).</P
><P
>In addition, an <B
CLASS="APPLICATION"
>UM</B
> event queue allows the application to be
warned when the queue exceeds a threshold of event count or event
latency.
This allows the application to take corrective action if it is running
too slow, such as throwing away all events older than a threshold, or
all events that are below a given priority.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="RATE-CONTROLS"
>2.8. Rate Controls</A
></H3
><P
>For UDP-based transports (LBT-RU and LBT-RM), <B
CLASS="APPLICATION"
>UM</B
> network stability
is insured through the use of <I
CLASS="FIRSTTERM"
>rate controls</I
>.
Without rate controls, sources can send UDP data so fast that the network
can be flooded.
Using rate controls, the source's bandwidth usage is limited.
If the source attempts to exceed its bandwidth allocation, it is
slowed down.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="OPERATIONAL-STATISTICS"
>2.9. Operational Statistics</A
></H3
><P
><B
CLASS="APPLICATION"
>UM</B
> maintains a variety of transport-level statistics which
gives a real-time snapshot of <B
CLASS="APPLICATION"
>UM</B
>'s internal handling.  For
example, it gives counts for transport messages transferred, bytes transferred,
retransmissions requested, unrecoverable loss, etc.</P
><P
>The <B
CLASS="APPLICATION"
>UM</B
> <I
CLASS="FIRSTTERM"
>monitoring</I
> API provides
framework to allow the convenient gathering and transmission of
<B
CLASS="APPLICATION"
>UM</B
> statistics to a central monitoring point.  
See <A
HREF="#MONITORING"
><I
>Monitoring UMS</I
></A
>.</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="LBM-OBJECTS"
>3. <B
CLASS="APPLICATION"
>UM</B
> Objects</A
></H2
><P
>Many <B
CLASS="APPLICATION"
>UM</B
> documents use the term <I
CLASS="FIRSTTERM"
>object</I
>.
Be aware that with the C API, they do <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>not</I
></SPAN
> refer
to formal objects as supported by C++ (i.e. class instances).
The term is used here in an informal sense to denote an entity that
can be created, used, and (usually) deleted, has functionality
and data associated with it, and is managed through the API.
The <I
CLASS="FIRSTTERM"
>handle</I
> that is used to refer to an object is
usually implemented as a pointer to a data structure (defined
in <TT
CLASS="FILENAME"
>lbm.h</TT
>), but the internal structure of an object
is said to be <I
CLASS="FIRSTTERM"
>opaque</I
>, meaning that application
code should not read or write the structure directly. </P
><P
>However, the <B
CLASS="APPLICATION"
>UM</B
> Java JNI and C# .NET APIs <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>are</I
></SPAN
>
object oriented, with formal Java/C# objects.
See the <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>Java documentation</A
>
and <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
>.NET documentation</A
>
for more information.</P
><P
>	 This section discusses the following objects.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#CONTEXT-OBJECT"
><I
>Context Object</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TOPIC-OBJECT"
><I
>Topic Object</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#SOURCE-OBJECT"
><I
>Source Object</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#RECEIVER-OBJECT"
><I
>Receiver Object</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#EVENT-QUEUE-OBJECT"
><I
>Event Queue Object</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TRANSPORT-OBJECTS"
><I
>Transport Objects</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="CONTEXT-OBJECT"
>3.1. Context Object</A
></H3
><P
>A <B
CLASS="APPLICATION"
>UM</B
> <I
CLASS="FIRSTTERM"
>context</I
> object conceptually is an
environment in which <B
CLASS="APPLICATION"
>UM</B
> runs.  An application creates a
context, typically during initialization, and uses it for
most other <B
CLASS="APPLICATION"
>UM</B
> operations.  In the process of creating the
context, <B
CLASS="APPLICATION"
>UM</B
> normally starts an independent thread (the <I
CLASS="FIRSTTERM"
>context
thread</I
>) to do the necessary
background processing such as the following.</P
><P
></P
><UL
><LI
><P
>	 Topic resolution
		</P
></LI
><LI
><P
>	 Enforce rate controls for sending messages 
		</P
></LI
><LI
><P
>	 Manage timers
		</P
></LI
><LI
><P
>	 Manage state  
		</P
></LI
><LI
><P
>	 Implement <B
CLASS="APPLICATION"
>UM</B
> protocols
		</P
></LI
><LI
><P
>	 Manage transport sessions
		</P
></LI
></UL
><P
>You create a context with <CODE
CLASS="FUNCTION"
>lbm_context_create()</CODE
>. 
Your application can give a context a name with <CODE
CLASS="FUNCTION"
>lbm_context_set_name()</CODE
>. 
Context names are optional but should be unique. <B
CLASS="APPLICATION"
>UM</B
> does not enforce uniqueness, rather issues a log warning 
if it encounters duplicate context names. Each context maintains a cache of other contexts it learns 
about through context advertisements, which <B
CLASS="APPLICATION"
>UM</B
> sends according to 
<A
HREF="../Config/majoroptions.html#CONTEXTRESOLVERCONTEXTADVERTISEMENTINTERVAL"
TARGET="_top"
><TT
CLASS="LITERAL"
>resolver_context_advertisement_interval</TT
></A
>. 
Context advertisement contains the context's name (if assigned), IP address, request port 
(<A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPPORT"
TARGET="_top"
> 
<TT
CLASS="LITERAL"
>request_tcp_port</TT
></A
>) 
and a Context Instance ID - an internal value assigned by <B
CLASS="APPLICATION"
>UM</B
>. 
If a context needs to know about a context that is not in its cache, it sends a context query, which the 
"unknown" context replies to with a context advertisement. This mechanism for naming and 
advertising <B
CLASS="APPLICATION"
>UM</B
> contexts facilitates UM Gateway operation
 especially for <B
CLASS="APPLICATION"
>UMP</B
>
.</P
><P
>One of the more important functions of a context is to hold
configuration information that is of <I
CLASS="FIRSTTERM"
>context scope</I
>.
See the <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration
Guide</A
> for options that are of context scope.</P
><P
>Most <B
CLASS="APPLICATION"
>UM</B
> applications create a single context.  However,
there are some specialized circumstances where an application would
create multiple contexts.  For example, with appropriate configuration
options, two contexts can provide separate topic name spaces.  Also,
multiple contexts can be used to portion available bandwidth
across topic sub-spaces (in effect allocating more bandwidth to
high-priority topics).</P
><DIV
CLASS="WARNING"
><BLOCKQUOTE
CLASS="WARNING"
><P
><B
>Warning</B
> Regardless of the number of contexts created by your application, a good practice is to keep them open 
 throughout the life of your application. Do not close them until you close the application.</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="TOPIC-OBJECT"
>3.2. Topic Object</A
></H3
><P
>A <B
CLASS="APPLICATION"
>UM</B
> <I
CLASS="FIRSTTERM"
>topic</I
> object is conceptually
very simple; it is little more than a string (the topic name).
However, <B
CLASS="APPLICATION"
>UM</B
> uses the topic object to hold a variety of state
information used by <B
CLASS="APPLICATION"
>UM</B
> for internal processing.
It is conceptually contained within a context.
Topic objects must be bound to source or receiver objects.</P
><P
>A data source creates a topic by calling
<CODE
CLASS="FUNCTION"
>lbm_src_topic_alloc()</CODE
>.
A data receiver doesn't explicitly create topic objects;
<B
CLASS="APPLICATION"
>UM</B
> does that as topics are discovered and cached.
Instead, the receiving application calls
<CODE
CLASS="FUNCTION"
>lbm_rcv_topic_lookup()</CODE
> to find the topic object.</P
><P
>Unlike other objects, the topic object is not created or deleted by the
application.  <B
CLASS="APPLICATION"
>UM</B
> creates, manages and deletes them internally as needed.
However, the application does use them, so the API has functions
that give the application access to them when needed
(<CODE
CLASS="FUNCTION"
>lbm_src_topic_alloc()</CODE
> and
<CODE
CLASS="FUNCTION"
>lbm_rcv_topic_lookup()</CODE
>).</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="SOURCE-OBJECT"
>3.3. Source Object</A
></H3
><P
>A <B
CLASS="APPLICATION"
>UM</B
> <I
CLASS="FIRSTTERM"
>source</I
> object is used to send
messages to the topic that it is bound to.
It is conceptually contained within a context.</P
><P
>You create a source object by calling
<CODE
CLASS="FUNCTION"
>lbm_src_create()</CODE
>.
One of its parameters is a topic object that must have been
previously allocated. A source object can be bound to only one topic. 
(A topic object, however, can be bound to many sources provided the sources exist 
in separate contexts.)</P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="MESSAGEPROPERTIESOBJECT"
>3.3.1. Message Properties Object</A
></H4
><P
>	The message properties object allows your application to insert named, typed metadata in 
	topic messages, and to implement functionality that depends on the message properties. 
	<B
CLASS="APPLICATION"
>UM</B
> allows eight property types: boolean, byte, short, int, long, float, double, and string. 
		</P
><P
>	To use message properties, create a message properties object with 
	<CODE
CLASS="FUNCTION"
>lbm_msg_properties_create()</CODE
>. 
	Then send topic messages with <CODE
CLASS="FUNCTION"
>lbm_src_send_ex()</CODE
> (or 
	<CODE
CLASS="FUNCTION"
>LBMSource.send()</CODE
> in the 
	<A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>Java API</A
> or 
	<A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
>.NET API</A
>) passing the message 
	properties object through <CODE
CLASS="FUNCTION"
>lbm_src_send_ex_info_t</CODE
>
	object. Set the LBM_SRC_SEND_EX_FLAG_PROPERTIES flag  on the 
	<CODE
CLASS="FUNCTION"
>lbm_src_send_ex_info_t</CODE
> object to indicate that it includes properties.
		</P
><P
>	Upon a receipt of a message with properties, your application can access the properties 
	directly through the messages properties field, which is null if no properties are present.
	You can retrieve individual property values directly by name, or you can iterate over
	the collection of properties to determine which properties are present at runtime.
		</P
><P
>	The <B
CLASS="APPLICATION"
>UM</B
> message property object supports the standard JMS message properties specification.
		</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	The Message Properties Object does not support receivers using the arrival order without reassembly 
	setting (option value = 0) of <A
HREF="../Config/majoroptions.html#RECEIVERORDEREDDELIVERY"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>ordered_delivery</TT
></A
>.
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="PROPSPERFORMANCE"
>3.3.1.1. Message Properties Performance Considerations</A
></H5
><P
>	UM sends property names on the wire with every message. To reduce bandwidth requirements, minimize the
	length and number of properties.</P
><P
>When coding sources, consider the following sequence of guidelines:
	</P
><P
></P
><OL
TYPE="1"
><LI
><P
>Allocate a data structure to store message properties objects. This can be a thread-local structure if
	you use a relatively small number of threads, or a thread-safe pool of objects.</P
></LI
><LI
><P
>Before sending, retrieve a message properties object from the pool. If an object is not available,
	create a new object.</P
></LI
><LI
><P
>Set properties for the message.</P
></LI
><LI
><P
>Send the message using the appropriate API call, passing in the properties object.</P
></LI
><LI
><P
>After the send completes, clear the message properties object and return it to the
	pool.</P
></LI
></OL
><P
>	When coding receivers in Java or .NET, call Dispose() on messages before returning from the
	application callback. This allows UM to internally recycle objects, and limits object allocation.
	</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="SOURCE-CONFIG-TRANSPORT-SESSIONS"
>3.3.2. Source Configuration and Transport Sessions</A
></H4
><P
>	As with contexts, a source holds configuration information that is of 
	<I
CLASS="FIRSTTERM"
>source scope</I
>. This includes network options,  
	operational options and reliability options for LBT-RU and LBT-RM.
	For example, each source can use a different transport and would therefore configure 
	a different network address to which to send topic messages.
	See the <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
> 
	for source configuration options. 
		</P
><P
>	As stated in <A
HREF="#TRANSPORTS"
><I
>Transports</I
></A
>, many topics 
	(and therefore sources) can be mapped to a single transport. Many of the configuration 
	options for sources actually control or influence transport session activity. If many 
	sources are sending topic messages over a single transport session (TCP, LBT-RU or 
	LBT-RM), <B
CLASS="APPLICATION"
>UM</B
> only uses the configuration options for the first source assigned 
	to the transport.
		</P
><P
>	For example, if the first source to use a LBT-RM transport session sets the 
	<A
HREF="../Config/transportlbt-rmreliabilityoptions.html#SOURCETRANSPORTLBTRMTRANSMISSIONWINDOWSIZE"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>transport_lbtrm_transmission_window_size</TT
></A
> to 24 MB and the
	second source sets the same option to 2 MB, UMS assigns 24 MB to the transport 
	session's 
	<A
HREF="../Config/transportlbt-rmreliabilityoptions.html#SOURCETRANSPORTLBTRMTRANSMISSIONWINDOWSIZE"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>transport_lbtrm_transmission_window_size</TT
></A
>.
		</P
><P
>	The <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
>
	identifies the source configuration options that may be ignored when <B
CLASS="APPLICATION"
>UM</B
> 
	assigns the source to an existing transport session. Log 
	file warnings also appear when <B
CLASS="APPLICATION"
>UM</B
> ignores source configuration options.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="ZOD-SOURCE"
>3.3.3. Zero Object Delivery (Source)</A
></H4
><P
>  The Zero Object Delivery (ZOD) feature for Java and .NET lets sources deliver events to an application with no 
  per-event object creation. (ZOD can also be utilized with context source events.) See <A
HREF="#ZOD-RECEIVER"
><I
>Zero Object Delivery (ZOD)</I
></A
> for information on how to employ ZOD.
	 </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="RECEIVER-OBJECT"
>3.4. Receiver Object</A
></H3
><P
>A <B
CLASS="APPLICATION"
>UM</B
> <I
CLASS="FIRSTTERM"
>receiver</I
> object is used to
receive messages from the topic that it is bound to.
It is conceptually contained within a context.
Messages are delivered to the application by an application callback
function, specified when the receiver object is created.</P
><P
>You create a receiver object by calling
<CODE
CLASS="FUNCTION"
>lbm_rcv_create()</CODE
>.
One of its parameters is a topic object that must have been
previously looked up. A receiver object can be bound to only one topic. 
Multiple receiver objects can be created for the same topic.
  </P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="RECEIVER-CONFIG-TRANSPORT-SESSIONS"
>3.4.1. Receiver Configuration and Transport Sessions</A
></H4
><P
>  A receiver holds configuration information that is of 
  <I
CLASS="FIRSTTERM"
>receiver scope</I
>. This includes network options,  
  operational options and reliability options for LBT-RU and LBT-RM.
  See the <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
> 
  for receiver configuration options. 
	 </P
><P
>  As stated above in 
  <A
HREF="#SOURCE-CONFIG-TRANSPORT-SESSIONS"
><I
>Source Configuration and Transport Sessions</I
></A
>, 
  many topics 
  (and therefore receivers) can be mapped to a single transport. As with source 
  configuration options, many receiver configuration 
  options control or influence transport session activity. If many 
  receivers are receiving topic messages over a single transport session (TCP, LBT-RU or 
  LBT-RM), <B
CLASS="APPLICATION"
>UM</B
> only uses the configuration options for the first receiver assigned 
  to the transport.
	 </P
><P
>  For example, if the first receiver to use a LBT-RM transport session sets the 
  <A
HREF="../Config/transportlbt-rmreliabilityoptions.html#RECEIVERTRANSPORTLBTRMNAKGENERATIONINTERVAL"
TARGET="_top"
>  <TT
CLASS="LITERAL"
>transport_lbtrm_nak_generation_interval</TT
></A
> to 10 seconds and the
  second receiver sets the same option to 2 seconds, UMS assigns 10 seconds to the transport 
  session's 
  <A
HREF="../Config/transportlbt-rmreliabilityoptions.html#RECEIVERTRANSPORTLBTRMNAKGENERATIONINTERVAL"
TARGET="_top"
>  <TT
CLASS="LITERAL"
>transport_lbtrm_nak_generation_interval</TT
></A
>.
	 </P
><P
>  The <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
>
  identifies the receiver configuration options that may be ignored when <B
CLASS="APPLICATION"
>UM</B
> 
  assigns the receiver to an existing transport session. Log 
  file warnings also appear when <B
CLASS="APPLICATION"
>UM</B
> ignores receiver configuration options.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="WILDCARD-RECEIVER"
>3.4.2. Wildcard Receiver</A
></H4
><P
>  A wildcard receiver object is created by calling
  <CODE
CLASS="FUNCTION"
>lbm_wildcard_rcv_create()</CODE
>.
  Instead of a topic object, the caller supplies a pattern which is used by
  <B
CLASS="APPLICATION"
>UM</B
> to match multiple topics.
  Since the application doesn't explicitly lookup the topics, the topic
  attribute is passed into <CODE
CLASS="FUNCTION"
>lbm_wildcard_rcv_create()</CODE
>
  so that options can be set.
  Also, wildcarding has its own set of options (e.g. pattern type).
  </P
><P
>  The pattern supplied for wildcard matching is normally a general regular
  expression.
  There are two types of supported regular expressions that differ somewhat
  in the syntax of the patterns
  (see the <CODE
CLASS="PARAMETER"
>wildcard_receiver pattern_type</CODE
> option in
  the <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
>).
  Those types are:
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
><CODE
CLASS="PARAMETER"
>PCRE</CODE
> - (recommended) the same form of
  regular expressions recognized by Perl; see
  <A
HREF="http://perldoc.perl.org/perlrequick.html"
TARGET="_top"
>http://perldoc.perl.org/perlrequick.html</A
>
  for details, or</P
></LI
><LI
><P
><CODE
CLASS="PARAMETER"
>regex</CODE
> - POSIX extended regular
  expressions; see
  <A
HREF="http://www.freebsd.org/cgi/man.cgi?query=re_format&#38;section=7"
TARGET="_top"
>http://www.freebsd.org/cgi/man.cgi?query=re_format&amp;section=7</A
>
  for details.  Note that <CODE
CLASS="PARAMETER"
>regex</CODE
> is not supported
  on all platforms.</P
></LI
></OL
><P
>  A third type of wildcarding is <CODE
CLASS="PARAMETER"
>appcb</CODE
>, in
  which the application defines its own algorithm to select topic names.
  When <CODE
CLASS="PARAMETER"
>appcb</CODE
> is configured, the
  <CODE
CLASS="PARAMETER"
>pattern</CODE
> parameter of
  <CODE
CLASS="FUNCTION"
>lbm_wildcard_rcv_create()</CODE
> is ignored.
  Instead, an application callback function is configured
  (see the <CODE
CLASS="PARAMETER"
>wildcard_receiver pattern_callback</CODE
> option in
  the <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
>).
  <B
CLASS="APPLICATION"
>UM</B
> then calls that application function with a topic name and
  the function can use whatever method is appropriate to decide if the
  topic should be included with the receiver.
	 </P
><P
>  Be aware that some platforms may not support all of the
  regular expression wildcard types. 
  For example, <B
CLASS="APPLICATION"
>UM</B
> does not support the use of Unicode PCRE characters in 
  wildcard receiver patterns on any system that communicates with a HP-UX or AIX system. 
  See the 
  <A
HREF="https://communities.informatica.com/infakb/kbexternal/default.aspx"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Knowledgebase</A
> article, 
  <B
CLASS="APPLICATION"
>Platform-Specific Dependencies</B
>
  for details.
  Also note that if <B
CLASS="APPLICATION"
>UM</B
> topic resolution is configured to turn off 
  source advertisements, then wildcard receivers <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>must</I
></SPAN
>
  be configured for <CODE
CLASS="PARAMETER"
>PCRE</CODE
>.
  The other wildcard types do not support receiver queries for topic
  resolution.
	 </P
><P
>  For an example of wildcard usage, see
  <A
HREF="../example/lbmwrcv.c"
TARGET="_top"
>lbmwrcv.c</A
>
	 </P
><P
>  Users of <SPAN
CLASS="TRADEMARK"
>TIBCO</SPAN
>&reg; <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>SmartSockets</SPAN
>&#8482;</B
> will want
  to look at the <A
HREF="https://communities.informatica.com/infakb/kbexternal/default.aspx"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Knowledgebase</A
> article,
  <B
CLASS="APPLICATION"
>Wildcard Topic Regular Expressions</B
>.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="ZOD-RECEIVER"
>3.4.3. Zero Object Delivery (ZOD)</A
></H4
><P
>	 The Zero Object Delivery (ZOD) feature for Java and .NET lets receivers (and sources) deliver messages and
	 events to an application with no per-message or per-event object creation. This facilitates source/receiver
	 applications that would require little to no garbage collection at runtime, producing lower and more consistent
	 message latencies.
  </P
><P
>	 To take advantage of this feature, you must call <CODE
CLASS="FUNCTION"
>dispose()</CODE
> on a message to mark it as
	 available for reuse. To access data from the message when using ZOD, you use a specific pair of
	 LBMMessage-class methods (see below) to extract message data directly from the message, rather than the
	 standard <CODE
CLASS="FUNCTION"
>data()</CODE
> method. Using the latter method creates a byte array, and consequently, an
	 object. It is the subsequent garbage collecting to recycle those objects that can affect performance.
  </P
><P
>	 For using ZOD, the LBMMessage class methods are:
  </P
><P
></P
><UL
><LI
><P
>	Java: <CODE
CLASS="FUNCTION"
>dispose()</CODE
>, <CODE
CLASS="FUNCTION"
>dataBuffer()</CODE
>, and <CODE
CLASS="FUNCTION"
>dataLength()</CODE
>
	</P
></LI
><LI
><P
>	.NET:  <CODE
CLASS="FUNCTION"
>dispose()</CODE
>, <CODE
CLASS="FUNCTION"
>dataPointer()</CODE
>, and <CODE
CLASS="FUNCTION"
>length()</CODE
>
	</P
></LI
></UL
><P
>  	 On the other hand, you may need to keep the message as an object for further use after callback. In this case,
	 ZOD is not appropriate and you must call <CODE
CLASS="FUNCTION"
>promote()</CODE
> on the message, and also you can use
	 <CODE
CLASS="FUNCTION"
>data()</CODE
> to extract
	 message data.
  </P
><P
>	 For more details see the <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>Java API Overview</A
> or the
	 <A
HREF="../DotNetAPI/doc/html/76efb44a-dc57-b7bc-b916-37d41144adc4.htm"
TARGET="_top"
>.Net LBMMessage Class 
	 description</A
>. This feature does not apply to the C API.
  </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="EVENT-QUEUE-OBJECT"
>3.5. Event Queue Object</A
></H3
><P
>  A <B
CLASS="APPLICATION"
>UM</B
> <I
CLASS="FIRSTTERM"
>event queue</I
> object is conceptually
  a managed data and control buffer.
  <B
CLASS="APPLICATION"
>UM</B
> delivers events (including received messages) to your
  application by means of application callback functions.
  Without event queues, these callback functions are called from the
  <B
CLASS="APPLICATION"
>UM</B
> context thread, which places the following restrictions on the application
  function being called:
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 The application function is not allowed to make certain API calls (mostly 
	 having to do with creating or deleting <B
CLASS="APPLICATION"
>UM</B
> objects).
	 </P
></LI
><LI
><P
>	 The application function must execute very quickly <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>without</I
></SPAN
> 
	 blocking.
	 </P
></LI
><LI
><P
>	 The application does not have control over when the callback executes. 
	 It can't prevent callbacks during critical sections of application code.
	 </P
></LI
></OL
><P
>  Some circumstances require the use of <B
CLASS="APPLICATION"
>UM</B
> event queues. As mentioned above, 
  if the receive callback needs to use <B
CLASS="APPLICATION"
>UM</B
> functions that create or delete objects. 
  Or if the receive callback performs operations that potentially block. You may also want to use 
  an event queue if the receive callback is CPU intensive and can make good use of multiple 
  CPU hardware. Not using an event queue provides the lowest latency, however, high message rates 
  or extensive message processing can negate the low latency benefit if the context thread 
  continually blocks.
	 </P
><P
>  Of course, your application can create its own queues, which can be bounded, blocking queues or 
  unbounded, non-blocking queues. For transports that are flow-controlled, a bounded, blocking 
  application queue preserves flow control in your messaging layer because the effect of a filled 
  or blocked queue extends through the message path all the way to source. The speed of the 
  application queue becomes the speed of the source. 
	 </P
><P
>  <B
CLASS="APPLICATION"
>UM</B
> event queues are unbounded, non-blocking queues and provide the following unique features.
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Your application can set a queue size threshold with 
	 <A
HREF="../Config/eventqueueoptions.html#EVENTQUEUEQUEUESIZEWARNING"
TARGET="_top"
>queue_size_warning</A
> 
	 and be warned when the queue contains too many messages.
	 </P
></LI
><LI
><P
>	 Your application can set a delay threshold with 
	 <A
HREF="../Config/eventqueueoptions.html#EVENTQUEUEQUEUEDELAYWARNING"
TARGET="_top"
>queue_delay_warning</A
> 
	 and be warned when events have been in the queue for too long.
	 </P
></LI
><LI
><P
>	 The application callback function has no <B
CLASS="APPLICATION"
>UM</B
> API restrictions.
	 </P
></LI
><LI
><P
>	 Your application can control exactly when <B
CLASS="APPLICATION"
>UM</B
> delivers queued events with
	 <CODE
CLASS="FUNCTION"
>lbm_event_dispatch()</CODE
>. And you can have control return to your
	 application either when specifically asked to do so (by calling
	 <CODE
CLASS="FUNCTION"
>lbm_event_dispatch_unblock()</CODE
>), or optionally when
	 there are no events left to deliver.
	 </P
></LI
><LI
><P
>	 Your application can take advantage of parallel processing on
	 multiple processor hardware since <B
CLASS="APPLICATION"
>UM</B
> processes asynchronously
	 on a separate thread from your application's processing of received messages.
	 By using multiple application threads to dispatch an event queue, or by
	 using multiple event queues, each with its own dispatch thread, your
	 application can further increase parallelism.
	 </P
></LI
></OL
><P
>  You create an <B
CLASS="APPLICATION"
>UM</B
> event queue in 
  the <A
HREF="../API/index.html"
TARGET="_top"
>C API</A
> by calling 
  <CODE
CLASS="FUNCTION"
>lbm_event_queue_create()</CODE
>. 
  In the <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>Java API</A
> and the
  <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
>.NET API</A
>, use the 
  <TT
CLASS="LITERAL"
>LBMEventQueue</TT
> class. 
  An event queue object also holds configuration information that is of 
  <I
CLASS="FIRSTTERM"
>event queue scope</I
>.
  See <A
HREF="../Config/eventqueueoptions.html"
TARGET="_top"
>Event Queue Options</A
>.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="TRANSPORT-OBJECTS"
>3.6. Transport Objects</A
></H3
><P
>	 
	 </P
><P
>	 This section discusses the following topics.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#TRANSPORT-TCP"
><I
>Transport TCP</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TRANSPORT-TCP-LB"
><I
>Transport TCP-LB</I
></A
> 
		</P
></LI
><LI
><P
>	 <A
HREF="#TRANSPORT-LBT-RU"
><I
>Transport LBT-RU</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TRANSPORT-LBT-RM"
><I
>Transport LBT-RM</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TRANSPORT-LBT-IPC"
><I
>Transport LBT-IPC</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TRANSPORT-LBT-RDMA"
><I
>Transport LBT-RDMA</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TRANSPORT-TCP"
>3.6.1. Transport TCP</A
></H4
><P
>The <I
CLASS="FIRSTTERM"
>TCP UMS transport</I
> uses normal TCP
connections to send messages from sources to receivers.
This is the default transport when it's not explicitly set.  TCP is a
good choice when:</P
><P
></P
><OL
TYPE="1"
><LI
><P
>  Flow control is desired.  I.e. when one or more receivers cannot keep up,
  it is desired to slow down the source.  This is a "better late than never"
  philosophy.</P
></LI
><LI
><P
>  Equal bandwidth sharing with other TCP traffic is desired.  I.e. when it is
  desired that the source slow down when general network traffic becomes heavy.</P
></LI
><LI
><P
>  There are few receivers listening to each topic.  Multiple receivers for a
  topic requires multiple transmissions of each message, which places a
  scaling burden on the source machine and the network.</P
></LI
><LI
><P
>  The application is not sensitive to latency.  Use of TCP as a messaging
  transport can result in unbounded latency.</P
></LI
><LI
><P
>  The messages must pass through a restrictive firewall which does not pass
  multicast traffic.</P
></LI
></OL
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	TCP transports may be distributed to receiving threads. See 
	<A
HREF="#MULTITHREADED-TRANSPORTS"
><I
>Multi-Transport Threads</I
></A
> 
	for more information.
		</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TRANSPORT-TCP-LB"
>3.6.2. Transport TCP-LB</A
></H4
><P
>The <I
CLASS="FIRSTTERM"
>TCP-LB UMS transport</I
> is a variation on
the TCP transport which adds latency-bounded behavior.
The source is not flow-controlled as a result of network congestion or
slow receivers.
So, for applications that require a "better never than late"
philosophy, TCP-LB can be a better choice.</P
><P
>However, latency cannot be controlled as tightly as with UDP-based
transports (see below).
In particular, latency can still be introduced because
TCP-LB shares bandwidth equally with other TCP traffic.
It also has the same scaling issues as TCP when multiple receivers are
present for each topic.</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	TCP-LB transports may be distributed to receiving threads. See 
	<A
HREF="#MULTITHREADED-TRANSPORTS"
><I
>Multi-Transport Threads</I
></A
> 
	for more information.
		</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TRANSPORT-LBT-RU"
>3.6.3. Transport LBT-RU</A
></H4
><P
>The <I
CLASS="FIRSTTERM"
>LBT-RU UMS transport</I
> adds reliable
delivery to unicast UDP to send messages from sources to receivers.
This provides greater flexibility in the control of latency.
For example, the application can further limit latency by allowing the use of
<I
CLASS="FIRSTTERM"
>arrival order
delivery</I
>. See the 
<A
HREF="https://communities.informatica.com/infakb/kbexternal/default.aspx"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Knowledgebase</A
> FAQ, 
<SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>Why can't I have low-latency delivery and in-order delivery?</I
></SPAN
>.
Also, LBT-RU is less sensitive to overall network load; it uses source rate
controls to limit its maximum send rate.</P
><P
>Since it is based on unicast addressing, LBT-RU can pass through most
firewalls.
However, it has the same scaling issues as TCP when multiple receivers are
present for each topic.</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 LBT-RU can use Datagram Bypass Layer (DBL) acceleration in conjunction 
	 with DBL-enabled 
	 <A
HREF="http://www.myri.com"
TARGET="_top"
><SPAN
CLASS="TRADEMARK"
>Myricom</SPAN
>&reg;</A
> 
	 10-Gigabit Ethernet NICs for Linux and <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
>&reg; <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>&reg;. DBL is a kernel-bypass technology that 
	 accelerates sending and receiving UDP traffic. See 
	 <A
HREF="../Config/transportaccelerationoptions.html"
TARGET="_top"
>Transport Acceleration Options</A
> 
	 for more information. 
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	LBT-RU transports may be distributed to receiving threads. See 
	<A
HREF="#MULTITHREADED-TRANSPORTS"
><I
>Multi-Transport Threads</I
></A
> 
	for more information.
		</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TRANSPORT-LBT-RM"
>3.6.4. Transport LBT-RM</A
></H4
><P
>The <I
CLASS="FIRSTTERM"
>LBT-RM UMS transport</I
> adds <I
CLASS="FIRSTTERM"
>reliable
multicast</I
> to UDP to send messages.
This provides the maximum flexibility in the control of latency.
In addition, LBT-RM can scale effectively to large numbers of receivers
per topic using network hardware to duplicate messages only when necessary
at wire speed. One limitation is that multicast is often blocked by firewalls.</P
><P
>LBT-RM is a UDP-based, reliable multicast protocol designed with 
the use of <B
CLASS="APPLICATION"
>UM</B
> and its target applications specifically in mind.
The protocol
is very similar to <A
HREF="http://www.ietf.org/rfc/rfc3208.txt"
TARGET="_top"
>PGM</A
>,
but with changes to aid low latency messaging applications. </P
><P
></P
><UL
><LI
><P
>Topic Mapping - Several topics may map onto the same LBT-RM session.
Thus a multiplexing mechanism to LBT-RM is used to distinguish
topic level concerns from LBT-RM session level concerns (such as retransmissions,
etc.). Each message to a topic is given a sequence number in addition
to the sequence number used at the LBT-RM session level for packet retransmission.</P
></LI
><LI
><P
>Negative Acknowledgments (NAKs) - LBT-RM uses NAKs as PGM does.
NAKs are unicast to the sender.  For 
simplicity, LBT-RM uses a similar NAK state management approach as
PGM specifies.</P
></LI
><LI
><P
>Time Bounded Recovery - LBT-RM allows receivers to specify a
a maximum time to wait for a lost piece of data to be retransmitted. This
allows a recovery time bound to be placed on data that has a definite lifetime of
usefulness. If this time limit is exceeded and no retransmission has been seen,
then the piece of data is marked as an unrecoverable loss and the application
is informed. The data stream may continue and the unrecoverable loss will
be ordered as a discrete event in the data stream just as a normal piece of
data.</P
></LI
><LI
><P
>Flexible Delivery Ordering - LBT-RM receivers have the option
to have the data for an individual topic delivered "in order" or "arrival order".
Messages delivered "in order" will arrive in sequence number order to the 
application. Thus loss may delay messages from being delivered until the loss
is recovered or unrecoverable loss is determined. With "arrival-order"
delivery, messages will arrive at the application as they are received by the
LBT-RM session. Duplicates are ignored and lost messages will have the same recovery
methods applied, but the ordering may not be preserved.
Delivery order is a topic level concern. Thus loss of messages in one topic will not
interfere or delay delivery of messages in another topic.</P
></LI
><LI
><P
>Session State Advertisements - In PGM, SPM packets are used to advertise 
session state and to perform PGM router assist in the routers. For LBT-RM, these
advertisements are only used when data is not flowing. Once data stops on a
session, advertisements are sent with an exponential back-off (to a configurable
maximum interval) so that the bandwidth taken up by the session is minimal.</P
></LI
><LI
><P
>Sender Rate Control - LBT-RM can control a sender's rate of injection
of data into the network by use of a rate limiter. This rate is configurable
and will back pressure the sender, not allowing the application to exceed the
rate limit it has specified. In addition, LBT-RM senders have control over
the rate of retransmissions separately from new data. This allows sending application
to guarantee a minimum transmission rate even in the face of massive loss at 
some or all receivers.</P
></LI
><LI
><P
>Low Latency Retransmissions - LBT-RM senders do not mandate the use of
NCF packets as PGM does. Because low latency retransmissions
is such an important feature, LBT-RM senders by default send retransmissions
immediately upon receiving a NAK. After sending a retransmission, the sender 
ignores additional NAKs for the same data and does not repeatedly send NCFs. 
The oldest data being requested in NAKs has priority over newer data so that if
retransmissions are rate controlled, then LBT-RM sends the most important 
retransmissions as fast as possible.</P
></LI
></UL
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 LBT-RM can use Datagram Bypass Layer (DBL) acceleration in conjunction 
	 with DBL-enabled 
	 <A
HREF="http://www.myri.com"
TARGET="_top"
><SPAN
CLASS="TRADEMARK"
>Myricom</SPAN
></A
> 
	 10-Gigabit Ethernet NICs for Linux and <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>. DBL is a kernel-bypass technology that 
	 accelerates sending and receiving UDP traffic. See 
	 <A
HREF="../Config/transportaccelerationoptions.html"
TARGET="_top"
>Transport Acceleration Options</A
> 
	 for more information. 
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	LBT-RM transports may be distributed to receiving threads. See 
	<A
HREF="#MULTITHREADED-TRANSPORTS"
><I
>Multi-Transport Threads</I
></A
> 
	for more information.
		</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TRANSPORT-LBT-IPC"
>3.6.5. Transport LBT-IPC</A
></H4
><P
>  The LBT-IPC transport is an Interprocess Communication (IPC) <B
CLASS="APPLICATION"
>UM</B
> transport that 
  allows sources to publish topic messages to a shared memory area managed as a static 
  ring buffer from which receivers can read topic messages. Message exchange takes place 
  at memory access speed which can greatly improve throughput when sources and receivers 
  can reside on the same host. LBT-IPC can be either source-paced or receiver-paced.
	 </P
><P
>  The LBT-IPC transport uses a "lock free" design that eliminates calls to the Operating 
  System and allows receivers quicker access to messages. An internal validation method 
  enacted by receivers while reading messages from the Shared Memory Area ensures message 
  data integrity. The validation method compares IPC header information at different times 
  to ensure consistent, and therefore, valid message data. Sources can send individual 
  messages or a batch of messages, each of which possesses an IPC header.
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	Transport LBT-IPC is not supported on the <SPAN
CLASS="TRADEMARK"
>HP NonStop</SPAN
>&reg; platform.
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="LBT-IPCSHAREDMEMORYAREA"
>3.6.5.1. LBT-IPC Shared Memory Area</A
></H5
><P
>	 The following diagram illustrates the Shared Memory Area used for LBT-IPC.
	 </P
><DIV
CLASS="FIGURE"
><A
NAME="LBT-IPC-SHARED-MEMORY-LAYOUT"
></A
><P
><B
>Figure 1. LBT-IPC Shared Memory Layout</B
></P
><P
><IMG
SRC="IPC_Shared_Memory_Layout.png"
ALIGN="CENTER"></P
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="LBT-IPC-HEADER"
>3.6.5.1.1. Header</A
></H6
><P
>	 The Header contains information about the shared memory area resource.
		</P
><P
></P
><UL
><LI
><P
>		Shared Lock - shared receiver pool semaphore (mutex on <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>) to ensure mutually 
		exclusive access to the receiver pool.
		</P
></LI
><LI
><P
>		Version - LBT-IPC version number which is independent of any <B
CLASS="APPLICATION"
>UM</B
> product 
		version number.
		</P
></LI
><LI
><P
>		Buffer Length - size of shared memory area.
		</P
></LI
><LI
><P
>		Receiver Map Size - Number of entries available in the Receiver Pool which you 
		configure with the source option, 
		<A
HREF="../Config/transportlbt-ipcoperationoptions.html#SOURCETRANSPORTLBTIPCMAXIMUMRECEIVERSPERTRANSPORT"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>transport_lbtipc_maximum_receivers_per_transport</TT
></A
>.
		</P
></LI
><LI
><P
>		New Client Flag - set by the receiver after setting its Receiver Pool entry and before 
		releasing the Shared Lock. Indicates to the source that a new receiver has joined the 
		transport.
		</P
></LI
><LI
><P
>		Receiver Paced - Indicates if you've configured the transport for receiver-pacing.
		</P
></LI
><LI
><P
>		Old Message Start - pointer indicating messages that may be reclaimed.
		</P
></LI
><LI
><P
>		New Message Start - pointer indicating messages that may be read.  
		</P
></LI
><LI
><P
>		New Message End - pointer indicating the end of messages that may be read, which 
		may not be the same as the Old Message Start pointer.
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="LBT-IPC-RECEIVER-POOL"
>3.6.5.1.2. Receiver Pool</A
></H6
><P
>	 The receiver pool is a collection of receiver connections maintained in the 
	 Shared Memory Area. The source reads this information if you've configured 
	 receiver-pacing to determine if a message can be reclaimed or to monitor 
	 a receiver. Each receiver is responsible for finding a free entry in the 
	 pool and marking it as used.
		</P
><P
></P
><UL
><LI
><P
>		In Use flag - set by receiver while holding the Shared Lock, 
		which effectively indicates the receiver has joined the transport session. Using 
		the Shared Lock ensures mutually exclusive access to the receiver connection pool.
		</P
></LI
><LI
><P
>		Oldest Message Start - set by receiver after reading a message. If you enable 
		receiver-pacing the source reads it to determine if message memory can be reclaimed.
		</P
></LI
><LI
><P
>		Monitor Shared Lock - checked by the source to monitor a receiver. 
		(semaphore on Linux, event on <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>)
		See <A
HREF="#RECEIVER-HEALTH"
><I
>Receiver Monitoring</I
></A
>.
		</P
></LI
><LI
><P
>		Signal Shared Lock - Set by source to notify receiver that new data 
		has been written. (semaphore on Linux, mutex on <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>) If you set 
		<A
HREF="../Config/transportlbt-ipcoperationoptions.html#CONTEXTTRANSPORTLBTIPCRECEIVERTHREADBEHAVIOR"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>transport_lbtipc_receiver_thread_behavior</TT
></A
> to 
		<TT
CLASS="LITERAL"
>busy_wait</TT
>, the receiver sets this semaphore to zero and the 
		source does not notify.
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="LBT-IPC-MESSAGE-BUFFER"
>3.6.5.1.3. Source-to-Receiver Message Buffer</A
></H6
><P
>	 This area contains message data. You specify the size of the shared 
	 memory area with a source option, 
	 <A
HREF="../Config/transportlbt-ipcoperationoptions.html#SOURCETRANSPORTLBTIPCTRANSMISSIONWINDOWSIZE"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtipc_transmission_window_size</TT
></A
>. 
	 The size of the shared memory area cannot exceed your platform's shared memory 
	 area maximum size. <B
CLASS="APPLICATION"
>UM</B
> stores the memory size 
	 in the shared memory area's header. The Old Message Start and New Message Start point 
	 to positions in this buffer.
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SOURCES-LBT-IPC"
>3.6.5.2. Sources and LBT-IPC</A
></H5
><P
>	 When you create a source with <TT
CLASS="LITERAL"
>lbm_src_create()</TT
> and you've 
	 set the transport option to IPC, <B
CLASS="APPLICATION"
>UM</B
> creates a shared memory area object. 
	 <B
CLASS="APPLICATION"
>UM</B
> assigns one of the transport IDs to this area specified with the 
	 <B
CLASS="APPLICATION"
>UM</B
> context configuration options, 
	 <A
HREF="../Config/transportlbt-ipcoperationoptions.html#CONTEXTTRANSPORTLBTIPCIDHIGH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtipc_id_high</TT
></A
> and 
	 <A
HREF="../Config/transportlbt-ipcoperationoptions.html#CONTEXTTRANSPORTLBTIPCIDLOW"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtipc_id_low</TT
></A
>. 
	 You can also specify a shared memory location outside of this range with a 
	 source configuration option, 
	 <A
HREF="../Config/transportlbt-ipcoperationoptions.html#SOURCETRANSPORTLBTIPCID"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtipc_id</TT
></A
>, 
	 to prioritize certain topics, if needed.
	 </P
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> names the shared memory area object according to the format, 
	 <TT
CLASS="LITERAL"
>LBTIPC_%x_%d</TT
> where <TT
CLASS="LITERAL"
>%x</TT
> is the hexadecimal 
	 Session ID and <TT
CLASS="LITERAL"
>%d</TT
> is the decimal Transport ID. Examples names are 
	 <TT
CLASS="LITERAL"
>LBTIPC_42792ac_20000 or LBTIPC_66e7c8f6_20001</TT
>. Receivers 
	 access a shared memory area with this object name to receive (read) topic messages.
	 </P
><P
>	 Using the configuration option, 
	 <A
HREF="../Config/transportlbt-ipcoperationoptions.html#RECEIVERTRANSPORTLBTIPCBEHAVIOR"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtipc_behavior</TT
></A
>, you can choose 
	 <TT
CLASS="LITERAL"
>source-paced</TT
> or <TT
CLASS="LITERAL"
>receiver-paced</TT
> message transport. 
	 See <A
HREF="../Config/transportlbt-ipcoperationoptions.html"
TARGET="_top"
>	 Transport LBT-IPC Operation Options</A
>.
	 </P
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="SENDING-LBT-IPC"
>3.6.5.2.1. Sending over LBT-IPC</A
></H6
><P
>	 To send on a topic (write to the shared memory area) the source writes to the 
	 Shared Memory Area starting at the Oldest Message Start position. It then increments 
	 each receiver's Signal Lock if the receiver has not set this to zero. 
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RECEIVERS-LBT-IPC"
>3.6.5.3. Receivers and LBT-IPC</A
></H5
><P
>	 Receivers operate identically 
	 to receivers for all other <B
CLASS="APPLICATION"
>UM</B
> transports. A receiver can actually receive 
	 topic messages from a source sending on its topic over TCP, LBT-RU or LBT-RM 
	 and from a second source sending on LBT-IPC with out any special configuration. 
	 The receiver learns what it needs to join the LBT-IPC session through the topic 
	 advertisement.
	 </P
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="TOPIC-RESOLUTION-LBT-IPC"
>3.6.5.3.1. Topic Resolution and LBT-IPC</A
></H6
><P
>	 Topic resolution operates identically with LBT-IPC as other <B
CLASS="APPLICATION"
>UM</B
> transports 
	 albeit with a new advertisement type, <TT
CLASS="LITERAL"
>LBMIPC</TT
>. Advertisements 
	 for LBT-IPC contain the Transport ID, Session ID and Host ID. Receivers obtain 
	 LBT-IPC advertisements in the normal manner (resolver cache, advertisements 
	 received on the multicast resolver address:port and responses to queries.) 
	 Advertisements for topics from LBT-IPC sources can reach receivers on 
	 different machines if they use the same topic resolution configuration, 
	 however, those receivers silently ignore those advertisements since they 
	 cannot join the IPC transport. 
	 See <A
HREF="#SENDING-BOTH-RECEIVERS"
><I
>Sending to Both Local and Remote Receivers</I
></A
>. 
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="RECEIVER-PACING"
>3.6.5.3.2. Receiver Pacing</A
></H6
><P
>	 Although receiver pacing is a source behavior option, some different things must 
	 happen on the receiving side to ensure that a source does not reclaim (overwrite) 
	 a message until all receivers have read it. When you use the default 
	 <A
HREF="../Config/transportlbt-ipcoperationoptions.html#RECEIVERTRANSPORTLBTIPCBEHAVIOR"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtipc_behavior</TT
></A
> (<TT
CLASS="LITERAL"
>source-paced</TT
>), 
	 each receiver's Oldest Message Start position in the Shared Memory Area is private to 
	 each receiver. The source writes to the Shared Memory Area independently of receivers' 
	 reading. For receiver-pacing, however, all receivers share their Oldest Message Start 
	 position with the source. The source will not reclaim a message until all receivers 
	 have successfully read that message.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="RECEIVER-HEALTH"
>3.6.5.3.3. Receiver Monitoring</A
></H6
><P
>	 To ensure that a source does not wait on a receiver that is not running, the source 
	 monitors a receiver via the Monitor Shared Lock allocated to each receiving context. 
	 (This lock is in addition to the semaphore already allocated for signaling new 
	 data.) A new receiver takes and holds the Monitor Shared Lock and releases the resource 
	 when it dies. If the source is able to obtain the resource, it knows the receiver has 
	 died. The source then clears the receiver's In Use flag in it's Receiver Pool Connection.
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SIMILARITIES-LBM-TRANSPORTS"
>3.6.5.4. Similarities with Other UM Transports</A
></H5
><P
>	 Although no actual network transport occurs, <B
CLASS="APPLICATION"
>UM</B
> functions in much the 
	 same way as if you send packets across the network as with other <B
CLASS="APPLICATION"
>UM</B
> 
	 transports. 
	 </P
><P
></P
><UL
><LI
><P
>	 If you use a range of LBT-IPC transport IDs, <B
CLASS="APPLICATION"
>UM</B
> assigns multiple topics sent by 
	 multiple sources to all the transport sessions in a round robin manner just like other 
	 <B
CLASS="APPLICATION"
>UM</B
> transports.
		</P
></LI
><LI
><P
>	 Transport sessions assume the configuration option values of the first source 
	 assigned to the transport session.  
		</P
></LI
><LI
><P
>	 Sources are subject to message batching.  
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="DIFFERENCES-LBM-TRANSPORTS"
>3.6.5.5. Differences from Other UM Transports</A
></H5
><P
></P
><UL
><LI
><P
>	 Unlike LBT-RM which uses a transmission window to specify a buffer size to retain 
	 messages in case they must be retransmitted, LBT-IPC uses the transmission window 
	 option to establish the size of the shared memory.
		</P
></LI
><LI
><P
>	 LBT-IPC does not retransmit messages. Since LBT-IPC transport is essentially 
	 a memory write/read operation, messages should not be be lost in transit. However, 
	 if the shared memory area fills up, new messages overwrite old messages and 
	 the loss is absolute. No retransmission of old messages that have been overwritten occurs.  
		</P
></LI
><LI
><P
>	 Receivers also do not send NAKs when using LBT-IPC.  
		</P
></LI
><LI
><P
>	 LBT-IPC does not support Ordered Delivery options. However, if you set 
	 <A
HREF="../Config/majoroptions.html#RECEIVERORDEREDDELIVERY"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>ordered_delivery</TT
></A
> <TT
CLASS="LITERAL"
><B
CLASS="APPLICATION"
>1</B
></TT
> 
	 or <TT
CLASS="LITERAL"
><B
CLASS="APPLICATION"
>-1</B
></TT
>, LBT-IPC reassembles any large messages.
		</P
></LI
><LI
><P
>	 LBT-IPC does not support Rate Control. 
		</P
></LI
><LI
><P
>	 LBT-IPC creates a separate receiver thread in the receiving context. 
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SENDING-BOTH-RECEIVERS"
>3.6.5.6. Sending to Both Local and Remote Receivers</A
></H5
><P
>	 A source application that wants to support both local and remote receivers 
	 should create two <B
CLASS="APPLICATION"
>UM</B
> Contexts with different topic resolution configurations, 
	 one for IPC sends and one for sends to remote receivers. Separate contexts 
	 allows you to use the same topic for both IPC and network sources. If you 
	 simply created two source objects (one IPC, one say LBT-RM) in the same 
	 <B
CLASS="APPLICATION"
>UM</B
> Context, you would have to use separate topics and suffer possible 
	 higher latency because the sending thread would be blocked for the duration 
	 of two send calls. 
	 </P
><P
>	 A <B
CLASS="APPLICATION"
>UM</B
> source will never automatically use IPC when the receivers are 
	 local and a network transport for remote receivers because the discovery of 
	 a remote receiver would hurt the performance of local receivers. An 
	 application that wants transparent switching can implement it in a simple wrapper. 
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="LBT-IPC-OBJECT-DIAGRAM"
>3.6.5.7. LBT-IPC Object Diagram</A
></H5
><P
>	 The following diagram illustrates how sources and receivers interact with 
	 the shared memory area used in the LBT-IPC transport.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="IPC-OBJECTS"
></A
><P
><B
>Figure 2. Sending and Receiving with LBT-IPC</B
></P
><P
><IMG
SRC="IPC_Objects.png"
ALIGN="CENTER"></P
></DIV
><P
>	 In the diagram above, 3 sources send (write) to two Shared Memory Areas while 
	 four receivers in two different contexts receive (read) from the areas. The 
	 diagram also shows the <B
CLASS="APPLICATION"
>UM</B
> configuration options that set up this scenario. 
	 The assignment of sources to Shared Memory Areas demonstrate <B
CLASS="APPLICATION"
>UM</B
>'s round 
	 robin method. <B
CLASS="APPLICATION"
>UM</B
> assigns the source sending on Topic A to Transport 
	 20001, the source sending on Topic B to Transport 20002 and the source 
	 sending on Topic C back to the top of the transport ID range, 20001. The 
	 memory area size, although the default value, appears for illustration.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="IPC-REQUIRED-AUTHORITIES"
>3.6.5.8. Required Authorities</A
></H5
><P
>	 LBT-IPC requires no special operating system authorities, except on <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows Vista</SPAN
>&reg; and 
	 <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
> Server 2008, which require Administrator privileges. In addition, on 
	 <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
> XP, applications must be started by the same user, however, the 
	 user is not required to have administrator privileges. In order for 
	 applications to communicate with a service, the service must use a user 
	 account that has Administrator privileges.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="IPC-RESOURCE-USAGE-LIMITS"
>3.6.5.9. Host Resource Usage and Limits</A
></H5
><P
>	 LBT-IPC contexts and sources consume host resources as follows.
	 </P
><P
></P
><UL
><LI
><P
>	 Per Source - 1 shared memory segment, 1 shared lock (semaphore on Linux, mutex on <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>)
		</P
></LI
><LI
><P
>	 Per Receiving Context - 2 shared locks (semaphores on Linux, one event and one mutex on <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>)
		</P
></LI
></UL
><P
>	 Across most operating system platforms, these resources have the following limits.
	 </P
><P
></P
><UL
><LI
><P
>	 4096 shared memory segments, though some platforms use different limits
		</P
></LI
><LI
><P
>	 32,000 shared semaphores (128 shared semaphore sets * 250 semaphores per set)  
		</P
></LI
></UL
><P
>	 Consult your operating system documentation for specific limits per type of resource. 
	 Resources may be displayed and reclaimed using the 
	 <A
HREF="#LBT-IPC-RESOURCE-MANAGER"
><I
>LBT-IPC Resource Manager</I
></A
>. 
	 See also <A
HREF="https://communities.informatica.com/infakb/faq/5/Pages/80201.aspx"
TARGET="_top"
>	 Managing LBT-IPC Host Resources</A
>.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="LBT-IPC-RESOURCE-MANAGER"
>3.6.5.10. LBT-IPC Resource Manager</A
></H5
><P
>	 Deleting an IPC source with <TT
CLASS="LITERAL"
>lbm_src_delete()</TT
> or deleting 
	 an IPC receiver with <TT
CLASS="LITERAL"
>lbm_rcv_delete()</TT
> reclaims 
	 the shared memory area and locks allocated by the IPC source or receiver. However, 
	 if a less than graceful exit from a process occurs, global resources remain 
	 allocated but unused. To address this possibility, the LBT-IPC Resource 
	 Manager maintains a resource allocation database with a record for each 
	 global resource (memory or semaphore) allocated or freed. You can use the 
	 LBT-IPC Resource Manager to discover and reclaim resources. See the three 
	 example outputs below. 
	 </P
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="DISPLAYING-RESOURCES"
>3.6.5.10.1. Displaying Resources</A
></H6
><PRE
CLASS="PROGRAMLISTING"
>$&#62; lbtipc_resource_manager 
Displaying Resources (to reclaim you must type '-reclaim' exactly)

--Memory Resources--
 Memory resource: Process ID: 24441 SessionID: ab569cec XportID: 20001

--Semaphore Resources--
 Semaphore key: 0x68871d75
	Semaphore resource Index 0: reserved
	Semaphore resource: Process ID: 24441 Sem Index: 1
	Semaphore resource: Process ID: 24436 Sem Index: 2 </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="RECLAIMING-RESOURCES"
>3.6.5.10.2. Reclaiming Unused Resources</A
></H6
><PRE
CLASS="PROGRAMLISTING"
>$&#62; lbtipc_resource_manager -reclaim

Reclaiming Resources
 Process 24441 not found: reclaiming Memory resource (SessionID: ab569cec XPortID: 20001)
 Process 24441 not found: reclaiming Semaphore resource: Key: 0x68871d75 Sem Index: 1
 Process 24436 not found: reclaiming Semaphore resource: Key: 0x68871d75 Sem Index: 2 </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="DISCOVERING-RESOURCES"
>3.6.5.10.3. Discovering Resources In Use</A
></H6
><PRE
CLASS="PROGRAMLISTING"
>$&#62; lbtipc_resource_manager -reclaim

Reclaiming Resources
 Process 24441 still active! Memory resource not reclaimed (SessionID: ab569cec XPortID: 20001)
 Process 24441 still active! Semaphore resource not reclaimed (Key: 0x68871d75 Sem Index: 1)
 Process 24436 still active! Semaphore resource not reclaimed (Key: 0x68871d75 Sem Index: 2)</PRE
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TRANSPORT-LBT-RDMA"
>3.6.6. Transport LBT-RDMA</A
></H4
><P
>	 The LBT-RDMA transport is Remote Direct Memory Access (RDMA) <B
CLASS="APPLICATION"
>UM</B
> transport that 
	 allows sources to publish topic messages to a shared memory area from which receivers 
	 can read topic messages. LBT-RDMA runs across InfiniBand and 10 Gigabit Ethernet 
	 hardware.
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	Use of the LBT-RDMA transport requires the purchase and installation of the <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> 
	<B
CLASS="APPLICATION"
>RDMA Transport Module</B
>. See your <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> representative for licensing specifics.
		  </P
></BLOCKQUOTE
></DIV
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	Transport LBT-RDMA is not supported on the <SPAN
CLASS="TRADEMARK"
>HP NonStop</SPAN
> platform.
		</P
></BLOCKQUOTE
></DIV
><P
>	 When you create a source with <TT
CLASS="LITERAL"
>lbm_src_create()</TT
> and you've 
	 set the transport option to RDMA, <B
CLASS="APPLICATION"
>UM</B
> creates a shared memory area object on 
	 the sending machine's Host Channel Adapter (HCA) card. 
	 <B
CLASS="APPLICATION"
>UM</B
> assigns one of the RDMA transport ports to this area specified with the 
	 <B
CLASS="APPLICATION"
>UM</B
> context configuration options, 
	 <A
HREF="../Config/transportlbt-rdmaoperationoptions.html#CONTEXTTRANSPORTLBTRDMAPORTHIGH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtrdma_port_high</TT
></A
> and 
	 <A
HREF="../Config/transportlbt-rdmaoperationoptions.html#CONTEXTTRANSPORTLBTRDMAPORTLOW"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtrdma_port_low</TT
></A
>. 
	 You can also specify a shared memory location outside of this range with a 
	 source configuration option, 
	 <A
HREF="../Config/transportlbt-rdmaoperationoptions.html#CONTEXTTRANSPORTLBTRDMAPORT"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtrdma_port</TT
></A
>, 
	 to prioritize certain topics, if needed.
	 </P
><P
>	 When you create a receiver with <TT
CLASS="LITERAL"
>lbm_rcv_create()</TT
> for a topic being sent 
	 over LBT-RDMA, <B
CLASS="APPLICATION"
>UM</B
> creates a shared memory area on the receiving machine's HCA card. 
	 The network hardware immediately copies any new data from the sending HCA to the 
	 receiving HCA. <B
CLASS="APPLICATION"
>UM</B
> receivers monitor the receiving shared memory area for new topic 
	 messages. You configure receiver monitoring with  
	 <A
HREF="../Config/transportlbt-rdmaoperationoptions.html#CONTEXTTRANSPORTLBTRDMARECEIVERTHREADBEHAVIOR"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>transport_lbtrdma_receiver_thread_behavior</TT
></A
>.
	 </P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="LBT-RDMA-OBJECT-DIAGRAM"
>3.6.6.1. LBT-RDMA Object Diagram</A
></H5
><P
>	 The following diagram illustrates how sources and receivers interact with 
	 the shared memory area used in the LBT-RDMA transport.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="RDMA-OBJECTS"
></A
><P
><B
>Figure 3. Sending and Receiving with LBT-RDMA</B
></P
><P
><IMG
SRC="RDMA_Objects.png"
ALIGN="CENTER"></P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RDMA-SIMILARITIES-LBM-TRANSPORTS"
>3.6.6.2. Similarities with Other UMS Transports</A
></H5
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> functions in much the same way as if you send packets across a traditional 
	 Ethernet network as with other <B
CLASS="APPLICATION"
>UM</B
> transports. 
	 </P
><P
></P
><UL
><LI
><P
>	 If you use a range of ports, <B
CLASS="APPLICATION"
>UM</B
> assigns multiple topics 
	 that have been sent by multiple sources in a round robin manner to all the transport sessions 
	 configured my the port range.
		</P
></LI
><LI
><P
>	 Transport sessions assume the configuration option values of the first source 
	 assigned to the transport session.  
		</P
></LI
><LI
><P
>	 Sources are subject to message batching.  
		</P
></LI
><LI
><P
>	 Topic resolution operates identically with LBT-RDMA as other <B
CLASS="APPLICATION"
>UM</B
> transports 
	 albeit with a new advertisement type, <TT
CLASS="LITERAL"
>LBMRDMA</TT
>.  
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RDMA-DIFFERENCES-LBM-TRANSPORTS"
>3.6.6.3. Differences from Other UMS Transports</A
></H5
><P
></P
><UL
><LI
><P
>	 Unlike LBT-RM which uses a transmission window to specify a buffer size to retain 
	 messages in case they must be retransmitted, LBT-RDMA uses the transmission window 
	 option to establish the size of the shared memory.
		</P
></LI
><LI
><P
>	 LBT-RDMA does not retransmit messages. Since LBT-RDMA transport is essentially 
	 a memory write/read operation, messages should not be be lost in transit. However, 
	 if the shared memory area fills up, new messages overwrite old messages and 
	 the loss is absolute. No retransmission of old messages that have been overwritten occurs.  
		</P
></LI
><LI
><P
>	 Receivers also do not send NAKs when using LBT-RDMA.  
		</P
></LI
><LI
><P
>	 LBT-RDMA does not support Ordered Delivery. However, if you set 
	 <A
HREF="../Config/majoroptions.html#RECEIVERORDEREDDELIVERY"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>ordered_delivery</TT
></A
> <TT
CLASS="LITERAL"
><B
CLASS="APPLICATION"
>1</B
></TT
> 
	 or <TT
CLASS="LITERAL"
><B
CLASS="APPLICATION"
>-1</B
></TT
>, LBT-RDMA reassembles any large messages.
		</P
></LI
><LI
><P
>	 LBT-RDMA does not support Rate Control. 
		</P
></LI
><LI
><P
>	 LBT-RDMA creates a separate receiver thread in the receiving context. 
		</P
></LI
></UL
></DIV
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="ARCHITECTURE"
>4. Architecture</A
></H2
><P
><B
CLASS="APPLICATION"
>UM</B
> is designed to be a flexible architecture. Unlike many messaging
systems, <B
CLASS="APPLICATION"
>UM</B
> does not require an intermediate daemon to handle routing
issues or protocol processing. This increases the performance of <B
CLASS="APPLICATION"
>UM</B
>
and returns valuable computation time and memory back to applications
that would normally be consumed by messaging daemons.</P
><P
>	 This section discusses the following topics.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#EMBEDDED-MODE"
><I
>Embedded Mode</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#SEQUENTIAL-MODE"
><I
>Sequential Mode</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TOPIC-RESOLUTION"
><I
>Topic Resolution</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#MESSAGE-BATCHING"
><I
>Message Batching</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#ORDERED-DELIVERY"
><I
>Ordered Delivery</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="EMBEDDED-MODE"
>4.1. Embedded Mode</A
></H3
><P
>When you create a context (<TT
CLASS="LITERAL"
>lbm_context_create()</TT
>) with the 
<A
HREF="../Config/majoroptions.html#CONTEXTOPERATIONALMODE"
TARGET="_top"
><TT
CLASS="LITERAL"
>operational_mode</TT
></A
> set to <TT
CLASS="LITERAL"
>embedded</TT
> 
(the default),
<B
CLASS="APPLICATION"
>UM</B
> creates an independent thread, called the <I
CLASS="FIRSTTERM"
>context thread</I
>, 
which handles timer and socket events, and does protocol-level processing, like
retransmission of dropped packets.</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="SEQUENTIAL-MODE"
>4.2. Sequential Mode</A
></H3
><P
>When you create a context (<TT
CLASS="LITERAL"
>lbm_context_create()</TT
>) with the 
<A
HREF="../Config/majoroptions.html#CONTEXTOPERATIONALMODE"
TARGET="_top"
><TT
CLASS="LITERAL"
>operational_mode</TT
></A
> set to <TT
CLASS="LITERAL"
>sequential</TT
>, 
the context thread is NOT created. It becomes the application's responsibility to 
donate a thread to <B
CLASS="APPLICATION"
>UM</B
> by calling <CODE
CLASS="FUNCTION"
>lbm_context_process_events()</CODE
> 
regularly, typically in a tight loop.  Use Sequential mode for 
circumstances where your application wants control over the attributes of the context 
thread.  For example, some applications raise the priority of the context thread so 
as to obtain more consistent latencies.
In sequential mode, no separate thread is spawned when a context is created.</P
><P
>You enable Sequential mode with the following configuration option. 
  </P
><PRE
CLASS="SCREEN"
>context operational_mode sequential
  </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="TOPIC-RESOLUTION"
>4.3. Topic Resolution</A
></H3
><P
>  Topic resolution is the discovery of a topic's transport session information 
  by a receiver to enable the receipt of topic messages. By default, <B
CLASS="APPLICATION"
>UM</B
> 
  relies on multicast requests and responses to resolve topics to transport 
  sessions. (You can also use Unicast requests and responses, if needed.) 
  <B
CLASS="APPLICATION"
>UM</B
> receivers multicast their topic requests, or queries, to an IP 
  multicast address and UDP port 
  (<A
HREF="../Config/multicastresolvernetworkoptions.html#CONTEXTRESOLVERMULTICASTADDRESS"
TARGET="_top"
>  <TT
CLASS="LITERAL"
>resolver_multicast_address</TT
></A
> and 
  <A
HREF="../Config/multicastresolvernetworkoptions.html#CONTEXTRESOLVERMULTICASTPORT"
TARGET="_top"
>  <TT
CLASS="LITERAL"
>resolver_multicast_port</TT
></A
>). <B
CLASS="APPLICATION"
>UM</B
> sources also 
  multicast their advertisements  and responses to receiver queries to the 
  same multicast address and UDP port.
  </P
><P
>Topic Resolution offers 3 distinct phases that can be implemented.
  </P
><P
></P
><UL
><LI
><P
>  Initial Phase - Period that allows you to resolve a topic aggressively. Can be used to 
  resolve all known topics before message sending begins. This phase can be configured to 
  run differently from the defaults or completely disabled.
	 </P
></LI
><LI
><P
>  Sustaining Phase - Period that allows new receivers to resolve a topic after the Initial 
  Phase. Can also be the primary period of topic resolution if you disable the Initial Phase. 
  This phase can also be configured to run differently from the defaults or completely disabled.
	 </P
></LI
><LI
><P
>  Quiescent Phase - The "steady state" period during which a topic is resolved and <B
CLASS="APPLICATION"
>UM</B
> 
  uses no system resources for topic resolution.  
	 </P
></LI
></UL
><P
>	 This section discusses the following topics.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#MULTICAST-TOPIC-RESOLUTION"
><I
>Multicast Topic Resolution</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TR-PHASES"
><I
>Topic Resolution Phases</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#TOPIC-RESOLUTION-CONFIG-OPTIONS"
><I
>Topic Resolution Configuration Options</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#UNICAST-TOPIC-RESOLUTION"
><I
>Unicast Topic Resolution</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#UNICAST-TOPIC-RES-NAT"
><I
>Unicast Topic Resolution Across Administrative Domains</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="MULTICAST-TOPIC-RESOLUTION"
>4.3.1. Multicast Topic Resolution</A
></H4
><P
>  The following diagram depicts the <B
CLASS="APPLICATION"
>UM</B
> topic resolution using multicast.
	 </P
><DIV
CLASS="FIGURE"
><A
NAME="TOPICRESOLUTION"
></A
><P
><B
>Figure 4. Topic Resolution via Multicast</B
></P
><P
><IMG
SRC="TopicResolution.png"
ALIGN="CENTER"></P
></DIV
><P
>  <B
CLASS="APPLICATION"
>UM</B
> performs topic resolution automatically. Your application does not need to 
  call any API functions to initiate topic resolution, however, you can influence topic 
  resolution with <A
HREF="#TOPIC-RESOLUTION-CONFIG-OPTIONS"
><I
>Topic Resolution Configuration Options</I
></A
>. Moreover, you can set configuration 
  options for individual topics by using the <TT
CLASS="LITERAL"
>lbm_*_attr_setopt()</TT
> functions 
  in your application. 
  See <A
HREF="#DIFFERENT-OPTIONS"
><I
>Assigning Different Configuration Options to Individual Topics</I
></A
>
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 Multicast topic resolution traffic can use Datagram Bypass Layer (DBL) acceleration in conjunction 
	 with DBL-enabled 
	 <A
HREF="http://www.myri.com"
TARGET="_top"
><SPAN
CLASS="TRADEMARK"
>Myricom</SPAN
></A
> 
	 10-Gigabit Ethernet NICs for Linux and <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>. DBL is a kernel-bypass technology that 
	 accelerates sending and receiving UDP traffic. See 
	 <A
HREF="../Config/transportaccelerationoptions.html"
TARGET="_top"
>Transport Acceleration Options</A
> 
	 for more information. 
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	Multicast Topic Resolution is not supported directly on the <SPAN
CLASS="TRADEMARK"
>HP NonStop</SPAN
> platform, but can be run a different host 
	within your network supplying topic resolution services to sources and receivers running on <SPAN
CLASS="TRADEMARK"
>HP NonStop</SPAN
> platform.
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SOURCES-ADVERTISE"
>4.3.1.1. Sources Advertise</A
></H5
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> sources help <B
CLASS="APPLICATION"
>UM</B
> receivers discover transport information in the following ways.
	 </P
><P
></P
><UL
><LI
><P
>	 Advertise Active Topics - Each source advertises its active topic first upon its creation 
	 and subsequently according to the 
	 <A
HREF="../Config/resolveroperationoptions.html#SOURCERESOLVERADVERTISEMENTMAXIMUMINITIALINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_advertisement_*_interval</TT
></A
>
	 configuration options for the Initial and Sustaining Phases. Sources advertise by sending 
	 a Topic Information Record (TIR). (You can prevent a source from sending an advertisement 
	 upon creation with 
	 <A
HREF="../Config/resolveroperationoptions.html#SOURCERESOLVERSENDINITIALADVERTISEMENT"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_send_initial_advertisement</TT
></A
>.)
		</P
></LI
><LI
><P
>	 Respond to Topic Queries - Each source responds immediately to queries from receivers 
	 about its topic.  
		</P
></LI
></UL
><P
>	 Both a topic advertisement and a query response contain the topic's transport session 
	 information. Based on the transport type, a receiver can join the appropriate multicast 
	 group (for LBT-RM), send a connection request (for LBT-RU), connect to the source (for TCP) 
	 or access a shared memory area (for LBT-IPC). The address and port information potentially 
	 contained within a TIR includes:
		</P
><P
></P
><UL
><LI
><P
>	 For a TCP transport, the source address and TCP port.
		</P
></LI
><LI
><P
>	 For an LBT-RM transport, the unicast UDP port (to which NAKs are sent) and the UDP 
	 destination port. 
		</P
></LI
><LI
><P
>	 For an LBT-RU transport, the source address and UDP port.
		</P
></LI
><LI
><P
>	 For an LBT-IPC transport, the Host ID, LBT-IPC Session ID and Transport ID. 
		</P
></LI
><LI
><P
>	 For the UM Gateway, the context instance and Domain ID of the original source plus the Hop Count and Portal Cost. 
	 See <A
HREF="../Gateway/concepts.html#FORWARDING-COSTS"
TARGET="_top"
>Forwarding Costs</A
>
		</P
></LI
><LI
><P
>	 For various <B
CLASS="APPLICATION"
>UMP</B
> options, the store address and TCP port, and the source address 
	 and TCP port (to which receivers send delivery confirmations).
		</P
></LI
><LI
><P
>	 For <B
CLASS="APPLICATION"
>UMQ</B
>, the Queue Name, which allows the receiver to then resolve the Queue 
	 in order to receive queued messages.  
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RECEIVERS-QUERY"
>4.3.1.2. Receivers Query</A
></H5
><P
>	 Receivers can discover transport information in the following ways.
	 </P
><P
></P
><UL
><LI
><P
>	 Search advertisements collected in the resolver cache maintained by the <B
CLASS="APPLICATION"
>UM</B
> context.
		</P
></LI
><LI
><P
>	 Listen for source advertisements on the <TT
CLASS="LITERAL"
>resolver_multicast_address:port</TT
>.  
		</P
></LI
><LI
><P
>	 Send a topic query (TQR).
		</P
></LI
></UL
><P
>	 A new receiver queries for its topic according to the 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMAXIMUMINITIALINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_*_interval</TT
></A
> configuration options for the 
	 Initial and Sustaining Phases.
		</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 The <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMINIMUMINITIALINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_minimum_initial_interval</TT
></A
> actually begins after 
	 you call <TT
CLASS="LITERAL"
>lbm_rcv_topic_lookup()</TT
> prior to creating the receiver. 
	 If you have disabled the Initial Phase for the topic's resolution, the 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYSUSTAININTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_sustaining_interval</TT
></A
> begins after you call 
	 <TT
CLASS="LITERAL"
>lbm_rcv_topic_lookup()</TT
>.
		</P
></BLOCKQUOTE
></DIV
><P
>	 A Topic Query Record (TQR) consists primarily of the topic string. Receivers continue 
	 querying on a topic until they discover the number of sources configured by 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLUTIONNUMBEROFSOURCESQUERYTHRESHOLD"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolution_number_of_sources_query_threshold</TT
></A
>. 
	 However the large default of this configuration option (10,000,000) allows a receiver 
	 to continue to query until both the initial and sustaining phase of topic resolution complete.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="WILDCARD"
>4.3.1.3. Wildcard Receivers</A
></H5
><P
>	 Wildcard receivers can discover transport information in the following ways. 
	 </P
><P
></P
><UL
><LI
><P
>	 Search advertisements collected in the resolver cache maintained by the <B
CLASS="APPLICATION"
>UM</B
> context.
		</P
></LI
><LI
><P
>	 Listen for source advertisements on the <TT
CLASS="LITERAL"
>resolver_multicast_address:port</TT
>.  
		</P
></LI
><LI
><P
>	 Send a wildcard receiver topic query (WC-TQR).  
		</P
></LI
></UL
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> implements only one phase of wildcard receiver queries, sending wildcard receiver 
	 queries according to wildcard receiver 
	 <A
HREF="../Config/wildcardreceiveroptions.html#WILDCARDRECEIVERRESOLVERQUERYMAXIMUMINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_*_interval</TT
></A
> 
	 configuration options until the topic pattern has been queried for the 
	 <A
HREF="../Config/wildcardreceiveroptions.html#WILDCARDRECEIVERRESOLVERQUERYMINIMUMDURATION"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_minimum_duration</TT
></A
>. 
	 The wildcard receiver topic query (WC-TQR) contains the topic pattern and the 
	 <A
HREF="../Config/wildcardreceiveroptions.html#WILDCARDRECEIVERPATTERNTYPE"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>pattern_type</TT
></A
>.
	 </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TR-PHASES"
>4.3.2. Topic Resolution Phases</A
></H4
><P
>  The phases of topic resolution pertain to individual topics. Therefore if your system 
  has 100 topics, 100 different topic resolution advertisement and query phases may be 
  running concurrently. This describes the three phases of <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> topic resolution.
	 </P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#INITIAL-PHASE"
><I
>Initial Phase</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#SUSTAIN-PHASE"
><I
>Sustaining Phase</I
></A
> 
		</P
></LI
><LI
><P
>	 <A
HREF="#QUIESCENT-PHASE"
><I
>Quiescent Phase</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="INITIAL-PHASE"
>4.3.2.1. Initial Phase</A
></H5
><P
>	 The initial topic resolution phase for a topic is an aggressive phase that can be 
	 used to resolve all topics before sending any messages. During the initial phase, 
	 network traffic and CPU utilization might actually be higher. You can completely 
	 disable this phase, if desired. See <A
HREF="../Config/disable-topic-res.html"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>Disabling Aspects of Topic Resolution</TT
></A
>.
	 </P
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="INITIAL-PHASE-ADS"
>4.3.2.1.1. Advertising in the Initial Phase</A
></H6
><P
>	 For the initial phase default settings, the resolver issues the first advertisement 
	 as soon as the scheduler can process it. The resolver issues the second advertisement 
	 10 ms later, or at the 
	 <A
HREF="../Config/resolveroperationoptions.html#SOURCERESOLVERADVERTISEMENTMINIMUMINITIALINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_advertisement_minimum_initial_interval</TT
></A
>. 
	 For each subsequent advertisement, <B
CLASS="APPLICATION"
>UM</B
> doubles the interval between advertisements. 
	 The source sends an advertisement at 20 ms, 40 ms, 80 ms, 160 ms, 320 ms and finally 
	 at 500 ms, or the 
	 <A
HREF="../Config/resolveroperationoptions.html#SOURCERESOLVERADVERTISEMENTMAXIMUMINITIALINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_advertisement_maximum_initial_interval</TT
></A
>. 
	 These 8 advertisements require a total of 1130 ms. The interval between 
	 advertisements remains at the maximum 500 ms, resulting in 7 more advertisements 
	 before the total duration of the initial phase reaches 5000 ms, or the 
	 <A
HREF="../Config/resolveroperationoptions.html#SOURCERESOLVERADVERTISEMENTMINIMUMINITIALDURATION"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_advertisement_minimum_initial_duration</TT
></A
>. 
	 This concludes the initial advertisement phase for the topic. 
		</P
><DIV
CLASS="FIGURE"
><A
NAME="INITIAL-PHASE-TIR"
></A
><P
><B
>Figure 5. Initial Advertisement Phase</B
></P
><P
><IMG
SRC="Resolver_Initial_Phase_TIR.png"
ALIGN="CENTER"></P
></DIV
><P
>	 The initial phase for a topic can take longer than the 
	 <A
HREF="../Config/resolveroperationoptions.html#SOURCERESOLVERADVERTISEMENTMINIMUMINITIALDURATION"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_advertisement_minimum_initial_duration</TT
></A
> 
	 if many topics are in resolution at the same time. The configuration options, 
	 <A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERINITIALADVERTISEMENTSPERSECOND"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_initial_advertisements_per_second</TT
></A
> and 
	 <A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERINITIALADVERTISEMENTBPS"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_initial_advertisement_bps</TT
></A
> enforce a rate 
	 limit on topic advertisements for the entire <B
CLASS="APPLICATION"
>UM</B
> context. A large number 
	 of topics in resolution - in any phase - or long topic names may exceed these limits.
		</P
><P
>	 If a source advertising in the initial phase receives a topic query, it responds 
	 with a topic advertisement. <B
CLASS="APPLICATION"
>UM</B
> recalculates the next advertisement interval 
	 from that point forward as if the advertisement was sent at the nearest interval.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="INITIAL-PHASE-QUERY"
>4.3.2.1.2. Querying in the Initial Phase</A
></H6
><P
>	 Querying activity by receivers in the initial phase operates in similar fashion 
	 to advertising activity, although with different interval defaults. The 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMINIMUMINITIALINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_minimum_initial_interval</TT
></A
> 
	 default is 20 ms. Subsequent intervals double in length until the interval 
	 reaches 200 ms, or the 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMAXIMUMINITIALINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_maximum_initial_interval</TT
></A
>. The query interval 
	 remains at 200 ms until the initial querying phase reaches 5000 ms, or the 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMINIMUMINITIALDURATION"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_minimum_initial_duration</TT
></A
>.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="INITIAL-PHASE-TQR"
></A
><P
><B
>Figure 6. Initial Query Phase</B
></P
><P
><IMG
SRC="Resolver_Initial_Phase_TQR.png"
ALIGN="CENTER"></P
></DIV
><P
>	 The initial query phase completes when it reaches the 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMINIMUMINITIALDURATION"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_minimum_initial_duration</TT
></A
>.
	 The initial query phase also has <B
CLASS="APPLICATION"
>UM</B
> context-wide rate limit controls 
	 (<A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERINITIALQUERIESPERSECOND"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_initial_queries_per_second</TT
></A
> and 
	 <A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERINITIALQUERYBPS"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_initial_query_bps</TT
></A
>) that can result in the extension 
	 of a phase's duration in the case of a large number of topics or long topic names.
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SUSTAIN-PHASE"
>4.3.2.2. Sustaining Phase</A
></H5
><P
>	 The sustaining topic resolution phase follows the initial phase and can be a less 
	 active phase in which a new receiver resolves its topic. It can also act as the sole 
	 topic resolution phase if you disable the initial phase. The sustaining phase defaults 
	 use less network resources than the initial phase and can also be modified or disabled 
	 completely. See <A
HREF="../Config/disable-topic-res.html"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>Disabling Aspects of Topic Resolution</TT
></A
>.
	 </P
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="SUSTAIN-PHASE-ADS"
>4.3.2.2.1. Advertising in the Sustaining Phase</A
></H6
><P
>	 For the sustaining phase defaults, a source sends an advertisement every second 
	 (<A
HREF="../Config/resolveroperationoptions.html#SOURCERESOLVERADVERTISEMENTSUSTAININTERVAL"
TARGET="_top"
> 
	 <TT
CLASS="LITERAL"
>resolver_advertisement_sustain_interval</TT
></A
>) for 1 minute 
	 (<A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERADVERTISEMENTMINIMUMSUSTAINDURATION"
TARGET="_top"
> <TT
CLASS="LITERAL"
>resolver_advertisement_minimum_sustain_duration</TT
></A
>). 
	 When this duration expires, the sustaining phase of advertisement for a topic ends. 
	 If a source receives a topic query, the sustaining phase resumes for the topic 
	 and the source completes another duration of advertisements.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="SUSTAIN-PHASE-TIR"
></A
><P
><B
>Figure 7. Sustaining Advertisement Phase</B
></P
><P
><IMG
SRC="Resolver_Sustain_Phase_TIR.png"
ALIGN="CENTER"></P
></DIV
><P
>	 The sustaining advertisement phase has <B
CLASS="APPLICATION"
>UM</B
> context-wide rate limit controls 
	 (<A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERSUSTAINADVERTISEMENTSPERSECOND"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_sustain_advertisements_per_second</TT
></A
> and 
	 <A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERSUSTAINADVERTISEMENTBPS"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_sustain_advertisement_bps</TT
></A
>) that can result in 
	 the extension of a phase's duration in the case of a large number of topics or long topic names.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="SUSTAIN-PHASE-QUERY"
>4.3.2.2.2. Querying in the Sustaining Phase</A
></H6
><P
>	 Default sustaining phase querying operates the same as advertising. Unresolved 
	 receivers query every second 
	 (<A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYSUSTAININTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_sustain_interval</TT
></A
>) for 1 minute 
	 (<A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMINIMUMSUSTAINDURATION"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_minimum_sustain_duration</TT
></A
>). 
	 When this duration expires, the sustaining phase of querying for a topic ends.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="SUSTAIN-PHASE-TQR"
></A
><P
><B
>Figure 8. Sustaining Query Phase</B
></P
><P
><IMG
SRC="Resolver_Sustain_Phase_TQR.png"
ALIGN="CENTER"></P
></DIV
><P
>	 Sustaining phase queries stop when one of the following events occurs.
		</P
><P
></P
><UL
><LI
><P
>	 The receiver discovers multiple sources that equal 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLUTIONNUMBEROFSOURCESQUERYTHRESHOLD"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolution_number_of_sources_query_threshold</TT
></A
>.
		</P
></LI
><LI
><P
>	 The sustaining query phase reaches the 
	 <A
HREF="../Config/resolveroperationoptions.html#RECEIVERRESOLVERQUERYMINIMUMSUSTAINDURATION"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_query_minimum_sustain_duration</TT
></A
>.  
		</P
></LI
></UL
><P
>	 The sustaining query phase also has <B
CLASS="APPLICATION"
>UM</B
> context-wide rate limit controls 
	 (<A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERSUSTAINQUERIESPERSECOND"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_sustain_queries_per_second</TT
></A
> and 
	 <A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERSUSTAINQUERYBPS"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_sustain_query_bps</TT
></A
>) that can result in the 
	 extension of a phase's duration in the case of a large number of topics or long topic names.
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="QUIESCENT-PHASE"
>4.3.2.3. Quiescent Phase</A
></H5
><P
>	 This phase is the absence of topic resolution activity for a given topic. It is 
	 possible that some topics may be in the quiescent phase at the same time other 
	 topics are in initial or sustaining phases of topic resolution. This phase ends if 
	 either of the following occurs.
	 </P
><P
></P
><UL
><LI
><P
>	 A new receiver sends a query.
		</P
></LI
><LI
><P
>	 Your application calls <TT
CLASS="LITERAL"
>lbm_context_topic_resolution_request()</TT
> 
	 that provokes the sending of topic queries for any receiver or wildcard receiver 
	 in this state.  
		</P
></LI
></UL
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TOPIC-RESOLUTION-CONFIG-OPTIONS"
>4.3.3. Topic Resolution Configuration Options</A
></H4
><P
>  Refer to the <B
CLASS="APPLICATION"
>UM</B
> Configuration Guide for specific information about Topic 
  Resolution Configuration Options.
	 </P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../Config/resolveroperationoptions.html"
TARGET="_top"
>Resolver Operation Options</A
>
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/multicastresolvernetworkoptions.html"
TARGET="_top"
>Multicast Resolver 
	 Network Options</A
>  
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/unicastresolvernetworkoptions.html"
TARGET="_top"
>Unicast Resolver 
	 Network Options</A
>  
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/wildcardreceiveroptions.html"
TARGET="_top"
>Wildcard Receiver Options</A
>  
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="DIFFERENT-OPTIONS"
>4.3.3.1. Assigning Different Configuration Options to Individual Topics</A
></H5
><P
>  You can assign different configuration option values to individual topics by accessing 
  the topic attribute table (<TT
CLASS="LITERAL"
>lbm_*_topic_attr_t_stct</TT
>) before creating the 
  source, receiver or wildcard receiver.
	 </P
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="DIFFERENT-OPTIONS-SOURCE"
>4.3.3.1.1. Creating a Source with Different Topic Resolution Options</A
></H6
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_src_topic_attr_setopt()</TT
> to set new option value
		</P
></LI
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_src_topic_alloc()</TT
>  
		</P
></LI
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_src_create()</TT
>  
		</P
></LI
></OL
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="DIFFERENT-OPTIONS-RECEIVER"
>4.3.3.1.2. Creating a Receiver with Different Topic Resolution Options</A
></H6
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_rcv_topic_attr_setopt()</TT
> to set new option value
		</P
></LI
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_rcv_topic_lookup()</TT
>  
		</P
></LI
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_rcv_create()</TT
> 
		</P
></LI
></OL
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="DIFFERENT-OPTIONS-WILDCARD"
>4.3.3.1.3. Creating a Wildcard Receiver with Different Topic Resolution Options</A
></H6
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_wildcard_rcv_attr_setopt()</TT
>  to set new wildcard receiver option value
		</P
></LI
><LI
><P
>	 Call <TT
CLASS="LITERAL"
>lbm_wildcard_rcv_create()</TT
>  
		</P
></LI
></OL
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="MULTICAST-NETWORK"
>4.3.3.2. Multicast Network Options</A
></H5
><P
>	 Essentially, the <TT
CLASS="LITERAL"
>_incoming</TT
> and <TT
CLASS="LITERAL"
>_outgoing</TT
> 
	 versions of <TT
CLASS="LITERAL"
>resolver_multicast_address/port</TT
> provide more 
	 fine-grained control of topic resolution. By default, the 
	 <A
HREF="../Config/multicastresolvernetworkoptions.html#CONTEXTRESOLVERMULTICASTADDRESS"
TARGET="_top"
>  <TT
CLASS="LITERAL"
>resolver_multicast_address</TT
></A
> and 
  <A
HREF="../Config/multicastresolvernetworkoptions.html#CONTEXTRESOLVERMULTICASTPORT"
TARGET="_top"
>  <TT
CLASS="LITERAL"
>resolver_multicast_port</TT
></A
> 
	 and the  <TT
CLASS="LITERAL"
>_incoming</TT
> and <TT
CLASS="LITERAL"
>_outgoing</TT
> address 
	 and port are set to the same value.  If you want your context to listen to a 
	 particular multicast address/port and send on another address/port, then you 
	 can set the <TT
CLASS="LITERAL"
>_incoming</TT
> and <TT
CLASS="LITERAL"
>_outgoing</TT
> 
	 configuration options to different values.
	 </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="UNICAST-TOPIC-RESOLUTION"
>4.3.4. Unicast Topic Resolution</A
></H4
><P
>      This section also discusses the following topics.
        </P
><P
></P
><UL
><LI
><P
>      <A
HREF="#UNICAST-TOPIC-RES-RESILIENCE"
><I
>Unicast Topic Resolution Resilience</I
></A
>
        </P
></LI
><LI
><P
>      <A
HREF="#UNICAST-TOPIC-RES-NAT"
><I
>Unicast Topic Resolution Across Administrative Domains</I
></A
> 
        </P
></LI
></UL
><P
>  By default <B
CLASS="APPLICATION"
>UM</B
> expects multicast connectivity between all sources and receivers. 
  When only unicast connectivity is available, you may configure all sources and 
  receivers to use unicast topic resolution. This requires that you run one or more <B
CLASS="APPLICATION"
>UM</B
> 
  unicast topic resolution daemon(s) 
  (<A
HREF="#LBMRD-MANPAGE"
><I
>Manpage for lbmrd</I
></A
>), 
  which perform the same topic resolution activities as multicast topic resolution. You 
  configure each instance of the unicast topic resolution daemon with 
  <A
HREF="../Config/unicastresolvernetworkoptions.html#CONTEXTRESOLVERUNICASTDAEMON"
TARGET="_top"
>  <TT
CLASS="LITERAL"
>resolver_unicast_daemon</TT
></A
>. 
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	The Unicast Topic Resolver <TT
CLASS="LITERAL"
>lbmrd</TT
> is not supported on the <SPAN
CLASS="TRADEMARK"
>HP NonStop</SPAN
> platform.
		</P
></BLOCKQUOTE
></DIV
><P
>	 The <TT
CLASS="LITERAL"
>lbmrd</TT
> can run on any machine, including the source or 
	 receiver (enter <TT
CLASS="LITERAL"
>lbmrd</TT
> -h for instructions). Of course, sources 
	 will also have to select a transport protocol that uses unicast addressing 
	 (e.g. TCP, TCP-LB, or LBT-RU).  
	 The <TT
CLASS="LITERAL"
>lbmrd</TT
> maintains a table of clients (address and port pairs) 
	 from which it has received a topic resolution message, which can be any of the 
	 following.
	 </P
><P
></P
><UL
><LI
><P
>	 Topic Information Records (TIR) - also known as topic advertisements
		</P
></LI
><LI
><P
>	 Topic Query Records (TQR)  
		</P
></LI
><LI
><P
>	 keepalive messages, which are only used in unicast topic resolution  
		</P
></LI
></UL
><P
>	 After <TT
CLASS="LITERAL"
>lbmrd</TT
> receives a TQR or TIR, it forwards it to all 
	 known clients.
	 If a client (i.e. source or receiver) is not sending either TIRs or TQRs, 
	 it sends a  keepalive message to <TT
CLASS="LITERAL"
>lbmrd</TT
> according to the 
	 <A
HREF="../Config/resolveroperationoptions.html#CONTEXTRESOLVERUNICASTKEEPALIVEINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>resolver_unicast_keepalive_interval</TT
></A
>. 
	 This registration with the <TT
CLASS="LITERAL"
>lbmrd</TT
> allows the client 
	 to receive advertisements or queries from <TT
CLASS="LITERAL"
>lbmrd</TT
>. 
	 <TT
CLASS="LITERAL"
>lbmrd</TT
> maintains no state about topics, only about clients.
	 </P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="UNICAST-TOPIC-RES-TIR"
>4.3.4.1. Topic Information Records</A
></H5
><P
>	 Of all topic resolution messages, only the TIR contains address and port 
	 information. This tells a receiver how it can get the data being published. 
	 Based on the transport type, a receiver can join the appropriate multicast 
	 group (for LBT-RM), send a connection request (for LBT-RU), or connect to the 
	 source (for TCP).
	 </P
><P
>	 The TIR contains additional blocks of information to define <B
CLASS="APPLICATION"
>UMP</B
> capabilities, 
	 indicating the address and port of the source and store.
	 </P
><P
>	 The address and port information potentially contained within a TIR includes:
	 </P
><P
></P
><UL
><LI
><P
>	 For a TCP transport, the source address and TCP port.
		</P
></LI
><LI
><P
>	 For an LBT-RM transport, the unicast UDP port (to which NAKs are sent) and 
	 the UDP destination port.  
		</P
></LI
><LI
><P
>	 For an LBT-RU transport, the source address and UDP port.
		</P
></LI
><LI
><P
>	 For various <B
CLASS="APPLICATION"
>UMP</B
> options, the store address and TCP port, and the source 
	 address and TCP port (to which delivery confirmations are sent).
		</P
></LI
><LI
><P
>	 For <B
CLASS="APPLICATION"
>UMQ</B
>, the Queue Name and TCP port.
		</P
></LI
></UL
><P
>	 For unicast-based transports (TCP and LBT-RU), the TIR source address is 0.0.0.0, 
	 not the actual source address. This allows some minimal functionality within a 
	 Network Address Translation (NAT) environment.
	 </P
><P
>	 Topic resolution messages (whether received by the application via multicast, 
	 or by the unicast topic resolution daemon via unicast) are always UDP datagrams. 
	 They are received via a <TT
CLASS="LITERAL"
>recvfrom()</TT
> call, which also obtains 
	 the address and port 
	 from which the datagrams were received. If the address 0.0.0.0 (INADDR_ANY) appears 
	 for one of the addresses, <TT
CLASS="LITERAL"
>lbmrd</TT
> replaces it with the address 
	 from which the datagram is received. The net effect is as if the actual source 
	 address had originally been put into the TIR.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="UNICAST-TOPIC-RES-RESILIENCE"
>4.3.4.2. Unicast Topic Resolution Resilience</A
></H5
><P
>    Running multiple instances of <TT
CLASS="LITERAL"
>lbmrd</TT
> allows your applications to continue operation 
    in the face of a <TT
CLASS="LITERAL"
>lbmrd</TT
> failure. Your applications' sources and receivers send topic resolution 
    messages as usual, however, rather than sending every message to each <TT
CLASS="LITERAL"
>lbmrd</TT
> instance, 
    <B
CLASS="APPLICATION"
>UM</B
> directs messages to <TT
CLASS="LITERAL"
>lbmrd</TT
> instances in a round-robin fashion. 
    Since the <TT
CLASS="LITERAL"
>lbmrd</TT
> does not maintain any resolver state, as long as one 
    <TT
CLASS="LITERAL"
>lbmrd</TT
> instance is running, <B
CLASS="APPLICATION"
>UM</B
> continues to forward LBMR packets to 
    all connected clients. <B
CLASS="APPLICATION"
>UM</B
> switches to the next active <TT
CLASS="LITERAL"
>lbmrd</TT
> instance every 250-750 ms.
	</P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="UNICAST-TOPIC-RES-NAT"
>4.3.4.3. Unicast Topic Resolution Across Administrative Domains</A
></H5
><P
>	 If your network architecture includes remote or local LANs that use Network 
	 Address Translation (NAT), you can implement an <TT
CLASS="LITERAL"
>lbmrd</TT
> 
	 configuration file to translate IP addresses/ports across administrative domains. Without 
	 translation, <TT
CLASS="LITERAL"
>lbmrd</TT
> clients (sources and receivers) across 
	 NAT boundaries cannot connect to each other in response to topic advertisements 
	 due to NAT restrictions. 
	 </P
><P
>	 By default, topic advertisements 
	 forwarded by <TT
CLASS="LITERAL"
>lbmrd</TT
> contain the private (or inside) address/port 
	 of the source. Routers implementing NAT prevent connection to these private 
	 addresses from receivers outside the LAN. 
	 </P
><P
>	 The <TT
CLASS="LITERAL"
>lbmrd</TT
> configuration file allows <TT
CLASS="LITERAL"
>lbmrd</TT
> 
	 to insert a translation or outside address/port for the private address/port of the source 
	 in the topic advertisement. This outside or translation address must already be 
	 configured in the router's static NAT table. When the receiver attempts to connect 
	 to the source by using the source address/port in the topic advertisement, the NAT 
	 router automatically translates the outside address/port to the private address/port, 
	 thereby allowing the connection.
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
> The Request/Response model and the Late Join feature only work with 
	 (<TT
CLASS="LITERAL"
>lbmrd</TT
>) across local LANs that use Network Address Translation (NAT) 
	 if you use the default value (0.0.0.0) for 
	 <A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPINTERFACE"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>request_tcp_interface</TT
></A
>. 
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECTION"
><HR><H6
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG"
>4.3.4.3.1. lbmrd Configuration File</A
></H6
><P
>	 This section presents the syntax of the <TT
CLASS="LITERAL"
>lbmrd</TT
> configuration 
	 file, which is an XML file. Descriptions of elements also appear below. See 
	 <A
HREF="../Config/unicastresolver.html"
TARGET="_top"
>Unicast Resolver Example Configuration</A
> 
	 for an example <TT
CLASS="LITERAL"
>lbmrd</TT
> configuration file.
	 </P
><PRE
CLASS="PROGRAMLISTING"
>&lt;?xml version="1.0" encoding="UTF-8" ?&#62;
&lt;lbmrd version="1.0"&#62;
	&lt;domains&#62;
	 &lt;domain name="domain-name-1"&#62;
		 &lt;network&#62;network-specification&lt;/network&#62;
	 &lt;/domain&#62;
	 &lt;domain name="domain-name-2"&#62;
		 &lt;network&#62;network-specification&lt;/network&#62;
	 &lt;/domain&#62;
	&lt;/domains&#62;
	&lt;transformations&#62;
	 &lt;transform source="source-domain-name"
		 destination="destination-domain-name"&#62;
		 &lt;rule&#62;
		  &lt;match address="original-address" port="original-port"/&#62;
		  &lt;replace address="replacement-address" port="replacement-port"/&#62;
		 &lt;/rule&#62;
	 &lt;/transform&#62;
	&lt;/transformations&#62;
&lt;/lbmrd&#62;</PRE
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-LBMRD"
>4.3.4.3.1.1. &lt;lbmrd&#62; Element</A
></H7
><P
>	 The &lt;lbmrd&#62; element is the root element. It requires a single attribute, 
	 version, which defines the version of the DTD to be used. Currently, only 
	 version 1.0 is supported. The &lt;lbmrd&#62; element must contain a single 
	 &lt;domains&#62; element and a single &lt;transformations&#62; element.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-DOMAINS"
>4.3.4.3.1.2. &lt;domains&#62; Element</A
></H7
><P
>	 The &lt;domains&#62; element defines the set of network domains. The &lt;domains&#62; 
	 element may contain one or more &lt;domain&#62; elements. Each defines a separate domain.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-DOMAIN"
>4.3.4.3.1.3. &lt;domain&#62; Element</A
></H7
><P
>	 The &lt;domain&#62; element defines a single network domain. Each domain must be 
	 named via the name attribute. This name is referenced in &lt;map&#62; elements, 
	 which are discussed below. Each domain name must be unique. The &lt;domain&#62; 
	 element may contain one or more &lt;network&#62; elements.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-NETWORK"
>4.3.4.3.1.4. &lt;network&#62; Element</A
></H7
><P
>	 The &lt;network&#62; element defines a single network specification which is 
	 to be considered part of the enclosing &lt;domain&#62;. The network specification 
	 must contain either an IP address, or a network specification in CIDR form.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-TRANSFORMATIONS"
>4.3.4.3.1.5. &lt;transformations&#62; Element</A
></H7
><P
>	 The &lt;transformations&#62; element defines and contains the set of 
	 transformations to be applied to the TIRs. The &lt;transformations&#62; element 
	 contains one or more &lt;transform&#62; elements, described below.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-TRANSFORM"
>4.3.4.3.1.6. &lt;transform&#62; Element</A
></H7
><P
>	 The &lt;transform&#62; element defines a set of transformation tuples. Each 
	 tuple applies to a TIR sent from a specific network domain (specified using 
	 the source attribute), and destined for a specific network domain (specified 
	 using the destination attribute). The source and destination attributes must 
	 specify a network domain name as defined by the &lt;domain&#62; elements. The 
	 &lt;transform&#62; element contains one or more &lt;rule&#62; elements, described below.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-RULE"
>4.3.4.3.1.7. &lt;rule&#62; Element</A
></H7
><P
>	 Each &lt;rule&#62; element is associated with the enclosing &lt;transform&#62; 
	 element, and completes the transformation tuple. The &lt;rule&#62; element must 
	 contain one &lt;match&#62; element, and one &lt;replace&#62; element, described below.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-MATCH"
>4.3.4.3.1.8. &lt;match&#62; Element</A
></H7
><P
>	 The &lt;match&#62; element defines the address and port to match within the TIR. 
	 The attributes address and port specify the address and port. address must 
	 specify a full IP address (a network specification is not permitted). port 
	 specifies the port in the TIR. To match any port, specify port="*" (which is 
	 the default).
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-REPLACE"
>4.3.4.3.1.9. &lt;replace&#62; Element</A
></H7
><P
>	 The &lt;replace&#62; element defines the address and port which are to replace 
	 those matched in the TIR. The attributes address and port specify the address 
	 and port. address must specify a full IP address (a network specification is 
	 not permitted). To leave the TIR port unchanged, specify port="*" (which is 
	 the default).
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H7
CLASS="SECTION"
><A
NAME="LBMRD-NAT-CONFIG-NOTES"
>4.3.4.3.1.10. Notes on the &lt;match&#62; and &lt;replace&#62; Elements</A
></H7
><P
>	 It is valid to specify port="*" for both &lt;match&#62; and &lt;replace&#62;. This 
	 effectively matches all ports for the given address and changes only the 
	 address. It is important to note that TIR addresses and ports are considered 
	 together. For example, the Ultra Messaging R for the Enterprise option in the 
	 TIR contains the source address and port, and the store address and port. 
	 When processing a transformation tuple, the source address and source port 
	 are considered (and transformed) together, and the store address and store 
	 port are considered (and transformed) together.
		</P
></DIV
></DIV
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="MESSAGE-BATCHING"
>4.4. Message Batching</A
></H3
><P
>Batching many small messages into fewer network packets decreases the 
per-message CPU load, thereby increasing throughput. Let's say it costs 2 
microseconds of CPU to fully process a message. If you process 10 messages 
per second, you won't notice the load. If you process half a million messages 
per second, you saturate the CPU. So to achieve high message rates, you have 
to reduce the per-message CPU cost with some form of message batching. 
These per-message costs apply to both the sender and the receiver. However, 
the implementation of batching is almost exclusively the realm of the sender.
  </P
><P
>Many people are under the impression that while batching improves CPU load, 
it increases message latency. While it is true that there are circumstances 
where this can happen, it is also true that careful use of batching can 
result in small latency increases or none at all. In fact, there are 
circumstances where batching can actually reduce latency.
  </P
><P
><B
CLASS="APPLICATION"
>UM</B
> allows the following methods for batching messages.</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#IMPLICIT-BATCHING"
><I
>Implicit Batching</I
></A
> 
	 - the default behavior, batching messages for individual transport sessions.
		</P
></LI
><LI
><P
>	 <A
HREF="#ADAPTIVE-BATCHING"
><I
>Adaptive Batching</I
></A
> 
	 - a convenience feature of <B
CLASS="APPLICATION"
>UM</B
> that monitors sending activity and automatically 
	 determines the optimum time to flush the Implicit Batch buffer.
		</P
></LI
><LI
><P
>	 <A
HREF="#INTELLIGENT-BATCHING"
><I
>Intelligent Batching</I
></A
>
	 - a method that makes use of your application's knowledge of the messages it 
	 must send, clearing the Implicit Batching buffer when sending the only remaining 
	 message.
		</P
></LI
><LI
><P
>	 <A
HREF="#EXPLICIT-BATCHING"
><I
>Explicit Batching</I
></A
> 
	 - provides greater control to your application through 
	 <TT
CLASS="LITERAL"
>lbm_src_send()</TT
> message flags and also operates in 
	 conjunction with the Implicit Batching mechanism.
		</P
></LI
><LI
><P
>	 <A
HREF="#APPLICATION-BATCHING"
><I
>Application Batching</I
></A
>
	 - your application groups messages and sends them in a single batch.
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="IMPLICIT-BATCHING"
>4.4.1. Implicit Batching</A
></H4
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> automatically batches smaller messages into transport 
	 session datagrams. The implicit batching options,       
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_interval</TT
></A
> (default = 200 milliseconds) and 
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGMINIMUMLENGTH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
></A
> (default = 2048 bytes) govern
	 <B
CLASS="APPLICATION"
>UM</B
> implicit message batching.
	 Although these are source options, they actually apply to the transport 
	 session to which the source was assigned. See also 
	 <A
HREF="#SOURCE-CONFIG-TRANSPORT-SESSIONS"
><I
>Source Configuration and Transport Sessions</I
></A
>.
		</P
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> establishes the implicit batching parameters when it creates the 
	 transport session. Any sources assigned to that transport session use the 
	 implicit batching limits set for that transport session, and the limits apply 
	 to any and all sources subsequently assigned to that transport session. 
	 This means that batched transport datagrams can contain messages on 
	 multiple topics. See 
	 <A
HREF="#EXPLICIT-BATCHING"
><I
>Explicit Batching</I
></A
> 
	 for information about topic-level message batching.
		</P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="IMPLICIT-BATCHING-OPERATION"
>4.4.1.1. Implicit Batching Operation</A
></H5
><P
>		Implicit Batching buffers messages until:
		</P
><P
></P
><UL
><LI
><P
>		the buffer size exceeds the configured 
		<A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGMINIMUMLENGTH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
></A
> or
		</P
></LI
><LI
><P
>		the oldest message in the buffer has been in the buffer for 
		<A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_interval</TT
></A
> milliseconds.
		</P
></LI
></UL
><P
>		When either condition is met, <B
CLASS="APPLICATION"
>UM</B
> flushes the buffer, pushing the 
		messages onto the network.
		</P
><P
>		It may appear this design introduces significant latencies for low-rate 
		topics. However, remember that Implicit Batching operates on a transport 
		session basis. Typically many low-rate topics map to the same transport session, 
		providing a high aggregate rate. The 
		<A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGINTERVAL"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>implicit_batching_interval</TT
></A
> option is a last resort 
		to prevent messages from becoming stuck in the Implicit Batching buffer. 
		If your <B
CLASS="APPLICATION"
>UM</B
> deployment frequently uses the 
		<TT
CLASS="LITERAL"
>implicit_batching_interval</TT
> to push out the data (i.e. if 
		the entire transport session has periods of inactivity longer than the value of 
		<A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGINTERVAL"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>implicit_batching_interval</TT
></A
> (defaults to 200 ms), 
		then either the implicit batching options need to be fine-tuned (reducing one 
		or both), or you should consider an alternate form of batching. 
		See <A
HREF="#INTELLIGENT-BATCHING"
><I
>Intelligent Batching</I
></A
>.
		</P
><P
>		The minimum value for the 
		<A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGINTERVAL"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>implicit_batching_interval</TT
></A
> is 3 milliseconds.
		The actual minimum amount of time that data stays in the buffer depends on
		your Operating System and its scheduling clock interval. For example, 
		on a Solaris 8 machine, the actual time is approximately 20 milliseconds. 
		On <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
> machines, the time is probably 16 milliseconds. On a Linux 2.6 kernel, 
		the actual time is 3 milliseconds.  
		Using a <TT
CLASS="LITERAL"
>implicit_batching_interval</TT
> value of 3 guarantees the 
		minimum possible wait for whichever operating system you are using.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="IMPLICIT-BATCHING-EXAMPLE"
>4.4.1.2. Implicit Batching Example</A
></H5
><P
>		The following example demonstrates how the 
		<TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
> is actually a trigger 
		or floor, for sending batched messages. It is sometimes misconstrued as a 
		ceiling or upper limit.
		</P
><PRE
CLASS="SCREEN"
>  implicit_batching_minimum_length = 2000
		</PRE
><P
></P
><OL
TYPE="1"
><LI
><P
>		The first <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>send</I
></SPAN
> by your application puts 1900 bytes 
		into the batching buffer, which is below the minimum, so <B
CLASS="APPLICATION"
>UM</B
> holds it.
		</P
></LI
><LI
><P
>		The second <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>send</I
></SPAN
> fills the batching buffer to 
		3800 bytes, well over the minimum. <B
CLASS="APPLICATION"
>UM</B
> sends it down to the transport 
		layer, which builds a 3800-byte (plus overhead) datagram and sends it.   
		</P
></LI
><LI
><P
>		The Operating System fragments the datagram into packets independently 
		of <B
CLASS="APPLICATION"
>UM</B
> and reassembles them on the receiving end.   
		</P
></LI
><LI
><P
>		<B
CLASS="APPLICATION"
>UM</B
> reads the datagram from the socket at the receiver.  
		</P
></LI
><LI
><P
>		<B
CLASS="APPLICATION"
>UM</B
> parses out the two messages and delivers them to the 
		appropriate topic levels, which deliver the data.  
		</P
></LI
></OL
><P
>		The proper setting of the implicit batching parameters often represents a 
		tradeoff between latency and efficiency, where efficiency affects the highest 
		throughput attainable. In general, a large minimum length setting increases 
		efficiency and allows a higher peak message rate, but at low message rates 
		a large minimum length can increase latency. A small minimum length can lower 
		latency at low message rates, but does not allow the message rate to reach the 
		same peak levels due to inefficiency. An intelligent use of implicit batching 
		and application-level flushing can be used to implement an adaptive form of 
		batching known as 
		<A
HREF="#INTELLIGENT-BATCHING"
><I
>Intelligent Batching</I
></A
> 
		which can provide low latency and high throughput with a single setting.
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="ADAPTIVE-BATCHING"
>4.4.2. Adaptive Batching</A
></H4
><P
>	 Adaptive Batching is a convenience batching feature that attempts to send 
	 messages immediately during periods of low volume and automatically batch 
	 messages during periods of higher volume. The goal of Adaptive Batching is 
	 to automatically optimize throughput and latency by monitoring such things 
	 as the time between calls to <CODE
CLASS="FUNCTION"
>lbm_src_send()</CODE
>, the time 
	 messages spend in the Implicit Batching queue, the Rate Controller queue, 
	 and other sending activities. With this information, Adaptive Batching 
	 determines if sending batched messages now or later produces the least 
	 latency.
		</P
><P
>	 Adaptive Batching will not satisfy everyone's requirements of throughput and 
	 latency. You only need to turn it on and determine if it produces satisfactory 
	 performance. If it does, you need do nothing more. If you are not satisfied with 
	 the results, simply turn it off.
		</P
><P
>	 You enable Adaptive Batching by setting 
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGTYPE"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_type</TT
></A
> to <TT
CLASS="LITERAL"
>adaptive</TT
>. 
	 When using Adaptive Batching, it is advisable to increase the 
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGMINIMUMLENGTH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
></A
> option to a higher 
	 value.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="INTELLIGENT-BATCHING"
>4.4.3. Intelligent Batching</A
></H4
><P
>	 Intelligent Batching uses Implicit Batching along with your application's 
	 knowledge of the messages it must send. It is a form of dynamic adaptive 
	 batching that automatically adjusts for different message rates. Intelligent 
	 Batching can provide significant savings of CPU resources 
	 without adding any noticeable latency.
		</P
><P
>	 For example, your application might receive input events in a batch, and 
	 therefore know that it must produce a corresponding batch of output messages. 
	 Or the message producer works off of an input queue, and it can detect 
	 messages in the queue. 
		</P
><P
>	 In any case, if the application knows that it has more messages to send 
	 without going to sleep, it simply does normal sends to <B
CLASS="APPLICATION"
>UM</B
>, letting 
	 Implicit Batching send only when the buffer meets the 
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGMINIMUMLENGTH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
></A
> 
	 threshold. However, when the application detects that it 
	 has no more messages to send after it sends the current message, it sets 
	 the FLUSH flag (LBM_MSG_FLUSH) when sending the message 
	 which instructs <B
CLASS="APPLICATION"
>UM</B
> to 
	 flush the implicit batching buffer immediately by sending all 
	 messages to the transport layer. Refer to <TT
CLASS="LITERAL"
>lbm_src_send()</TT
> in
	 the UMS API documentation 
	 (<A
HREF="../API/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> C API</A
>, 
	 <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Java API</A
> or
	 <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> .NET API</A
>) 
	 for all the available send flags.
		</P
><P
>	 When using Intelligent Batching, it is usually advisable to increase the 
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGMINIMUMLENGTH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
></A
> option to 10 
	 times the size of the average message, to a maximum value of 8196. This 
	 tends to strike a good balance between batching length and flushing 
	 frequency, giving you low latencies across a wide variation of message rates.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="EXPLICIT-BATCHING"
>4.4.4. Explicit Batching</A
></H4
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> allows you to batch messages for a particular topic with 
	 explicit batching. When your application sends a message 
	 (<TT
CLASS="LITERAL"
>lbm_src_send()</TT
>) it may flag the message as being the 
	 start of a batch (LBM_MSG_START_BATCH) or the end of a batch (LBM_MSG_END_BATCH). 
	 All messages sent between the 
	 start and end are grouped together. The flag used to indicate the end 
	 of a batch also signals <B
CLASS="APPLICATION"
>UM</B
> to send the message immediately to 
	 the implicit batching buffer. At this point, 
	 <A
HREF="#IMPLICIT-BATCHING"
><I
>Implicit Batching</I
></A
>      
	 completes the batching operation. <B
CLASS="APPLICATION"
>UM</B
> includes the start and 
	 end flags in the message so receivers can process the batched 
	 messages effectively.
		</P
><P
>	 Unlike Intelligent Batching which allows intermediate messages to trigger 
	 flushing according to the 
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGMINIMUMLENGTH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
></A
> option, 
	 explicit batching holds all messages until the batch is completed. This 
	 feature is useful if you configure a relatively small 
	 <A
HREF="../Config/implicitbatchingoptions.html#SOURCEIMPLICITBATCHINGMINIMUMLENGTH"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
></A
> and your 
	 application has a batch of messages to send that exceeds the 
	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
>. By releasing all the 
	 messages at once, Implicit Batching maximizes the size of the network datagrams.
		</P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="EXPLICIT-BATCHING-EXAMPLE"
>4.4.4.1. Explicit Batching Example</A
></H5
><P
>	 The following example demonstrates explicit batching.
		</P
><PRE
CLASS="SCREEN"
>implicit_batching_minimum_length = 8000
		</PRE
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Your application performs 10 <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>sends</I
></SPAN
> of 100 bytes 
	 each as a single explicit batch.
		</P
></LI
><LI
><P
>	 At the 10th <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>send</I
></SPAN
> (which completes the batch), 
	 <B
CLASS="APPLICATION"
>UM</B
> delivers the 1000 bytes of messages to the implicit batch buffer.   
		</P
></LI
><LI
><P
>	 Let's assume that the buffer already has 7899 bytes of data in it 
	 from other topics on the same transport session 
		</P
></LI
><LI
><P
>	  <B
CLASS="APPLICATION"
>UM</B
> adds the first 100-byte message to the buffer, bringing it to 7999.
		</P
></LI
><LI
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> adds the second 100-byte message, bringing it up to 8099 bytes, 
	 which exceeds <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
> but 
	 is below the 8192 maximum datagram size.
		</P
></LI
><LI
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> sends the 8099 bytes (plus overhead) datagram.
		</P
></LI
><LI
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> adds the third through tenth messages to the implicit 
	 batch buffer. These messages will be sent when either 
	 <TT
CLASS="LITERAL"
>implicit_batching_minimum_length</TT
> is again exceeded, or the 
	 <TT
CLASS="LITERAL"
>implicit_batching_interval</TT
> is met, or a message 
	 arrives in the buffer with the flush flag (LBM_MSG_FLUSH) set.
		</P
></LI
></OL
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="APPLICATION-BATCHING"
>4.4.5. Application Batching</A
></H4
><P
>	 In all of the above situations, your application sends individual messages 
	 to <B
CLASS="APPLICATION"
>UM</B
> and lets <B
CLASS="APPLICATION"
>UM</B
> decide when to push the data onto the wire 
	 (often with application help). With application batching, your application 
	 buffers messages itself and sends a group of messages to <B
CLASS="APPLICATION"
>UM</B
> with a 
	 single send. Thus, <B
CLASS="APPLICATION"
>UM</B
> treats the send as a single message. On the 
	 receiving side, your application needs to know how to dissect the <B
CLASS="APPLICATION"
>UM</B
> 
	 message into individual application messages.
		</P
><P
>	 This approach is most useful for Java or .NET applications where there is 
	 a higher per-message cost in delivering an <B
CLASS="APPLICATION"
>UM</B
> message to the application. 
	 It can also be helpful when using an event queue to deliver received messages. 
	 This imposes a thread switch cost for each <B
CLASS="APPLICATION"
>UM</B
> message. At low message 
	 rates, this extra overhead is not noticeable. However, at high message 
	 rates, application batching can significantly reduce CPU overhead.
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="ORDERED-DELIVERY"
>4.5. Ordered Delivery</A
></H3
><P
>		With the Ordered Delivery feature, a receiver's delivery controller can deliver messages to your
		application in sequence number order or arrival order. This feature can also reassemble fragmented
		messages or leave reassembly to the application. Ordered Delivery can be set via <B
CLASS="APPLICATION"
>UM</B
> configuration option
		to one of three modes:
		</P
><P
></P
><UL
><LI
><P
>			Sequence Number Order, Fragments Reassembled
		</P
></LI
><LI
><P
>			Arrival Order, Fragments Not Reassembled
		</P
></LI
><LI
><P
>			Arrival Order, Fragments Reassembled
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="SQN-ORDER"
>4.5.1. Sequence Number Order, Fragments Reassembled (Default Mode)</A
></H4
><P
>			In this mode, a receiver's delivery controller delivers messages in sequence number order (the
			same order in which they are sent). This feature also guarantees reassembly of fragmented large
			messages. To enable sequence number ordered delivery, set the  <A
HREF="../Config/majoroptions.html#RECEIVERORDEREDDELIVERY"
TARGET="_top"
>	                <TT
CLASS="LITERAL"
>ordered_delivery</TT
></A
> configuration option as shown:
			</P
><PRE
CLASS="SCREEN"
>receiver ordered_delivery 1</PRE
><P
>			Please note that ordered delivery can introduce latency when packets are lost.
			</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="ARR-ORDER-NO-REASSEMBLY"
>4.5.2. Arrival Order, Fragments Not Reassembled</A
></H4
><P
>			This mode allows messages to be delivered to the application in the order they are received. If
			a message is lost, <B
CLASS="APPLICATION"
>UM</B
> will retransmit the message. In the meantime, any subsequent messages
			received are delivered immediately to the application, followed by the dropped packet when its
			retransmission is received. This mode guarantees the lowest latency.
			</P
><P
>			With this mode, the receiver delivers messages larger than the transport's maximum datagram size
			as individual fragments. (See <TT
CLASS="LITERAL"
>transport_*_datagram_max_size</TT
> in the Ultra Messaging Configuration
			Guide.) The C API function, <CODE
CLASS="FUNCTION"
>lbm_msg_retrieve_fragment_info()</CODE
> returns fragmentation information
			for the message you pass to it, and can be used to reassemble large messages. (In Java and .NET,
			<CODE
CLASS="FUNCTION"
>LBMMessage</CODE
> provides methods to return the same fragment information.) Note that reassembly is
			not required for small messages.
			</P
><P
>			To enable this no-reassemble arrival-order mode, set the following configuration option as
			shown:
			</P
><PRE
CLASS="SCREEN"
>receiver ordered_delivery 0</PRE
><P
>			When developing message reassembly code, consider the following:
			</P
><P
></P
><UL
><LI
><P
>				Message fragments don't necessarily arrive in sequence number order.
			</P
></LI
><LI
><P
>				Some message fragments may never arrive (unrecoverable loss), so you must time out
				partial messages.
			</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="ARR-ORDER-WITH-REASSEMBLY"
>4.5.3. Arrival Order, Fragments Reassembled</A
></H4
><P
>			This mode delivers messages in the order they are received, except for fragmented messages,
			which <B
CLASS="APPLICATION"
>UM</B
> reassembles before delivering to your application. Your application can then use the
			<TT
CLASS="LITERAL"
>sequence_number</TT
> field of <TT
CLASS="LITERAL"
>lbm_msg_t</TT
> objects to order or discard messages.
			</P
><P
>			To enable this arrival-order-with-reassembly mode, set the following configuration option as
			shown:
			</P
><PRE
CLASS="SCREEN"
>receiver ordered_delivery -1</PRE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="TSNIS"
>4.6. Loss Detection Using TSNIs</A
></H3
><P
>	 	When a source enters a period during which it has no data traffic to send, that source issues timed
		Topic Sequence Number Info (TSNI) messages. The TSNI lets receivers know that the source is still active
		and also reminds receivers of the sequence number of the last message. This helps receivers become aware
		of any lost messages between TSNIs.
		</P
><P
>		Sources send TSNIs over the same transport and on the same topic as normal data messages. You can set a
		time value of the TSNI interval with configuration option
		<A
HREF="../Config/majoroptions.html#SOURCETRANSPORTTOPICSEQUENCENUMBERINFOINTERVAL"
TARGET="_top"
>                <TT
CLASS="LITERAL"
>transport_topic_sequence_number_info_interval</TT
></A
>.
		You can also set a time value for the duration that the source sends contiguous TSNIs with configuration
		option
		<A
HREF="../Config/majoroptions.html#SOURCETRANSPORTTOPICSEQUENCENUMBERINFOACTIVETHRESHOLD"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>transport_topic_sequence_number_info_active_threshold</TT
></A
>,
		after which time the source stops issuing
		TSNIs.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="TSNI-TIMING"
></A
><P
><B
>Figure 9. TSNI Timing</B
></P
><P
><IMG
SRC="TSNIs.png"
ALIGN="CENTER"></P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="SMS"
>4.7. Receiver Keepalive Using Sesssion Messages</A
></H3
><P
>	 	When an LBT-RM, LBT-RU, or LBT-IPC transport session enters a period during which it has no data traffic
		to send, UM issues timed Session Messages (SMs). For example, suppose all topics in a session stop
		sending data. One by one, they then send TSNIs, and if there is still no data to send, their TSNI
		periods eventually expire. After the last quiescent topic's TSNIs stop, UM begins transmitting SMs.
		</P
><P
>		You can set time values for SM interval and duration with configuration options specific to their
		transport type.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="SM-TIMING"
></A
><P
><B
>Figure 10. Session Message Timing</B
></P
><P
><IMG
SRC="SMs.png"
ALIGN="CENTER"></P
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="LBM-FEATURES"
>5. UMS Features</A
></H2
><P
></P
><UL
><LI
><P
>	 <A
HREF="#USING-LATE-JOIN"
><I
>Using Late Join</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#OTR"
><I
>Off-Transport Recovery (OTR)</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#REQUEST-RESPONSE-MESSAGES"
><I
>Request/Response Model</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#SELF-DESCRIBING-MESSAGING"
><I
>Self Describing Messaging</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#PRE-DEFINED-MESSAGING"
><I
>Pre-Defined Messaging</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#MULTICAST-IMMEDIATE-MESSAGING"
><I
>Multicast Immediate Messaging</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#SPECTRUM"
><I
>Spectrum</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#HOT-FAILOVER"
><I
>Hot Failover</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="USING-LATE-JOIN"
>5.1. Using Late Join</A
></H3
><P
>This section introduces the use of <B
CLASS="APPLICATION"
>UM</B
> Late Join in default and specialized configurations.
Specifically, this section on <B
CLASS="APPLICATION"
>UM</B
> Late Join includes:
  </P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#LATE-JOIN-OVERVIEW"
><I
>Late Join Overview</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#LATE-JOIN-WITH-UMP"
><I
>Late Join With UMP</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#LATE-JOIN-OPTIONS-SUMMARY"
><I
>Late Join Options Summary</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#USING-LATE-JOIN-DEFAULTS"
><I
>Using Default Late Join Options</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#USING-LATE-JOIN-RANGE"
><I
>Specifying a Range of Messages 
	 to Retransmit</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#USING-LATE-JOIN-RECENT"
><I
>Retransmitting Only Recent Messages</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#USING-LATE-JOIN-LARGENUMBERS"
><I
>Configuring Late Join for 
	 Large Numbers of Messages</I
></A
>
		</P
></LI
></UL
><P
>	 See the <A
HREF="../Config/reference.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
> for specific
	 information about Late Join configuration options.
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
> If your application is running within a <B
CLASS="APPLICATION"
>UM</B
> context with configuration
	 option <A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPBINDREQUESTPORT"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>request_tcp_bind_request_port</TT
></A
> set to zero, then request port
	 binding has been turned off, which also disables the Late Join feature.
	 </P
></BLOCKQUOTE
></DIV
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
> The Late Join feature only works with the unicast topic resolution daemon 
	 (<TT
CLASS="LITERAL"
>lbmrd</TT
>) across local LANs that use Network Address Translation (NAT) 
	 if you use the default value (0.0.0.0) for 
	 <A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPINTERFACE"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>request_tcp_interface</TT
></A
>. 
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="LATE-JOIN-OVERVIEW"
>5.1.1. Late Join Overview</A
></H4
><P
>	 The Late Join feature enables newly created receivers to receive previously transmitted messages. 
	 Sources configured for Late Join maintain a retention buffer (not to be confused with a transport 
	 retransmission window), which holds transmitted messages for late-joining receivers.
	 </P
><P
>	  A Late Join operation follows the following sequence: 
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 A new receiver configured for Late Join with <A
HREF="../Config/latejoinoptions.html#RECEIVERUSELATEJOIN"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>use_late_join</TT
></A
> completes topic resolution. Topic advertisements from the source 
		 indicate that the source is configured for Late Join with <A
HREF="../Config/latejoinoptions.html#SOURCELATEJOIN"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>late_join</TT
></A
>.
	 </P
></LI
><LI
><P
>	 The new receiver sends a Late Join Initiation Request (LJIR) to request previously transmitted messages. 
	 The receiver configuration option, 
	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITREQUESTOUTSTANDINGMAXIMUM"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>retransmit_request_outstanding_maximum</TT
></A
>, 
	 determines the number of messages the receiver requests.		  
	 </P
></LI
><LI
><P
>	 The source responds with a Late Join Information (LJI) message containing the sequence numbers for 
	 the retained messages that are available for retransmission.
	 </P
></LI
><LI
><P
>	 The source unicasts the messages. 
	 </P
></LI
><LI
><P
>	 When <A
HREF="#USING-LATE-JOIN-LARGENUMBERS"
><I
>Configuring Late Join for 
	 Large Numbers of Messages</I
></A
>,
	 the receiver issues additional requests, and the
	 source retransmits these additional groups of older messages, oldest first.
	 </P
></LI
></OL
><DIV
CLASS="FIGURE"
><A
NAME="LATEJOINPATH"
></A
><P
><B
>Figure 11. Late Join Message Path</B
></P
><P
><IMG
SRC="LateJoin.png"
ALIGN="CENTER"></P
></DIV
><P
>	  The source's retention buffer's is not pre-allocated and occupies an increasing amount of memory 
	  as the source sends messages and adds them to the buffer. If a retention buffer grows to 
	  a size equal to the value of the source configuration option,
	 <A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONSIZETHRESHOLD"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>retransmit_retention_size_threshold</TT
></A
>, 
	 the source deletes older messages as it adds new ones. The source configuration option, 
	<A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONAGETHRESHOLD"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>retransmit_retention_age_threshold</TT
></A
>, controls message deletion based on message age.
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	  UM uses control-structure overhead memory on a per-message basis for messages held in the 
	  retention buffer, in addition to the retention buffer's memory. Such memory usage can become 
	  significantly higher when retained messages are smaller in size, since more of them can then fit in 
	  the retention buffer.
	 </P
></BLOCKQUOTE
></DIV
><DIV
CLASS="CAUTION"
><BLOCKQUOTE
CLASS="CAUTION"
><P
><B
>Caution</B
>	 If you set the receiver configuration option 
	 <A
HREF="../Config/majoroptions.html#RECEIVERORDEREDDELIVERY"
TARGET="_top"
><TT
CLASS="LITERAL"
>ordered_delivery</TT
></A
> 
	 to 1, the receiver must deliver messages to your application in sequence number order. 
	 The receiver holds out-of-order messages in an ordered list cache until messages arrive to fill the sequence number gaps. 
	 If an out-of-order message arrives with a sequence number that creates a message gap greater than the value of 
	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITMESSAGECACHINGPROXIMITY"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>retransmit_message_caching_proximity</TT
></A
>, the receiver creates a burst loss event and 
	 terminates the Late Join recovery operation. You can increase the value of the proximity option and restart 
	 the receiver, but a burst loss is a significant event and you should investigate your network and message 
	 system components for failures.
	 </P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="LATE-JOIN-WITH-UMP"
>5.1.2. Late Join With UMP</A
></H4
><P
>	 Late Join can be implemented in conjunction with <B
CLASS="APPLICATION"
>UMP</B
>'s persistent store feature, however in this 
	 configuration, it functions somewhat differently. After a Late-Join-enabled receiver has been 
	 created, resolved a topic, and become registered with a store, it may then request older messages. 
	 This request is handled by the store, which unicasts the retransmission messages. If the store 
	 does not have these messages, it requests them of the source (assuming option
	 <TT
CLASS="LITERAL"
>retransmission-request-forwarding</TT
> is enabled), thus initiating Late Join.
	 </P
><P
>	 Unlike with a persistent store, a source/topic using <B
CLASS="APPLICATION"
>UMQ</B
>'s queue feature will service Late Join 
	 requests in the same manner used by UMS.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="LATE-JOIN-OPTIONS-SUMMARY"
>5.1.3. Late Join Options Summary</A
></H4
><P
>	 Following is a summary of Late join configuration options. Please refer to
	 <A
HREF="../Config/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Configuration Guide</A
>
	 for full descriptions of these options.
	 </P
><DIV
CLASS="INFORMALTABLE"
><P
></P
><A
NAME="AEN1890"
></A
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL
WIDTH="144"><COL
WIDTH="384"><THEAD
><TR
><TH
>scope (object)</TH
><TH
>option</TH
></TR
></THEAD
><TBODY
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;		 <A
HREF="../Config/latejoinoptions.html#SOURCELATEJOIN"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>late_join</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONAGETHRESHOLD"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_retention_age_threshold</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONSIZELIMIT"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_retention_size_limit</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONSIZETHRESHOLD"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_retention_size_threshold</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#RECEIVERUSELATEJOIN"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>use_late_join</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITINITIALSEQUENCENUMBERREQUEST"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_initial_sequence_number_request</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITMESSAGECACHINGPROXIMITY"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_message_caching_proximity</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITREQUESTGENERATIONINTERVAL"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_request_generation_interval</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITREQUESTINTERVAL"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_request_interval</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITREQUESTMAXIMUM"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_request_maximum</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITREQUESTOUTSTANDINGMAXIMUM"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_request_outstanding_maximum</TT
></A
>
		 </TD
></TR
></TBODY
></TABLE
><P
></P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="USING-LATE-JOIN-DEFAULTS"
>5.1.4. Using Default Late Join Options</A
></H4
><P
>	 To implement Late Join with default options, set the Late Join configuration options to
	 activate the feature on both a source and receiver in the following manner.
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Create a configuration file with source and receiver Late Join activation options set
	 to 1. For example, file <TT
CLASS="LITERAL"
>cfg1.cfg</TT
> containing the two lines:
	 </P
><PRE
CLASS="SCREEN"
>	 source late_join 1
	 receiver use_late_join 1
	 </PRE
></LI
><LI
><P
>	 Run an application that starts a Late-Join-enabled source. For example:
	 </P
><PRE
CLASS="SCREEN"
>	 lbmsrc -c cfg1.cfg -P 1000 topicName
	 </PRE
></LI
><LI
><P
>	 Wait a few seconds, then run an application that starts a Late-Join-enabled receiver.
	 For example:
	 </P
><P
>	 <PRE
CLASS="SCREEN"
>	 lbmrcv -c cfg1.cfg -v topicName
	 </PRE
></P
></LI
></OL
><P
>	 The output for each should closely resemble the following.
		</P
><P
>	 LBMSRC
		</P
><PRE
CLASS="SCREEN"
>	 $ lbmsrc -c cfg1.cfg -P 1000 topicName
	 LOG Level 5: NOTICE: Source "topicName" has no retention settings (1 message retained max)
	 Sending 10000000 messages of size 25 bytes to topic [topicName]
	 Receiver connect [TCP:10.29.3.77:34200]
	 </PRE
><P
>	 LBMRCV
	 </P
><PRE
CLASS="SCREEN"
>	 $ lbmrcv -c cfg1.cfg -v topicName
	 Immediate messaging target: TCP:10.29.3.77:4391
	 [topicName][TCP:10.29.3.76:4371][2]-RX-, 25 bytes
	 1.001 secs. 0.0009988 Kmsgs/sec. 0.1998 Kbps
	 [topicName][TCP:10.29.3.76:4371][3], 25 bytes
	 1.002 secs. 0.0009982 Kmsgs/sec. 0.1996 Kbps
	 [topicName][TCP:10.29.3.76:4371][4], 25 bytes
	 1.003 secs. 0.0009972 Kmsgs/sec. 0.1994 Kbps
	 [topicName][TCP:10.29.3.76:4371][5], 25 bytes
	 1.003 secs. 0.0009972 Kmsgs/sec. 0.1994 Kbps
	 </PRE
><P
>	 Note that the source only retained 1 Late Join message (due to default retention
	 settings) and that this message appears as a retransmit (<TT
CLASS="LITERAL"
>-RX-</TT
>). Also note that it is
	 possible to sometimes receive 2 RX messages in this scenario (see
	 <A
HREF="#USING-LATE-JOIN-RECENT"
><I
>Retransmitting Only Recent Messages</I
></A
>.)
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="USING-LATE-JOIN-RANGE"
>5.1.5. Specifying a Range of Messages 
	 to Retransmit</A
></H4
><P
>	 To receive more than one or two Late Join messages, increase the source's
	 retransmit_retention_size_threshold from its default value of 0. Once this threshold is
	 exceeded, the source now allows the next new message entering the retention buffer to
	 bump out the oldest one. Note that this threshold's units are bytes (which includes a
	 small overhead per message).
	 </P
><P
>	 While the retention threshold endeavors to keep the buffer size close to its value, it
	 does not set hard upper limit for retention buffer size. For this, the
	 retransmit_retention_size_limit configuration option (also in bytes) sets this
	 boundary.
	 </P
><P
>	 Follow the steps below to demonstrate how a source can retain about 50MB of messages,
	 but no more than 60MB:
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Create a second configuration file (<TT
CLASS="LITERAL"
>cfg2.cfg</TT
>) with the following options:
	 </P
><PRE
CLASS="SCREEN"
>	 source late_join 1
	 source retransmit_retention_size_threshold 50000000
	 source retransmit_retention_size_limit 60000000
	 receiver use_late_join 1</PRE
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmsrc -c cfg2.cfg -P 1000 topicName</TT
>.
	 </P
></LI
><LI
><P
>	 Wait a few seconds and run <TT
CLASS="LITERAL"
>lbmrcv -c cfg2.cfg -v topicName</TT
>.
	 </P
></LI
></OL
><P
>	 The output for each should closely resemble the following.
	 </P
><P
>	 LBMSRC
	 </P
><PRE
CLASS="SCREEN"
>	 $ lbmsrc -c cfg2.cfg -P 1000 topicName
	 Sending 10000000 messages of size 25 bytes to topic [topicName]
	 Receiver connect [TCP:10.29.3.76:34444]
	 </PRE
><P
>	 LBMRCV
	 </P
><PRE
CLASS="SCREEN"
>	 $ lbmrcv -c cfg2.cfg -v topicName
	 Immediate messaging target: TCP:10.29.3.76:4391
	 [topicName][TCP:10.29.3.77:4371][0]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][1]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][2]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][3]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][4]-RX-, 25 bytes
	 1.002 secs. 0.004991 Kmsgs/sec. 0.9981 Kbps
	 [topicName][TCP:10.29.3.77:4371][5], 25 bytes
	 1.002 secs. 0.0009984 Kmsgs/sec. 0.1997 Kbps
	 [topicName][TCP:10.29.3.77:4371][6], 25 bytes
	 1.002 secs. 0.0009983 Kmsgs/sec. 0.1997 Kbps
	 [topicName][TCP:10.29.3.77:4371][7], 25 bytes
	 </PRE
><P
>	 Note that lbmrcv received live messages with sequence numbers 7, 6, and 5, and RX
	 messages going from 4 all the way back to Sequence Number 0. 
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="USING-LATE-JOIN-RECENT"
>5.1.6. Retransmitting Only Recent Messages</A
></H4
><P
>	 Thus far we have worked with only source late join settings, but suppose that you want
	 to receive only the last 10 messages. To do this, configure the receiver option
	 retransmit_request_maximum option to set how many messages to request backwards from
	 the latest message.
		</P
><P
>	 Follow the steps below to demonstrate setting this option to 10. 
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Add the following line to <TT
CLASS="LITERAL"
>cfg2.cfg</TT
> and rename it <TT
CLASS="LITERAL"
>cfg3.cfg</TT
>.
	 </P
><PRE
CLASS="PROGRAMLISTING"
>receiver retransmit_request_maximum 10</PRE
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmsrc -c cfg3.cfg -P 1000 topicName</TT
>.
	 </P
></LI
><LI
><P
>	 Wait a few seconds and run <TT
CLASS="LITERAL"
>lbmrcv -c cfg3.cfg -v topicName</TT
>.
	 </P
></LI
></OL
><P
>	 The output for each should closely resemble the following.
	 </P
><P
>	 LBMSRC
	 </P
><PRE
CLASS="SCREEN"
>	 $ lbmsrc -c cfg3.cfg -P 1000 topicName
	 Sending 10000000 messages of size 25 bytes to topic [topicName]
	 Receiver connect [TCP:10.29.3.76:34448]
	 </PRE
><P
>	 LBMRCV
	 </P
><PRE
CLASS="SCREEN"
>	 $ lbmrcv -c cfg3.cfg -v topicName
	 Immediate messaging target: TCP:10.29.3.76:4391
	 [topicName][TCP:10.29.3.77:4371][13]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][14]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][15]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][16]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][17]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][18]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][19]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][20]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][21]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][22]-RX-, 25 bytes
	 [topicName][TCP:10.29.3.77:4371][23]-RX-, 25 bytes
	 1.002 secs. 0.01097 Kmsgs/sec. 2.195 Kbps
	 [topicName][TCP:10.29.3.77:4371][24], 25 bytes
	 1.002 secs. 0.0009984 Kmsgs/sec. 0.1997 Kbps
	 [topicName][TCP:10.29.3.77:4371][25], 25 bytes
	 1.002 secs. 0.0009984 Kmsgs/sec. 0.1997 Kbps
	 [topicName][TCP:10.29.3.77:4371][26], 25 bytes
	 </PRE
><P
>	 Note that 11, not 10, retransmits were actually received. This can happen because
	 network and timing circumstances may have one RX already in transit while the specific
	 RX amount is being processed. (Hence, please note that it is not possible to guarantee
	 one and only one RX message for every possible Late Join recovery.)
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="USING-LATE-JOIN-LARGENUMBERS"
>5.1.7. Configuring Late Join for 
	 Large Numbers of Messages</A
></H4
><P
>	 Suppose you have a receiver that comes up at midday and must gracefully catch up on 
	 the large number of messages it has missed. The following discussion explains the 
	 relevant Late Join options and how to use them.
		</P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RETRANSMIT-REQUEST-GENERATION-INTERVAL"
>5.1.7.1. retransmit_request_generation_interval (receiver)</A
></H5
><P
>	  This option sets the maximum interval (default 10,000ms) between when a receiver first
	  sends a retransmission request and when the receiver gives up on receiving any more
	  RXs (if any at all were received). The receiver then delivers received RXs, and
	  commences delivering live messages.
	  </P
><P
>	  For requested messages not received, the receiver generates either an individual
	  message loss report, or, if receiver option delivery_control_maximum_burst_loss is
	  exceeded, a burst loss report.
	  </P
><P
>	  Set this option high enough so that all requested Late Join messages can be
	  retransmitted to the receiver. Although the default 10-second value works in many
	  situations, extremely high volumes of Late Join messages may require more time.
	  </P
><P
>	  As an alternative, you can set this option to the longest expected Late Join recovery
	  time. To estimate Late Join recovery time, see
	 <A
HREF="../Config/latejoinoptions.html#ESTIMATINGRECOVERYTIME"
TARGET="_top"
>Estimating
	 Recovery Time</A
> in the Configuration Guide.
	  </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RETRANSMIT-REQUEST-OUTSTANDING-MAXIMUM"
>5.1.7.2. retransmit_request_outstanding_maximum (receiver)</A
></H5
><P
>	 When a receiver comes up and begins requesting Late Join messages, it does not simply
	 request messages starting at Sequence Number 0 through 1000000. Rather, it requests the
	 messages a little at a time, depending upon 
	 <A
HREF="../Config/latejoinoptions.html#RECEIVERRETRANSMITREQUESTOUTSTANDINGMAXIMUM"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>retransmit_request_outstanding_maximum</TT
></A
>. 
	 For example, when set to the default of 200, the receiver requests the first 200
	 messages (Sequence Number 0 - 199). Upon receiving Sequence Number 0, it then requests
	 the next grouping, starting at Sequence Number 200, and so on.
	 </P
><P
>	 Note that in some environments, the default of 200 messages may be too high and
	 overwhelm receivers with RXs, which can cause loss in a live LBT-RM stream. However,
	 higher values can also increase the rate of RXs received.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RETRANSMIT-MESSAGE-CACHING-PROXIMITY"
>5.1.7.3. retransmit_message_caching_proximity (receiver)</A
></H5
><P
>	 Long recoveries of active sources can create memory cache problems due to the
	 processing of both new and retransmitted messages. This option provides a method to
	 control caching and cache size during recovery.
	 </P
><P
>	 It does this by comparing the option value (default 2147483647) to the difference
	 between the newest (live) received sequence number and the latest received RX sequence
	 number. If the difference is less than the option's value incoming live new messages
	 are cached. Otherwise, new messages are dropped and not cached (they can be requested
	 later as retransmissions). 
	 </P
><P
>	 The default value of retransmit_message_caching_proximity encourages caching and should
	 be optimal for most receivers.
	 </P
><P
>	 If your source sends faster than it retransmits, caching is beneficial, as it ensures
	 new data is received only once, thus reducing recovery time. If the source retransmits
	 faster than it sends, which is the optimal condition, you can lower the value of this
	 option to use less memory during recovery, with little performance impact. 
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RETRANSMIT-MESSAGE-MAP-TABLESZ"
>5.1.7.4. retransmit_message_map_tablesz (source)</A
></H5
><P
><B
CLASS="APPLICATION"
>This option has been deprecated.</B
></P
><P
>	This option specifies the size of the hash table the source uses to store Late Join
	messages.
	</P
><P
></P
><UL
><LI
><P
>		A larger table can store more messages more efficiently, but takes up more memory. 
		</P
></LI
><LI
><P
>		A smaller table uses less memory, but costs more CPU time as more messages are retained.
		</P
></LI
></UL
><P
>	 For example, if the table size is left at its default of 131, bringing up a receiver 
	 requesting 1 million Late Join messages can take over 5 minutes. If you increase the 
	 table size to 131113, the receiver will need only 8 seconds to become fully caught up.
	</P
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="OTR"
>5.2. Off-Transport Recovery (OTR)</A
></H3
><P
>  Off-Transport Recovery (OTR) is a lost-message-recovery feature that provides a level of hedging against the
  possibility of brief and incidental unrecoverable loss at the transport level or from a gateway. This section
  describes the OTR feature.
  </P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="OTR-OVERVIEW"
>5.2.1. OTR Overview</A
></H4
><P
>	 When a transport cannot recover lost messages, OTR
	 engages and looks to the source for message recovery. It does this by accessing the source's retention buffer
	 (used also by the Late Join feature) to re-request messages that no longer exist in a transport's transmission window
	 or other places such as a <B
CLASS="APPLICATION"
>UMP</B
> store or redundant source.
	 </P
><P
>	 OTR functions in a manner very similar to that of Late Join, but differs mainly in that it activates in message loss
	 situations rather than following the creation of a receiver, and shares only the source <A
HREF="../Config/latejoinoptions.html#SOURCELATEJOIN"
TARGET="_top"
><TT
CLASS="LITERAL"
>late_join</TT
></A
> option setting.
	 </P
><P
>	 Upon detecting loss, a receiver using TCP, TCP-LB, LBT-IPC or LBT-RDMA initiates OTR by sending repeated, 
	 spaced, OTR requests to the source, until it recovers lost messages or a timeout period elapses. 
	 </P
><P
>	 OTR operates independently from transport-level recovery mechanisms such as NAKs for LBT-RU or LBT-RM. 
	 When you enable OTR for a receiver with <A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVERUSEOTR"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>use_otr</TT
></A
>, the <A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTINITIALDELAY"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>otr_request_initial_delay</TT
></A
> starts as soon as the delivery controller detects a sequence 
	gap. OTR recovery initiates if the gap is not resolved by the end of the delay interval. 
	OTR recovery can occur before, during or after transport-level recovery attempts.
		</P
><P
>	 When a receiver initiates OTR, the intervals between OTR requests increases twofold after each request, until
	 the maximum interval is reached (assuming the receiver is still waiting to receive the retransmission). You use
	 configuration options <A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTMINIMUMINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>otr_request_minimum_interval</TT
></A
> and <A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTMAXIMUMINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>otr_request_maximum_interval</TT
></A
>to set the initial (minimum) and maximum intervals,
	 respectively.
	</P
><P
>	The source retransmits lost messages to the recovered receiver via unicast.
	</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="OTR-WITH-UMP"
>5.2.2. OTR With UMP</A
></H4
><P
>	 You can implement OTR in conjunction with <B
CLASS="APPLICATION"
>UMP</B
>'s persistent store feature, however in this configuration, it
	 functions somewhat differently. If an OTR-enabled receiver registered with a store 
	 detects a sequence gap in the live stream and that gap is not resolved by other means within the next 
	 <A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTINITIALDELAY"
TARGET="_top"
>	<TT
CLASS="LITERAL"
>otr_request_initial_delay</TT
></A
>, the receiver requests those messages from the store(s). 
	If the store does not have some of the requested messages, they will be requested from the source. 
	Regardless of whether the messages are recovered from a store or from the source, OTR delivers all recovered 
	messages the LBM_MSG_OTR flag, unlike Late Join, which uses the LBM_MSG_RETRANSMIT flag.
	 </P
><P
>	 Unlike with a persistent store, a source/topic using <B
CLASS="APPLICATION"
>UMQ</B
>'s queue feature services OTR 
	 requests in the same manner used by <B
CLASS="APPLICATION"
>UMS</B
>.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="OTR-OPTIONS-SUMMARY"
>5.2.3. OTR Options Summary</A
></H4
><P
>	 The following set of configuration options govern OTR functionality.
	 Please refer to the <A
HREF="../Config/config.html"
TARGET="_top"
>Ultra Messaging Configuration Guide</A
> 
	 for full descriptions of these options. You can click the individual links below for each option's description.
	 </P
><DIV
CLASS="INFORMALTABLE"
><P
></P
><A
NAME="AEN2089"
></A
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL
WIDTH="144"><COL
WIDTH="384"><THEAD
><TR
><TH
>scope (object)</TH
><TH
>option</TH
></TR
></THEAD
><TBODY
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/latejoinoptions.html#SOURCELATEJOIN"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>late_join</TT
></A
>
		</TD
></TR
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONAGETHRESHOLD"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_retention_age_threshold</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONSIZELIMIT"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_retention_size_limit</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; source</TD
><TD
>&nbsp;&#13;	 	 <A
HREF="../Config/latejoinoptions.html#SOURCERETRANSMITRETENTIONSIZETHRESHOLD"
TARGET="_top"
>		 <TT
CLASS="LITERAL"
>retransmit_retention_size_threshold</TT
></A
>
		 </TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVERUSEOTR"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>use_otr</TT
></A
>
		</TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTDURATION"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>otr_request_duration</TT
></A
>
		</TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTINITIALDELAY"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>otr_request_initial_delay</TT
></A
>
		</TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTLOGALERTCOOLDOWN"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>otr_request_log_alert_cooldown</TT
></A
>
		</TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTMAXIMUMINTERVAL"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>otr_request_maximum_interval</TT
></A
>
		</TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTMINIMUMINTERVAL"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>otr_request_minimum_interval</TT
></A
>
		</TD
></TR
><TR
><TD
>&nbsp; receiver</TD
><TD
>&nbsp;&#13;		<A
HREF="../Config/off-transportrecoveryoptions.html#RECEIVEROTRREQUESTOUTSTANDINGMAXIMUM"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>otr_request_outstanding_maximum</TT
></A
>
		</TD
></TR
></TBODY
></TABLE
><P
></P
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="REQUEST-RESPONSE-MESSAGES"
>5.3. Request/Response Model</A
></H3
><P
>  This section discusses the following topics.  
	 </P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#REQ-RESP-REQUEST-MESSAGE"
><I
>Request Message</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#REQ-RESP-RESPONSE-MESSAGE"
><I
>Response Message</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#REQ-RESP-TCP-MANAGEMENT"
><I
>TCP Management</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#REQ-RESP-CONFIGURATION"
><I
>Configuration</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#REQ-RESP-EXAMPLE-APPLICATIONS"
><I
>Example Applications</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="REQ-RESP-REQUEST-MESSAGE"
>5.3.1. Request Message</A
></H4
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> provides three ways to send a request message.
		</P
><P
></P
><UL
><LI
><P
>	 <TT
CLASS="LITERAL"
>lbm_send_request()</TT
> to send a request to a topic via a 
	 source object.  Uses the standard source-based transports (TCP, LBT-RM, LBT-RU).
		</P
></LI
><LI
><P
>	 <TT
CLASS="LITERAL"
>lbm_multicast_immediate_request()</TT
> to send a request to a 
	 topic as a multicast immediate message. See 
	 <A
HREF="#MULTICAST-IMMEDIATE-MESSAGING"
><I
>Multicast Immediate Messaging</I
></A
>.
		</P
></LI
><LI
><P
>	 <TT
CLASS="LITERAL"
>lbm_unicast_immediate_request()</TT
> to send a request to a 
	 topic as a unicast immediate message. See 
	 <A
HREF="#MULTICAST-IMMEDIATE-MESSAGING"
><I
>Multicast Immediate Messaging</I
></A
>. 
		</P
></LI
></UL
><P
>	 The request function returns a request object and defines an application 
	 callback for responses that allows the receiving application to send a response 
	 directly to the requesting application via a special TCP connection instead of a 
	 normal data transport. The requesting application -- not <B
CLASS="APPLICATION"
>UM</B
> -- determines 
	 how many responses it needs. Therefore, it must delete the request object when 
	 it no longer wants to receive responses by calling 
	 <TT
CLASS="LITERAL"
>lbm_request_delete()</TT
>. It discards any responses that arrive 
	 after the request object has been deleted.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="REQ-RESP-RESPONSE-MESSAGE"
>5.3.2. Response Message</A
></H4
><P
>	 An application responds to an <B
CLASS="APPLICATION"
>UM</B
> request message by calling 
	 <TT
CLASS="LITERAL"
>lbm_send_response()</TT
>. Contained within that request 
	 message's header is a response object, which serves as a return address 
	 to the requester. <B
CLASS="APPLICATION"
>UM</B
> passes the response object to 
	 <TT
CLASS="LITERAL"
>lbm_send_response()</TT
>. Since the response object is part of 
	 the message header, it is deleted at the same time that the message is 
	 deleted.  Therefore, if the sending of the response cannot be done 
	 within the responder's receive callback, the message must be retained 
	 and subsequently deleted.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="REQ-RESP-TCP-MANAGEMENT"
>5.3.3. TCP Management</A
></H4
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> creates and manages the special TCP connections for responses, 
	 maintaining  a list of active response connections . When an application 
	 sends a response, <B
CLASS="APPLICATION"
>UM</B
> scans that list for an active connection to the 
	 destination. If it doesn't find a connection for the response, it creates 
	 a new connection and adds it to the list. After the 
	 <TT
CLASS="LITERAL"
>lbm_send_response()</TT
> function returns, <B
CLASS="APPLICATION"
>UM</B
> schedules 
	 the <TT
CLASS="LITERAL"
>response_tcp_deletion_timeout</TT
>, which defaults to 2 
	 seconds. If a second request comes in from the same application before 
	 the timer expires, the responding application simply uses the existing 
	 connection and restarts the deletion timer. 
		</P
><P
>	 It is conceivable that a very large response could take more than the 
	 <TT
CLASS="LITERAL"
>response_tcp_deletion_timeout</TT
> default (2 seconds) to 
	 send to a slow-running receiver. In this case, <B
CLASS="APPLICATION"
>UM</B
> automatically increases 
	 the deletion timer as needed to ensure the last message completes.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="REQ-RESP-CONFIGURATION"
>5.3.4. Configuration</A
></H4
><P
>	 See the <B
CLASS="APPLICATION"
>UM</B
> Configuration Guide for the descriptions of the 
	 Request/Response configuration options.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../Config/requestnetworkoptions.html"
TARGET="_top"
>Request Network Options</A
>
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/requestoperationoptions.html"
TARGET="_top"
>Request Operations Options</A
>  
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/responseoperationoptions.html"
TARGET="_top"
>Response Operation Options</A
>  
		</P
></LI
></UL
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
> If your application is running within an <B
CLASS="APPLICATION"
>UM</B
> context where the configuration
	 option, 
	 <A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPBINDREQUESTPORT"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>request_tcp_bind_request_port</TT
></A
> has been set to zero, request port
	 binding has been turned off, which also disables the Request/Response feature.
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
> The Request/Response model only works with the unicast topic resolution daemon 
	 (<TT
CLASS="LITERAL"
>lbmrd</TT
>) across local LANs that use Network Address Translation (NAT) 
	 if you use the default value (0.0.0.0) for 
	 <A
HREF="../Config/requestnetworkoptions.html#CONTEXTREQUESTTCPINTERFACE"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>request_tcp_interface</TT
></A
>. 
		</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="REQ-RESP-EXAMPLE-APPLICATIONS"
>5.3.5. Example Applications</A
></H4
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> includes two example applications that illustrate Request/Response.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../example/lbmreq.c"
TARGET="_top"
>lbmreq.c</A
> - application that 
	 sends requests on a given topic (single source) and waits for responses. 
	 See also the Java example, <A
HREF="../java_example/lbmreq.java"
TARGET="_top"
>lbmreq.java</A
>, 
	 and the .NET example, <A
HREF="../dotnet_example/lbmreq.cs"
TARGET="_top"
>lbmreq.cs</A
>.
		</P
></LI
><LI
><P
>	 <A
HREF="../example/lbmresp.c"
TARGET="_top"
>lbmresp.c</A
> - application that waits 
	 for requests and sends responses back on a given topic (single receiver). 
	 See also the Java example, <A
HREF="../java_example/lbmresp.java"
TARGET="_top"
>lbmresp.java</A
>, 
	 and the .NET example, <A
HREF="../dotnet_example/lbmresp.cs"
TARGET="_top"
>lbmresp.cs</A
>.  
		</P
></LI
></UL
><P
>	 We can demonstrate a series of 5 requests and responses with the following procedure.
		</P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmresp -v topicname</TT
>
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmreq -R 5 -v topicname</TT
>  
		</P
></LI
></OL
><P
>	 <B
CLASS="APPLICATION"
>LBMREQ</B
>
		</P
><P
>	 Output for <B
CLASS="APPLICATION"
>lbmreq</B
> should resemble the following.
		</P
><PRE
CLASS="SCREEN"
>$ lbmreq -R 5 -q topicname
Event queue in use
Using TCP port 4392 for responses
Delaying requests for 1000 milliseconds
Sending request 0
Starting event pump for 5 seconds.
Receiver connect [TCP:10.29.1.78:4958]
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 1
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 2
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 3
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request. Sending request 4
Starting event pump for 5 seconds.
Done waiting for responses. 1 responses (25 bytes) received. Deleting request.
Quitting...
		</PRE
><P
>	 <B
CLASS="APPLICATION"
>LBMRESP</B
>
		</P
><P
>	 Output for <B
CLASS="APPLICATION"
>lbmresp</B
> should resemble the following.
		</P
><PRE
CLASS="SCREEN"
>$ lbmresp -v topicname
Request [topicname][TCP:10.29.1.78:14371][0], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][1], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][2], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][3], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
Request [topicname][TCP:10.29.1.78:14371][4], 25 bytes
Sending response. 1 responses of 25 bytes each (25 total bytes).
Done sending responses. Deleting response.
[topicname][TCP:10.29.1.78:14371], End of Transport Session
		</PRE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="SELF-DESCRIBING-MESSAGING"
>5.4. Self Describing Messaging</A
></H3
><P
>  The <B
CLASS="APPLICATION"
>UM</B
> Self-Describing Messaging (SDM) feature provides an API that simplifies the creation 
  and use of messages by your applications. An SDM message contains one or more fields and each 
  field consists of the following.
	 </P
><P
></P
><UL
><LI
><P
>	 A name
	  </P
></LI
><LI
><P
>	 A type
		</P
></LI
><LI
><P
>	 A value
		</P
></LI
></UL
><P
>	 Each named field may appear only once in a message. If multiple fields of the same name and 
	 type are needed, array fields are available. A field in a nested message may have the same name 
	 as a field in the outer message.
		</P
><P
>	 SDM is particularly helpful for creating messages sent across platforms by simplifying the 
	 creation of data formats. SDM automatically performs platform-specific data translations, 
	 eliminating Endianess conflicts.
		</P
><P
>	 Using SDM also simplifies message maintenance because the message format or structure can be 
	 independent of the source and receiver applications. For example, if your receivers query SDM 
	 messages for particular fields and ignore the order of the fields within the message, a source 
	 can change the field order if necessary with no modification of the receivers needed.
		</P
><P
>	 Use the following links to access a complete reference of SDM functions, field types and 
	 message field operations.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../API/index.html"
TARGET="_top"
>C Application Programmer's Interface</A
> 
	 -- click on the Files tab at the top and select <TT
CLASS="LITERAL"
>lbmsdm.h</TT
>.
	  </P
></LI
><LI
><P
>	 <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>Java Application Programmer's Interface</A
> 
	 -- select <TT
CLASS="LITERAL"
>com.latencybusters.lbm.sdm</TT
> under Packages.
		</P
></LI
><LI
><P
>	 <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
>.NET Application Programmer's Interface</A
> 
	 -- select the <TT
CLASS="LITERAL"
>com.latencybusters.lbm.sdm</TT
> Namespace.
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="PRE-DEFINED-MESSAGING"
>5.5. Pre-Defined Messaging</A
></H3
><P
>  The <B
CLASS="APPLICATION"
>UM</B
> Pre-Defined Messaging (PDM) feature provides an API similar to the SDM API,
  but allows you to define messages once and then use the definition to create messages that 
  may contain self-describing data. Eliminating the need to repeatedly send a message definition 
  increases the speed of PDM over SDM. The ability to use arrays created in a different 
  programming language also improves performance.
  </P
><P
>  The PDM library lets you create, serialize, and deserialize messages using pre-defined
  knowledge about the possible fields that may be used. You can create a definition that
  a) describes the fields to be sent and received in a message, b) creates the corresponding message,
  and c) adds field values to the message. This approach offers several performance advantages
  over SDM,
  as the definition is known in advance. However, the usage pattern is slightly different than the
  SDM library, where fields are added directly to a message without any type of definition.
  </P
><P
>  A PDM message contains one or more fields and 
  each field consists of the following.
  </P
><P
></P
><UL
><LI
><P
>	 A name
	 </P
></LI
><LI
><P
>	 A type
	 </P
></LI
><LI
><P
>	 A value
	 </P
></LI
></UL
><P
>  Each named field may appear only once in a message. If multiple fields of the same name and 
  type are needed, array fields are available. A field in a nested message may have the same name 
  as a field in the outer message.
  </P
><P
>  See the C, Java, and .NET Application Programmer's Interfaces for complete references
  of PDM functions, field types and 
  message field operations. The C API also has information and code samples about how to create 
  definitions and messages, set field values in a message, set the value of array fields in 
  a message, serialize, deserialize and dispose of messages, and fetch values from a message.
  See the following API documentation:
  </P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../API/index.html"
TARGET="_top"
>C Application Programmer's Interface</A
> 
	 -- click on the Files tab at the top and select <TT
CLASS="LITERAL"
>lbmpdm.h</TT
>.
	 </P
></LI
><LI
><P
>	 <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>Java Application Programmer's Interface</A
> 
	 -- select <TT
CLASS="LITERAL"
>com.latencybusters.lbm.pdm</TT
> under Packages.
	 </P
></LI
><LI
><P
>	 <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
>.NET Application Programmer's Interface</A
> 
	 -- select the <TT
CLASS="LITERAL"
>com.latencybusters.lbm.pdm</TT
> Namespace.
	 </P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="PDM-USE"
>5.5.1. Typical PDM Usage Patterns</A
></H4
><P
>    The typical PDM usage patterns can usually be broken down into two categories: sources
    (which need to serialize a message for sending) and receivers (which need to
    deserialize a message to extract field values). However, for optimum performance for both sources
    and receivers, first set up the definition and a
    single instance of the message only once during a setup or initialization phase, as in the following
    example workflow:
    </P
><P
></P
><OL
TYPE="1"
><LI
><P
>    Create a definition and set its id and version.
    </P
></LI
><LI
><P
>    Add field information to the definition to describe the types of fields to be in
    the message.
    </P
></LI
><LI
><P
>    Create a single instance of a message based on the definition.
    </P
></LI
></OL
><P
>Set up a source to do the following:</P
><P
></P
><OL
TYPE="1"
><LI
><P
>    Add field values to the message instance.
    </P
></LI
><LI
><P
>    Serialize the message so that it can be sent.
    </P
></LI
></OL
><P
>Likewise, set up a receiver to do the following:</P
><P
></P
><OL
TYPE="1"
><LI
><P
>    Deserialize the received bytes into the message instance.
    </P
></LI
><LI
><P
>    Extract the field values from the message.
    </P
></LI
></OL
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="GETTING-STARTED"
>5.5.2. Getting Started</A
></H4
><P
>    PDM APIs are provided in C, Java, and C#, however, the examples in this section are 
    Java based.
    </P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="PDM-EXAMPLE-SOURCE"
>5.5.2.1. PDM Code Example, Source</A
></H5
><P
>    Translating the Typical PDM Usage Patterns to Java for a source produces the following:
    </P
><PRE
CLASS="SCREEN"
>private PDMDefinition defn;
private PDMMessage msg;
private PDMFieldInfo fldInfo100;
private PDMFieldInfo fldInfo101;
private PDMFieldInfo fldInfo102;

public void setupPDM() {
	//Create the definition with 3 fields and using int field names
	defn = new PDMDefinition(3, true);
	
	//Set the definition id and version
	defn.setId(1001);
	defn.setMsgVersMajor((byte)1);
	defn.setMsgVersMinor((byte)0);
	
	//Create information for a boolean, int32, and float fields (all required)
	fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
	fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
	fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
	
	//Finalize the definition and create the message
	defn.finalizeDef();
	msg = new PDMMessage(defn);
}

public void sourceUsePDM() {
	//Call the function to setup the definition and message
	setupPDM();
	
	//Example values for the message
	boolean fld100Val = true;
	int fld101Val = 7;
	float fld102Val = 3.14F;
	
	//Set each field value in the message
	msg.setFieldValue(fldInfo100, fld100Val);
	msg.setFieldValue(fldInfo101, fld101Val);
	msg.setFieldValue(fldInfo102, fld102Val);
	
	//Serialize the message to bytes
	byte[] buffer = msg.toBytes();
}
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="PDM-EXAMPLE-RECEIVER"
>5.5.2.2. PDM Code Example, Receiver</A
></H5
><P
>    Translating the Typical PDM Usage Patterns to Java for a receiver produces the following:
    </P
><PRE
CLASS="SCREEN"
>private PDMDefinition defn;
private PDMMessage msg;
private PDMFieldInfo fldInfo100;
private PDMFieldInfo fldInfo101;
private PDMFieldInfo fldInfo102;

public void setupPDM() {
	//Create the definition with 3 fields and using int field names
	defn = new PDMDefinition(3, true);
	
	//Set the definition id and version
	defn.setId(1001);
	defn.setMsgVersMajor((byte)1);
	defn.setMsgVersMinor((byte)0);
	
	//Create information for a boolean, int32, and float field (all required)
	fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
	fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
	fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
	
	//Finalize the definition and create the message
	defn.finalizeDef();
	msg = new PDMMessage(defn);
}

public void receiverUsePDM(byte[] buffer) {
	//Call the function to setup the definition and message
	setupPDM();
	
	//Values to be retrieved from the message
	boolean fld100Val;
	int fld101Val;
	float fld102Val;
	
	//Deserialize the bytes into a message
	msg.parse(buffer);
	
	//Get each field value from the message
	fld100Val = msg.getFieldValueAsBoolean(fldInfo100);
	fld101Val = msg.getFieldValueAsInt32(fldInfo101);
	fld102Val = msg.getFieldValueAsFloat(fldInfo102);
}
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="PDM-EXAMPLE-NOTES"
>5.5.2.3. PDM Code Example Notes</A
></H5
><P
>    In the examples above, the setupPDM() function is called once to set up the PDM definition
    and message. It is identical in both the source and receiver cases and simply sets up a
    definition that contains three required fields with integer names (100, 101, 102). Once
    finalized, it can create a message that leverages its pre-defined
    knowledge about these three required fields. The source example adds the three sample
    field values (a boolean, int32, and float) to the message, which is then
    serialized to a byte array. In the receiver example, the message parses a byte array into
    the message and then extracts the three field values.
    </P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="USING-PDM-API"
>5.5.3. Using the PDM API</A
></H4
><P
>    The following code snippets expand upon the previous examples to demonstrate the usage
    of additional PDM functionality (but use "..." to eliminate redundant code).
    </P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="REUSE-MESSAGE-OBJECT"
>5.5.3.1. Reusing the Message Object</A
></H5
><P
>    Although the examples use a single message object (which provides performance benefits due
    to reduced message creation and garbage collection), it is not explicitly
    required to reuse a single instance. However, multiple threads should not
    access a single message instance.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="NUMBER-OF-FIELDS"
>5.5.3.2. Number of Fields</A
></H5
><P
>    Although the number of fields above is initially set to 3 in the PDMDefinition constructor,
    if you add more fields to the definition with the addFieldInfo method, the
    definition grows to accommodate each field. Once the definition is finalized, you cannot add
    additional field information because the definition is now locked and ready for use
    in a message.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="STRING-FIELD-NAMES"
>5.5.3.3. String Field Names</A
></H5
><P
>    The examples above use integer field names in the setupPDM() function when creating the
    definition. You can also use string field names when setting up the definition. However, you
    still must use a FieldInfo object to set or get a field value from a message, regardless of
    field name type. Notice that false is passed to the PDMDefinition constructor
    to indicate string field names should be used. Also, the overloaded addFieldInfo function
    uses string field names (.Field100.) instead of the integer field names. 
    </P
><PRE
CLASS="SCREEN"
>...
public void setupPDM() {
	//Create the definition with 3 fields and using string field names
	defn = new PDMDefinition(3, false);
	...
	//Create information for a boolean, int32, and float field (all required)
fldInfo100 = defn.addFieldInfo("Field100", PDMFieldType.BOOLEAN, true);
	fldInfo101 = defn.addFieldInfo("Field101", PDMFieldType.INT32, true);
	fldInfo102 = defn.addFieldInfo("Field102", PDMFieldType.FLOAT, true);
	...
}
...
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RETRIEVE-FIELDINFO"
>5.5.3.4. Retrieving FieldInfo from the Definition</A
></H5
><P
>    At times, it may be easier to lookup the FieldInfo from the definition using the integer
    name (or string name if used). This eliminates the need to
    store the reference to the FieldInfo when getting or setting a field value in a message, but
    it does incur a performance penalty due to the lookup in the definition to retrieve the
    FieldInfo. Notice that there are no longer FieldInfo objects being used when calling
    addFieldInfo and a lookup is being done for each call to msg.getFieldValueAs* to retrieve
    the FieldInfo by integer name.
    </P
><PRE
CLASS="SCREEN"
>private PDMDefinition defn;
private PDMMessage msg;

public void setupPDM() {
	...
	//Create information for a boolean, int32, and float field (all required)
	defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
	defn.addFieldInfo(101, PDMFieldType.INT32, true);
	defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
	...
}

public void receiverUsePDM(byte[] buffer) {
	...	
	//Get each field value from the message
	fld100Val = msg.getFieldValueAsBoolean(defn.getFieldInfo(100));
	fld101Val = msg.getFieldValueAsInt32(defn.getFieldInfo(101));
	fld102Val = msg.getFieldValueAsFloat(defn.getFieldInfo(102));
}</PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="REQUIRED-OPTIONAL-FIELDS"
>5.5.3.5. Required and Optional Fields</A
></H5
><P
>    When adding field information to a definition, you can indicate that the field is
    optional and may not be set for every message that uses the definition. Do this by
    passing false as the third parameter to the addFieldInfo function. Using required fields
    (fixed-required fields specifically) produces the best performance when serializing and
    deserializing messages, but causes an exception if all required fields are not set
    before serializing the message. Optional fields allow the concept of sending "null" as a
    value for a field by simply not setting that field value on the source side before
    serializing the message. However, after parsing a message, a receiver should check the
    isFieldValueSet function for an optional field before attempting to read the value from the
    field to avoid the exception mentioned above.
    </P
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo103;
...
public void setupPDM() {
	...
//Create information for a boolean, int32, and float field (all required)
	// as well as an optional int8 field
fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
	fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
	fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
	fldInfo103 = defn.addFieldInfo(103, PDMFieldType.INT8, false);
	...
}

public void sourceUsePDM() {
	...
	//Set each field value in the message
	// except do not set the optional field
	msg.setFieldValue(fldInfo100, fld100Val);
	msg.setFieldValue(fldInfo101, fld101Val);
	msg.setFieldValue(fldInfo102, fld102Val);
...
}
    </PRE
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo103;
...
public void setupPDM() {
	...
//Create information for a boolean, int32, and float field (all required)
	// as well as an optional int8 field
	fldInfo103 = defn.addFieldInfo(103, PDMFieldType.INT8, false);
	...
}
public void receiverUsePDM(byte[] buffer) {
	...
	byte fld103Val;
	...
	
	if(msg.isFieldValueSet(fldInfo103)) {
		fld103Val = msg.getFieldValueAsInt8(fldInfo103);
	}
}
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="FIXED-FIELD-TYPES"
>5.5.3.6. Fixed String and Fixed Unicode Field Types</A
></H5
><P
>    A variable length string typically does not have the performance
    optimizations of fixed-required fields. However, by indicating "required", as well
    as the field type FIX_STRING or FIX_UNICODE and specifying an integer number of fixed
    characters, PDM sets aside an appropriate fixed amount of space in the message for that
    field and treats it as an optimized fixed-required field. Strings of a smaller length
    can still be set as the value for the field, but the message allocates the specified
    fixed number of bytes for the string. Specify unicode strings in the same manner
    (with FIX_UNICODE as the type) and in "UTF-8" format.
    </P
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo104;
...
public void setupPDM() {
	...
	fldInfo104 = defn.addFieldInfo(104, PDMFieldType.FIX_STRING, 12, true);
	...
}

public void sourceUsePDM() {
	...
	String fld104Val = "Hello World!";
	
	//Set each field value in the message
	// except do not set the optional field
	msg.setFieldValue(fldInfo100, fld100Val);
	msg.setFieldValue(fldInfo101, fld101Val);
	msg.setFieldValue(fldInfo102, fld102Val);
	msg.setFieldValue(fldInfo104, fld104Val);
...
}
    </PRE
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo104;
...
public void setupPDM() {
	...
	fldInfo104 = defn.addFieldInfo(104, PDMFieldType.FIX_STRING, 12, true);
	...
}
public void receiverUsePDM(byte[] buffer) {
	...
	String fld104Val;
	...
		
	fld104Val = msg.getFieldValueAsString(fldInfo104);
}
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="VARIABLE-FIELD-TYPES"
>5.5.3.7. Variable Field Types</A
></H5
><P
>    The field types of STRING, UNICODE, BLOB, and MESSAGE are all variable length field types.
    They do not require a length to be specified when adding field info to the definition. You
    can use a BLOB field to store an arbitrary binary objects (in Java as an array of bytes)
    and a MESSAGE field to store a PDMMessage object, which enables "nesting"
    PDMMessages inside other PDMMessages. Creating and using a variable length string field is
    nearly identical to the previous fixed string example.
    </P
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo105;
...
public void setupPDM() {
	...
	fldInfo105 = defn.addFieldInfo(105, PDMFieldType.STRING, true);
	...
}

public void sourceUsePDM() {
	...
	String fld105Val = "variable length value";
	...
	msg.setFieldValue(fldInfo105, fld105Val);
...
}
    </PRE
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo105;
...
public void setupPDM() {
	...
	fldInfo105 = defn.addFieldInfo(105, PDMFieldType.STRING, true);
	...
}
public void receiverUsePDM(byte[] buffer) {
	...
	String fld105Val;
	...
		
	fld105Val = msg.getFieldValueAsString(fldInfo105);
}
    </PRE
><P
>    Retrieve the BLOB field values with the getFieldValueAsBlob function, and the MESSAGE field
    values with the getFieldValueAsMessage function.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="ARRAY-FIELD-TYPES"
>5.5.3.8. Array Field Types</A
></H5
><P
>    For each of the scalar field types (fixed and variable length), a corresponding
    array field type uses the convention *_ARR for the type name (ex: BOOLEAN_ARR,
    INT32_ARR, STRING_ARR, etc). This lets you set and get Java values such as an
    int[] or string[] directly into a single field. In addition, all of the array field types
    can specify a fixed number of elements for the size of the array when they are defined, or if
    not specified, behave as variable size arrays. Do this by passing an extra
    parameter to the addFieldInfo function of the definition. 
    </P
><P
>    To be treated as a fixed-required field, an array type field must be required as well as be
    specified as a fixed size array of fixed length elements. For instance, a required
    BOOLEAN_ARR field defined with a size of 3 would be treated as a fixed-required field. Also,
    a required FIX_STRING_ARR field defined with a size of 5 and fixed string length of 7 would
    be treated as a fixed-required field. However, neither a STRING_ARR field nor a BLOB_ARR
    field are treated as a fixed length field even if the size of the array is specified,
    since each element of the array can be variable in length. In the example below, field 106
    and field 108 are both treated as fixed-required fields, but field 107 is not because
    it is a variable size array field type.
    </P
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo106;
private PDMFieldInfo fldInfo107;
private PDMFieldInfo fldInfo108;
...
public void setupPDM() {
	...	
	//Create information for a boolean, int32, and float field (all required)
	// as well as an optional int8 field
	...
	//A required, fixed size array of 3 boolean elements
	fldInfo106 = defn.addFieldInfo(106, PDMFieldType.BOOLEAN_ARR, true, 3);
	//An optional, variable size array of int32 elements
	fldInfo107 = defn.addFieldInfo(107, PDMFieldType.INT32_ARR, false);
	//A required, fixed size array of 2 element which are each 5 character strings
	fldInfo108 = defn.addFieldInfo(108, PDMFieldType.FIX_STRING_ARR, 5, true, 2);
	...
}

public void sourceUsePDM() {
...
	
	//Example values for the message
	...
	boolean fld106Val[] = {true, false, true};
	int fld107Val[] = {1, 2, 3, 4, 5};
	String fld108Val[] = {"aaaaa", "bbbbb"};
	
	//Set each field value in the message
	...
	msg.setFieldValue(fldInfo106, fld106Val);
	msg.setFieldValue(fldInfo107, fld107Val);
	msg.setFieldValue(fldInfo108, fld108Val);
	
	...
}
    </PRE
><PRE
CLASS="SCREEN"
>...
private PDMFieldInfo fldInfo106;
private PDMFieldInfo fldInfo107;
private PDMFieldInfo fldInfo108;
...
public void setupPDM() {
	...	
	//Create information for a boolean, int32, and float field (all required)
	// as well as an optional int8 field
	...
	//A required, fixed size array of 3 boolean elements
	fldInfo106 = defn.addFieldInfo(106, PDMFieldType.BOOLEAN_ARR, true, 3);
	//An optional, variable size array of int32 elements
	fldInfo107 = defn.addFieldInfo(107, PDMFieldType.INT32_ARR, false);
	//A required, fixed size array of 2 element which are each 5 character strings
	fldInfo108 = defn.addFieldInfo(108, PDMFieldType.FIX_STRING_ARR, 5, true, 2);
	...
}

public void receiverUsePDM(byte[] buffer) {
	...
	
	//Values to be retrieved from the message
	...
	boolean fld106Val[];
	int fld107Val[];
	String fld108Val[];
	
	//Deserialize the bytes into a message
	msg.parse(buffer);
	
	//Get each field value from the message
	...
	fld106Val = msg.getFieldValueAsBooleanArray(fldInfo106);
	if(msg.isFieldValueSet(fldInfo107)) {
		fld107Val = msg.getFieldValueAsInt32Array(fldInfo107);
	}
	fld108Val = msg.getFieldValueAsStringArray(fldInfo108);
	
}
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="DEFINITION-INCLUDED-IN-MESSAGE"
>5.5.3.9. Definition Included In Message</A
></H5
><P
>    Optionally, a PDM message can also include the definition when it is serialized to bytes.
    This enables receivers to parse a PDM message without having pre-defined knowledge of the
    message, although including the definition with the message affects message size and
    performance of message deserialization. Notice that the
    setIncludeDefinition function is called with an argument of true for a source that
    serializes the definition as part of the message.
    </P
><PRE
CLASS="SCREEN"
>private PDMDefinition defn;
private PDMMessage msg;

public void setupPDM() {
	//Create the definition with 3 fields and using int field names
	defn = new PDMDefinition(3, true);
		
	...

	//Finalize the definition and create the message
	defn.finalizeDef();
	msg = new PDMMessage(defn);

//Set the flag to indicate that the definition should also be serialized
	msg.setIncludeDefinition(true);
}

...
    </PRE
><P
>    For a receiver, the setupPDM function does not need to set any flags for the message but
    rather should define a message without a definition, since we assume the source provides
    the definition. If a definition is set for a message, it will attempt to use
    that definition instead of the definition on the incoming message (unless the ids are
    different).
    </P
><PRE
CLASS="SCREEN"
>private PDMDefinition defn;
private PDMMessage msg;

public void setupPDM() {
	//Don.t define a definition

	//Create a message without a definition since the incoming message will have it

	msg = new PDMMessage();
}

...
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="THE-PDM-FIELD-ITERATOR"
>5.5.3.10. The PDM Field Iterator</A
></H5
><P
>    You can use the PDM Field Iterator to check all defined message fields to see if set, or to
    extract their values.
    You can extract a field value as an Object using this method, but due to the
    casting involved, we recommend you use the type specific get method to extract the exact
    value. Notice the use of field.isValueSet to check to see if the field value is set and the
    type specific get methods such as getBooleanValue and getFloatValue.
    </P
><PRE
CLASS="SCREEN"
>...

public void setupPDM() {
	//Create the definition with 3 fields and using int field names
	defn = new PDMDefinition(3, true);
	
	//Set the definition id and version
	defn.setId(1001);
	defn.setMsgVersMajor((byte)1);
	defn.setMsgVersMinor((byte)0);
	
	//Create information for a boolean, int32, and float field (all required)
	// as well as an optional int8 field
	fldInfo100 = defn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
	fldInfo101 = defn.addFieldInfo(101, PDMFieldType.INT32, true);
	fldInfo102 = defn.addFieldInfo(102, PDMFieldType.FLOAT, true);
	fldInfo103 = defn.addFieldInfo(103, PDMFieldType.INT8, false);
	fldInfo104 = defn.addFieldInfo(104, PDMFieldType.FIX_STRING, 12, true);
	fldInfo105 = defn.addFieldInfo(105, PDMFieldType.STRING, true);
	//A required, fixed size array of 3 boolean elements
	fldInfo106 = defn.addFieldInfo(106, PDMFieldType.BOOLEAN_ARR, true, 3);
	//An optional, variable size array of int32 elements
	fldInfo107 = defn.addFieldInfo(107, PDMFieldType.INT32_ARR, false);
	//A required, fixed size array of 2 element which are each 5 character strings
	fldInfo108 = defn.addFieldInfo(108, PDMFieldType.FIX_STRING_ARR, 5, true, 2);
	
	//Finalize the definition and create the message
	defn.finalizeDef();
	msg = new PDMMessage(defn);
}

public void receiveAndIterateMessage(byte[] buffer) {
	msg.parse(buffer);
	PDMFieldIterator iterator = msg.createFieldIterator();
	PDMField field = null;
	while(iterator.hasNext()) {
		field = iterator.next();
		System.out.println("Field set? " +field.isValueSet());
		switch(field.getIntName()) {
			case 100:
				boolean val100 = field.getBooleanValue();
				System.out.println(
						"Field 100's value is: " + val100);
				break;
			case 101:
				int val101 = field.getInt32Value();
				System.out.println(
						"Field 101's value is: " + val101);
				break;
			case 102:
				float val102 = field.getFloatValue(); 
				System.out.println(
						"Field 102's value is: " + val102);
				break;
			default:
				//Casting to object is possible but not recommended
				Object value = field.getValue();
				int name = field.getIntName();
				System.out.println(
						"Field " + name + "'s value is: " + value);
		}
	}
}
    </PRE
><P
>    Sample Output (106, 107, 108 are array objects as expected):
    </P
><PRE
CLASS="SCREEN"
>Field set? true
Field 100's value is: true
Field set? true
Field 101's value is: 7
Field set? true
Field 102's value is: 3.14
Field set? false
Field 103's value is: null
Field set? true
Field 104's value is: Hello World!
Field set? true
Field 105's value is: Variable
Field set? true
Field 106's value is: [Z@527736bd
Field set? true
Field 107's value is: [I@10aadc97
Field set? true
Field 108's value is: [Ljava.lang.String;@4178460d
    </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="USING-THE-DEFINITION-CACHE"
>5.5.3.11. Using the Definition Cache</A
></H5
><P
>    The PDM Definition Cache assists with storing and
    looking up definitions by their id and version. In some scenarios, it may not be desirable
    to maintain the references to the message and the definition from a setup phase by the
    application. A source could optionally create the definition during the setup phase and
    store it in the definition cache. At a later point in time, it could retrieve the definition
    from the cache and use it to create the message without needing to maintain any references
    to the objects.
    </P
><PRE
CLASS="SCREEN"
>public void createAndStoreDefinition() {
	PDMDefinition myDefn = new PDMDefinition(3, true);
	//Set the definition id and version
	myDefn.setId(2001);
	myDefn.setMsgVersMajor((byte)1);
	myDefn.setMsgVersMinor((byte)0);
	
	//Create information for a boolean, int32, and float field (all required)
	myDefn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
	myDefn.addFieldInfo(101, PDMFieldType.INT32, true);
	myDefn.addFieldInfo(102, PDMFieldType.FLOAT, true);

	myDefn.finalizeDef();
	
	PDMDefinitionCache.getInstance().put(myDefn);
}

public void createMessageUsingCache() {
	PDMDefinition myFoundDefn = PDMDefinitionCache.getInstance().get(2001, 1, 0);
	if(myFoundDefn != null) {
		PDMMessage myMsg = new PDMMessage(myFoundDefn);
		//Get FieldInfo from defn and then set field values in myMsg
		//...
	}
}
    </PRE
><P
>    A more advanced use of the PDM Definition Cache is by a receiver which may need to receive
    messages with different definitions and the definitions are not being included with the
    messages. The receiver can create the definitions in advance and then set a flag that allows
    automatic lookup into the definition cache when parsing a message (which is not on by
    default). Before receiving messages, the receiver should do something similar to
    createAndStoreDefinition (shown below) to set up definitions and put them in the definition
    cache. Then the flag to allow automatic lookup should be set as shown below in the call to
    setTryToLoadDefFromCache(true). This allows the PDMMessage to be created without a
    definition and still successfully parse a message by leveraging the definition cache.
    </P
><PRE
CLASS="SCREEN"
>public void createAndStoreDefinition() {
	PDMDefinition myDefn = new PDMDefinition(3, true);
	//Set the definition id and version
	myDefn.setId(2001);
	myDefn.setMsgVersMajor((byte)1);
	myDefn.setMsgVersMinor((byte)0);
	
	//Create information for a boolean, int32, and float field (all required)
	myDefn.addFieldInfo(100, PDMFieldType.BOOLEAN, true);
	myDefn.addFieldInfo(101, PDMFieldType.INT32, true);
	myDefn.addFieldInfo(102, PDMFieldType.FLOAT, true);
	
	myDefn.finalizeDef();
	
	PDMDefinitionCache.getInstance().put(myDefn);
	
	//Create and store other definitions
	//...
}

public void receiveKnownMessages(byte[] buffer) {
	PDMMessage myMsg = new PDMMessage();
	//Set the flag that enables messages to try
	// looking up the definition in the cache automatically
	// when parsing a byte buffer
	myMsg.setTryToLoadDefFromCache(true);
	myMsg.parse(buffer);
	
	if(myMsg.getDefinition().getId() == 2001 
			&#38;&#38; myMsg.getDefinition().getMsgVersMajor() == 1
			&#38;&#38; myMsg.getDefinition().getMsgVersMinor() == 0) {
		
		PDMDefinition myDefn = PDMDefinitionCache.getInstance().get(2001, 1, 0);
		PDMFieldInfo fldInfo100 = myDefn.getFieldInfo(100);
		PDMFieldInfo fldInfo101 = myDefn.getFieldInfo(101);
		PDMFieldInfo fldInfo102 = myDefn.getFieldInfo(102);
		
		boolean fld100Val;
		int fld101Val;
		float fld102Val;
		
		//Get each field value from the message
		fld100Val = myMsg.getFieldValueAsBoolean(fldInfo100);
		fld101Val = myMsg.getFieldValueAsInt32(fldInfo101);
		fld102Val = myMsg.getFieldValueAsFloat(fldInfo102);
		
		System.out.println(fld100Val + " " + fld101Val + " " + fld102Val);
	}
}
    </PRE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="MIGRATING-FROM-SDM"
>5.5.4. Migrating from SDM</A
></H4
><P
>    Applications using SDM with a known set of message fields are good
    candidates for migrating from SDM to PDM. With SDM, the source typically adds
    fields to an SDM message without a definition. But, as shown above in the PDM examples,
    creating/adding a PDM definition before adding field values is fairly straightforward.
    </P
><P
>    However, certain applications may be incapable of building a definition in advance due to
    the ad-hoc nature of their messaging needs, in which case a
    self-describing format like SDM may be preferred.
    </P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SIMPLE-MIGRATION-EXAMPLE"
>5.5.4.1. Simple Migration Example</A
></H5
><P
>    The following source code shows a basic application that serializes and deserializes three
    fields using SDM and PDM. The setup method in both cases initializes the object instances so
    they can be reused by the source and receiver methods.
    </P
><P
>    The goal of the sourceCreateMessageWith functions is to produce a byte array by setting
    field values in a message object. With SDM, actual Field classes are created, values are
    set, the Field classes are added to a Fields class, and then the Fields class is added to
    the SDMessage. With PDM, FieldInfo objects are created during the setup phase and then used
    to set specific values in the PDMMessage.
    </P
><P
>    The goal of the receiverParseMessageWith functions is to produce a message object by parsing
    the byte array and then extract the field values from the message. With SDM, the specific
    field is located and casted to the correct field class before getting the field value. With
    PDM, the appropriate getFieldValueAs function is called with the corresponding FieldInfo
    object created during the setup phase to extract the field value.
    </P
><PRE
CLASS="SCREEN"
>public class Migration {
	
	//SDM Variables
	private LBMSDMessage srcSDMMsg;
	private LBMSDMessage rcvSDMMsg;
	
	//PDM Variables
	private PDMDefinition defn;
	private PDMFieldInfo fldInfo100;
	private PDMFieldInfo fldInfo101;
	private PDMFieldInfo fldInfo102;
	private PDMMessage srcPDMMsg;
	private PDMMessage rcvPDMMsg;
	

public static void main(String[] args) {
		Migration app = new Migration();
		System.out.println("Setting up PDM Definition and Message");
		app.setupPDM();
		System.out.println("Setting up SDM Messages");
		app.setupSDM();
		
		byte[] sdmBuffer;
		sdmBuffer = app.sourceCreateMessageWithSDM();
		app.receiverParseMessageWithSDM(sdmBuffer);
		
		byte[] pdmBuffer;
		pdmBuffer = app.sourceCreateMessageWithPDM();
		app.receiverParseMessageWithPDM(pdmBuffer);
		
	}

	public void setupSDM() {
		rcvSDMMsg = new LBMSDMessage();
		srcSDMMsg = new LBMSDMessage();
	}
	
	public void setupPDM() {
		//Create the definition with 3 fields and using int field names
		defn = new PDMDefinition(3, false);
		
		//Set the definition id and version
		defn.setId(1001);
		defn.setMsgVersMajor((byte)1);
		defn.setMsgVersMinor((byte)0);
		
		//Create information for a boolean, int32, and float field (all required)
		// as well as an optional int8 field
		fldInfo100 = defn.addFieldInfo("Field100", PDMFieldType.INT8, true);
		fldInfo101 = defn.addFieldInfo("Field101", PDMFieldType.INT16, true);
		fldInfo102 = defn.addFieldInfo("Field102", PDMFieldType.INT32, true);
		
		//Finalize the definition and create the message
		defn.finalizeDef();
		srcPDMMsg = new PDMMessage(defn);
		rcvPDMMsg = new PDMMessage(defn);
	}
	
	public byte[] sourceCreateMessageWithSDM() {
		byte[] buffer = null;
		
		LBMSDMField fld100 = new LBMSDMFieldInt8("Field100", (byte)0x42);
		LBMSDMField fld101 = new LBMSDMFieldInt16("Field101", (short)0x1ead);
		LBMSDMField fld102 = new LBMSDMFieldInt32("Field102", 12345);
		LBMSDMFields fset = new LBMSDMFields();

		try {
			fset.add(fld100);
			fset.add(fld101);
			fset.add(fld102);
		} catch (LBMSDMException e) {
			System.out.println ( e );
		}
		
		
		srcSDMMsg.set(fset);
		try {
			buffer = srcSDMMsg.data();
		} catch (IndexOutOfBoundsException e) {
			System.out.println ( "SDM Exception occurred during build of message:" );
			System.out.println ( e.toString() );
		} catch (LBMSDMException e) {
			System.out.println ( e.toString() );
		}
		return buffer;
		
	}
	
	public byte[] sourceCreateMessageWithPDM() {
		//Set each field value in the message
		srcPDMMsg.setFieldValue(fldInfo100, (byte)0x42);
		srcPDMMsg.setFieldValue(fldInfo101, (short)0x1ead);
		srcPDMMsg.setFieldValue(fldInfo102, 12345);
		
		//Serialize the message to bytes
		byte[] buffer = srcPDMMsg.toBytes();
		return buffer;
	}
	
	public void receiverParseMessageWithSDM(byte[] buffer) {
		//Values to be retrieved from the message
		byte fld100Val;
		short fld101Val;
		int fld102Val;
		
		//Deserialize the bytes into a message
		try {
			rcvSDMMsg.parse(buffer);
		} catch (LBMSDMException e) {
			System.out.println(e.toString());
		}
		
		LBMSDMField fld100 = rcvSDMMsg.locate("Field100");
		LBMSDMField fld101 = rcvSDMMsg.locate("Field101");
		LBMSDMField fld102 = rcvSDMMsg.locate("Field102");
		
		//Get each field value from the message
		fld100Val = ((LBMSDMFieldInt8)fld100).get();
		fld101Val = ((LBMSDMFieldInt16)fld101).get();;
		fld102Val = ((LBMSDMFieldInt32)fld102).get();;
		
		
		System.out.println("SDM Results: Field100=" + fld100Val +
				", Field101=" + fld101Val +
				", Field102=" + fld102Val);
		
	}
	
	public void receiverParseMessageWithPDM(byte[] buffer) {		
		//Values to be retrieved from the message
		byte fld100Val;
		short fld101Val;
		int fld102Val;
		
		//Deserialize the bytes into a message
		rcvPDMMsg.parse(buffer);
		
		//Get each field value from the message
		fld100Val = rcvPDMMsg.getFieldValueAsInt8(fldInfo100);
		fld101Val = rcvPDMMsg.getFieldValueAsInt16(fldInfo101);
		fld102Val = rcvPDMMsg.getFieldValueAsInt32(fldInfo102);
		
		
		System.out.println("PDM Results: Field100=" + fld100Val +
				", Field101=" + fld101Val +
				", Field102=" + fld102Val);
		
	}
	
}
    </PRE
><P
>    Notice that with sourceCreateMessageWithSDM function, the three fields (name and value) are
    created and added to the fset variable, which is then added to the SDM message. On the other
    hand, the sourceCreateMessageWithPDM function uses the FieldInfo object references to add
    the field values to the message for each of the three fields.
    </P
><P
>    Also notice that the receiverParseMessageWithSDM requires a cast to the specific field class
    (like LBMSDMFieldInt8) once the field has been located. After the cast, calling the get
    method returns the expected value. On the other hand the receiverParseMessageWithPDM uses
    the FieldInfo object reference to directly retrieve the field value using the appropriate
    getFieldValueAs* method.
    </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SDM-RAW-CLASSES"
>5.5.4.2. SDM Raw Classes</A
></H5
><P
>    Several SDM classes with Raw in their name could be used as the value when creating an
    LBMSDMField. For example, an LBMSDMRawBlob instance could be created from a byte array and
    then that the LBMSDMRawBlob could be used as the value to a LBMSDMFieldBlob as shown in the
    following example.
    </P
><PRE
CLASS="SCREEN"
>		byte[] blob = new byte[25];
		LBMSDMRawBlob rawSDMBlob = new LBMSDMRawBlob(blob);
		try {
			LBMSDMField fld103 = new LBMSDMFieldBlob("Field103",rawSDMBlob);
		} catch (LBMSDMException e1) {
			System.out.println(e1);
		}
    </PRE
><P
>    The actual field named "Field103" is created in the try block using the rawSDMBlob variable
    which has been created to wrap the blob byte array. This field can be added to a
    LBMSDMFields object, which then uses it in a LBMSDMessage.
    </P
><P
>    In PDM, there are no "Raw" classes that can be created. When setting the value for a field
    for a message, the appropriate variable type should be passed in as the value. For example,
    setting the field value for a BLOB field would mean simply passing the byte array directly
    in the setValue method as shown in the following code snippet since the field is defined as
    type BLOB.
    </P
><PRE
CLASS="SCREEN"
>private PDMFieldInfo fldInfo103;	

public void setupPDM() {
		...
		fldInfo103 = defn.addFieldInfo("Field103", PDMFieldType.BLOB, true);
		...
	}
...
		byte[] blob = new byte[25];
		srcPDMMsg.setFieldValue(fldInfo103, blob);
    </PRE
><P
>    The PDM types of DECIMAL, TIMESTAMP, and MESSAGE expect a corresponding instance of
    PDMDecimal, PDMTimestamp, and PDMMessage as the field value when being set in the message so
    those types do require an instantiation instead of using a native Java type. For example, if
    "Field103" had been of type PDMFieldType.DECIMAL, the following code would be used to set
    the value.
    </P
><PRE
CLASS="SCREEN"
>PDMDecimal decimal = new PDMDecimal((long)2, (byte)32);
srcPDMMsg.setFieldValue(fldInfo103, decimal);
    </PRE
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="MULTICAST-IMMEDIATE-MESSAGING"
>5.6. Multicast Immediate Messaging</A
></H3
><P
>	 As an alternative to the normal, source-based <B
CLASS="APPLICATION"
>UM</B
> messaging model, Multicast 
	 Immediate Messaging (MIM) offers advantages to short-lived topics and applications 
	 that cannot tolerate a delay between source creation and the sending of the first 
	 message. See the <A
HREF="https://communities.informatica.com/infakb/kbexternal/default.aspx"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Knowledgebase</A
> article, 
	 <B
CLASS="APPLICATION"
>Delay Before Sending</B
> 
	 for background on this delay and other head-loss mitigation techniques.  
	 </P
><P
>	 Multicast Immediate Messaging avoids delay by eliminating the topic resolution 
	 process. MIM accomplishes this by:
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Configuring transport information into sending and receiving applications.
		</P
></LI
><LI
><P
>	 Including topic strings within each message.  
		</P
></LI
></OL
><P
>	 MIM is well-suited to applications where a small number of messages are sent 
	 to a topic. By eliminating topic resolution, MIM also reduces one of the causes 
	 of head-loss, defined as the loss of initial messages sent over a new transport 
	 session. Messages sent before topic resolution is complete will be lost.
	 </P
><P
>	 MIM is typically not used for normal streaming data because messages are somewhat 
	 less efficiently handled than source-based messages. Inefficiencies derive from 
	 larger message sizes due to the inclusion of the topic name, and on the receiving 
	 side, the MIM delivery controller hashing of topic names to find receivers, which 
	 consumes some extra CPU. If you have a high-message-rate stream, you should use a 
	 source-based method and not MIM. If head-loss is a concern and delay before sending 
	 is not feasible, then consider using late join (although this replaces head-loss 
	 with some head latency).
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 Multicast Immediate Messaging can use Datagram Bypass Layer (DBL) acceleration in conjunction 
	 with DBL-enabled 
	 <A
HREF="http://www.myri.com"
TARGET="_top"
><SPAN
CLASS="TRADEMARK"
>Myricom</SPAN
></A
> 
	 10-Gigabit Ethernet NICs for Linux and <SPAN
CLASS="TRADEMARK"
>Microsoft</SPAN
> <SPAN
CLASS="TRADEMARK"
>Windows</SPAN
>. DBL is a kernel-bypass technology that 
	 accelerates sending and receiving UDP traffic. See 
	 <A
HREF="../Config/transportaccelerationoptions.html"
TARGET="_top"
>Transport Acceleration Options</A
> 
	 for more information. 
		</P
></BLOCKQUOTE
></DIV
><P
>	 This section discusses the following topics.
	 </P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#TEMPORARY-TRANSPORT-SESSION"
><I
>Temporary Transport Session</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#RECEIVING-IMMEDIATE-MESSAGES"
><I
>Receiving Immediate Messages</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#MIM-CONFIGURATION"
><I
>MIM Configuration</I
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="#MIM-EXAMPLE-APPLICATIONS"
><I
>MIM Example Applications</I
></A
>
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TEMPORARY-TRANSPORT-SESSION"
>5.6.1. Temporary Transport Session</A
></H4
><P
>	 MIM uses the same reliable multicast algorithms as LBT-RM. When a sending 
	 application sends a message with <TT
CLASS="LITERAL"
>lbm_multicast_immediate_message()</TT
>, 
	 MIM creates a temporary transport session. Note that no topic-level source object is created. 
		</P
><P
>	 MIM automatically deletes the temporary transport session after a period 
	 of inactivity defined by 
	 <A
HREF="../Config/multicastimmediatemessagingoperationoptions.html#CONTEXTMIMSRCDELETIONTIMEOUT"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>mim_src_deletion_timeout</TT
></A
> which 
	 defaults to 30 seconds. A subsequent send creates a new  
	 transport session. Due to the possibility of head-loss in the switch, it 
	 is recommended that sending applications use a long deletion timeout if they continue 
	 to use MIM after significant periods of inactivity.
		</P
><P
>	 MIM forces all topics across all sending applications to be concentrated 
	 onto a single multicast address to which ALL applications listen, even if 
	 they aren't interested in any of the topics. Thus, all topic filtering must 
	 happen in <B
CLASS="APPLICATION"
>UM</B
>. 
		</P
><P
>	 MIM can also be used to send an <B
CLASS="APPLICATION"
>UM</B
> request message with 
	 <TT
CLASS="LITERAL"
>lbm_multicast_immediate_request()</TT
>. For example, an application 
	 can use MIM to request initialization information right when it starts up. MIM 
	 sends the response directly to the initializing application, avoiding the topic 
	 resolution delay inherent in the normal source-based 
	 <TT
CLASS="LITERAL"
>lbm_send_request()</TT
> function.
		</P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="MIM-NOTIFICATIONS"
>5.6.1.1. MIM Notifications</A
></H5
><P
>	 MIM notifications differ in the following ways from normal <B
CLASS="APPLICATION"
>UM</B
> source-based sending.
		</P
><P
></P
><UL
><LI
><P
>	 When a sending application's MIM transport session times out and is 
	 deleted, the receiving applications do not receive an EOS notification.
		</P
></LI
><LI
><P
>	 Applications with a source notification callback are not informed of a 
	 MIM sender. Since source notification is basically a hook into the topic 
	 resolution system, this should not come as a surprise.  
		</P
></LI
><LI
><P
>	 MIM sending supports the non-blocking flag. However, it does not provide an 
	 LBM_SRC_EVENT_WAKEUP notification when the MIM session becomes writable again.
		</P
></LI
><LI
><P
>	 MIM sends unrecoverable loss notifications to a context callback, not to 
	 a receiver callback. See 
	 <A
HREF="#LOSS-HANDLING"
><I
>Loss Handling</I
></A
>.  
		</P
></LI
></UL
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="RECEIVING-IMMEDIATE-MESSAGES"
>5.6.2. Receiving Immediate Messages</A
></H4
><P
>	 MIM does not require any special type of receiver. It uses the topic-based 
	 publish/subscribe model so an application must still create a receiver for a 
	 topic to receive MIM messages.
		</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 If needed, an application can send topic-less messages using MIM. A MIM 
	 sender passes in a NULL string instead of a topic name. The message goes 
	 out on the MIM multicast address and is received by all other receivers. 
	 A receiving application can use 
	 <TT
CLASS="LITERAL"
>lbm_context_rcv_immediate_msgs()</TT
> to set the callback 
	 procedure and delivery method for non-topic immediate messages.
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="WILDCARD-RECEIVERS"
>5.6.2.1. Wildcard Receivers</A
></H5
><P
>	 When an application receives an immediate message, it's topic is hashed to 
	 see if there is at least one regular (non-wildcard) receiver object listening 
	 to the topic. If so, then MIM delivers the message data to the list of receivers. 
		</P
><P
>	 However, if there are no regular receivers for that topic in the receive 
	 hash, MIM runs the message topic through all existing wildcard patterns and 
	 delivers matches to the appropriate wildcard receiver objects without creating 
	 sub-receivers. The next MIM message received for the same topic will again be 
	 run through all existing wildcard patterns. This can consume significant CPU 
	 resources since it is done on a per-message basis. 
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="LOSS-HANDLING"
>5.6.2.2. Loss Handling</A
></H5
><P
>	 The receiving application can set up a context callback to be notified of 
	 MIM unrecoverable loss (<TT
CLASS="LITERAL"
>lbm_mim_unrecloss_function_cb</TT
>). 
	 It is not possible to do this notification on a topic basis because the 
	 receiving <B
CLASS="APPLICATION"
>UM</B
> has no way of knowing which topics were affected by the loss.
		</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 The <A
HREF="../API/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> API's</A
> statistics functions 
	 and the <B
CLASS="APPLICATION"
>UM</B
> <A
HREF="../API/lbmmon_8h.html"
TARGET="_top"
>Monitoring API</A
> 
	 do not provide access to MIM transport session statistics. 
		</P
></BLOCKQUOTE
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="MIM-CONFIGURATION"
>5.6.3. MIM Configuration</A
></H4
><P
>	 As of <B
CLASS="APPLICATION"
>UM</B
> 3.1, MIM supports ordered delivery. As of <B
CLASS="APPLICATION"
>UM</B
> 3.3.2, 
	 the MIM configuration option, 
	 <A
HREF="../Config/multicastimmediatemessagingoperationoptions.html#CONTEXTMIMORDEREDDELIVERY"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>mim_ordered_delivery</TT
></A
> 
	 defaults to ordered delivery. A byproduct of MIM ordered delivery is 
	 cross-topic ordering, which normal source-based <B
CLASS="APPLICATION"
>UM</B
> senders cannot guarantee. 
		</P
><P
>	 See the <B
CLASS="APPLICATION"
>UM</B
> Configuration Guide for the descriptions of the MIM configuration options.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../Config/multicastimmediatemessagingnetworkoptions.html"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>Multicast Immediate Messaging Network Options</TT
></A
>
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/multicastimmediatemessagingreliabilityoptions.html"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>Multicast Immediate Messaging Reliability Options</TT
></A
>  
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/multicastimmediatemessagingoperationoptions.html"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>Multicast Immediate Messaging Operation Options</TT
></A
>  
		</P
></LI
></UL
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	Setting <A
HREF="../Config/multicastimmediatemessagingnetworkoptions.html#CONTEXTMIMINCOMINGADDRESS"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>mim_incoming_address</TT
></A
> to <TT
CLASS="LITERAL"
>0.0.0.0</TT
> 
	 turns off MIM.
		</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="MIM-EXAMPLE-APPLICATIONS"
>5.6.4. MIM Example Applications</A
></H4
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> includes two example applications that illustrate MIM.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../example/lbmimsg.c"
TARGET="_top"
>lbmimsg.c</A
> - application that sends immediate 
	 messages as fast as it can to a given topic (single source). See also the Java example,
	 <A
HREF="../java_example/lbmimsg.java"
TARGET="_top"
>lbmimsg.java</A
> and the .NET example,
	 <A
HREF="../dotnet_example/lbmimsg.cs"
TARGET="_top"
>lbmimsg.cs</A
>.
		</P
></LI
><LI
><P
>	 <A
HREF="../example/lbmireq.c"
TARGET="_top"
>lbmireq.c</A
> - application that sends immediate 
	 requests to a given topic (single source) and waits for responses.  
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="LBMIMSG-C"
>5.6.4.1. lbmimsg.c</A
></H5
><P
>	 We can demonstrate the default operation of Immediate Messaging with 
	 <B
CLASS="APPLICATION"
>lbmimsg</B
> and <B
CLASS="APPLICATION"
>lbmrcv</B
>. 
		</P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmrcv -v topicName</TT
>
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmimsg topicName</TT
> 
		</P
></LI
></OL
><P
>	 The <B
CLASS="APPLICATION"
>lbmrcv</B
> output should resemble the following.
		</P
><PRE
CLASS="SCREEN"
>Immediate messaging target: TCP:10.29.1.78:14391
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][0], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][1], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][2], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][3], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][4], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][5], 25 bytes
[topicName][LBTRM:10.29.1.78:14390:644c8862:224.10.10.21:14401][6], 25 bytes
  </PRE
><P
>	 Each line in the lbmrcv output is a message received, showing the topic 
	 name, transport type, receiver IP:Port, multicast address and message number.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="LBMIREQ-C"
>5.6.4.2. lbmireq.c</A
></H5
><P
>	 Sending an <B
CLASS="APPLICATION"
>UM</B
> request by MIM can be demonstrated with 
	 <B
CLASS="APPLICATION"
>lbmireq</B
> and <B
CLASS="APPLICATION"
>lbmrcv</B
>, 
	 which shows a single request being sent by <B
CLASS="APPLICATION"
>lbmireq</B
> 
	 and received by <B
CLASS="APPLICATION"
>lbmrcv</B
>. 
	 (<B
CLASS="APPLICATION"
>lbmrcv</B
> sends no response.)
		</P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmrcv -v topicName</TT
>
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmireq topicName</TT
>  
		</P
></LI
></OL
><P
>	 <B
CLASS="APPLICATION"
>lbmrcv</B
>
		</P
><P
>	 The <B
CLASS="APPLICATION"
>lbmrcv</B
> output should resemble the following.
		</P
><PRE
CLASS="SCREEN"
>$ lbmrcv -v topicName
Immediate messaging target: TCP:10.29.1.78:14391
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
[topicName][LBTRM:10.29.1.78:14390:92100885:224.10.10.21:14401][0], Request
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
1     secs.  0     Kmsgs/sec.  0     Kbps
  </PRE
><P
>	 <B
CLASS="APPLICATION"
>lbmireq</B
>
		</P
><P
>	 The <B
CLASS="APPLICATION"
>lbmireq</B
> output should resemble the following.
		</P
><PRE
CLASS="SCREEN"
>$ lbmireq topicName
Using TCP port 4392 for responses
Sending 1 requests of size 25 bytes to target &lt;&#62; topic &lt;topicName&#62;
Sending request 0
Sent request 0. Pausing 5 seconds.
Done waiting for responses. 0 responses (0 bytes) received. Deleting request
Quitting...
Lingering for 5 seconds...
  </PRE
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="SPECTRUM"
>5.7. Spectrum</A
></H3
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> Spectrum, which refers to a "spectrum of channels", allows a source 
	 application to allocate any number of channels using <TT
CLASS="LITERAL"
>lbm_src_channel_create()</TT
> 
	 on which to send (<TT
CLASS="LITERAL"
>lbm_src_send_ex()</TT
>)different messages of the same 
	 topic. A receiving application can subscribe receivers to one or more channels with 
	 either <TT
CLASS="LITERAL"
>lbm_rcv_subscribe_channel</TT
> or 
	 <TT
CLASS="LITERAL"
>lbm_wrcv_subscribe_channel</TT
>. Since each channel requires a 
	 different receiver callback, the receiver application can achieve more granular 
	 filtering of messages. Moreover, messages are received in-order across channels 
	 since all messages are part of the same topic stream.
	 </P
><P
>	 The same level of filtering can be accomplished with a topic space design that 
	 creates separate topics for each channel, however, <B
CLASS="APPLICATION"
>UM</B
> cannot guarantee the 
	 delivery of messages from multiple sources/topics in any particular order. Not 
	 only can <B
CLASS="APPLICATION"
>UM</B
> Spectrum deliver the messages over many channels in the order 
	 they were sent by the source, but it also reduces topic resolution traffic since 
	 <B
CLASS="APPLICATION"
>UM</B
> advertises only topics, not channels.
	 </P
><P
>	 See also the <A
HREF="../API/index.html"
TARGET="_top"
>C API</A
> documentation.
	 </P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="SPECTRUM-PERF"
>5.7.1. Performance Pluses</A
></H4
><P
>	 The use of separate callbacks for different channels improves filtering and also 
	 relieves the source application of the task of including filtering information in 
	 the message data.
		</P
><P
>	 Java and .NET performance also receives a boost because messages not of interest 
	 can be discarded before they transition to the Java or .NET level.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="SPECTRUM-CONFIG-OPTIONS"
>5.7.2. Configuration Options</A
></H4
><P
>	 Spectrum's default behavior delivers messages on any channels the receiver has 
	 subscribed to on the callbacks specified when subscribing, and all other messages 
	 on the receiver's default callback. This behavior can be changed with the following 
	 configuration options.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="../Config/deliverycontroloptions.html#RECEIVERNULLCHANNELBEHAVIOR"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>null_channel_behavior</TT
></A
> - behavior for messages delivered 
	 with no channel information.
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/deliverycontroloptions.html#RECEIVERUNRECOGNIZEDCHANNELBEHAVIOR"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>unrecognized_channel_behavior</TT
></A
> - behavior for messages 
	 delivered with channel information but are on a channel for which the receiver has 
	 not registered interest.  
		</P
></LI
><LI
><P
>	 <A
HREF="../Config/deliverycontroloptions.html#RECEIVERCHANNELMAPTABLESZ"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>channel_map_tablesz</TT
></A
> - controls the size of the table 
	 used by a receiver to store channel subscriptions.  
		</P
></LI
></UL
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="HOT-FAILOVER"
>5.8. Hot Failover</A
></H3
><P
>	<B
CLASS="APPLICATION"
>UM</B
> Hot Failover (HF) lets you implement sender redundancy in your applications. You can create multiple HF
	senders in different <B
CLASS="APPLICATION"
>UM</B
> contexts, or, for even greater resiliency, on separate machines. There is no hard limit
	to the number of HF sources, and different HF sources can use different transport types.
	</P
><P
>	Hot Failover receivers filter out the duplicate messages and deliver one message to your application. Thus,
	sources can drop a few messages or even fail completely without causing message loss, as long as the HF receiver
	receives each message from at least one source.
	</P
><P
>	The following diagram displays Hot Failover operation.
		</P
><DIV
CLASS="FIGURE"
><A
NAME="HF-OPERATION"
></A
><P
><B
>Figure 12. Hot Failover Operation</B
></P
><P
><IMG
SRC="Hot_Failover.png"
ALIGN="CENTER"></P
></DIV
><P
>	In the figure above, HF sources send copies of Message X. An HF receiver delivers the first copy of Message X it
	receives to the application, and discards subsequent copies coming from the other sources.
	</P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="IMPLEMENTING-HFSRCS"
>5.8.1. Implementing Hot Failover Sources</A
></H4
><P
>		You create Hot Failover sources with <CODE
CLASS="FUNCTION"
>lbm_hf_src_create()</CODE
>. This returns a source
		object with internal state information that lets it send HF messages. You delete HF sources
		with the <CODE
CLASS="FUNCTION"
>lbm_src_delete()</CODE
> function.
		</P
><P
>		HF sources send HF messages via <CODE
CLASS="FUNCTION"
>lbm_hf_src_send_ex()</CODE
> or
		<CODE
CLASS="FUNCTION"
>lbm_hf_src_sendv_ex()</CODE
>. These functions take a sequence number, supplied via the
		<TT
CLASS="LITERAL"
>exinfo</TT
> object, that HF receivers use to identify the same message sent from different
		HF sources. The <TT
CLASS="LITERAL"
>exinfo</TT
> has an <TT
CLASS="LITERAL"
>hf_sequence_number</TT
>, with a flag
		(<TT
CLASS="LITERAL"
>LBM_SRC_SEND_EX_FLAG_HF_32</TT
> or <TT
CLASS="LITERAL"
>LBM_SRC_SEND_EX_FLAG_HF_64</TT
>) that
		identifies whether it's a 32- or 64-bit number. Each HF source sends the same message content for a
		given sequence number, which must be coordinated by your application.
		</P
><P
>		If the source needs to restart its sequence number to an earlier value (e.g. start of day; not needed
		for normal wraparound), delete and re-create the source and receiver objects. Without re-creating the
		objects, the receiver sees the smaller sequence number, assumes the data is duplicate, and discards it.
		In (and only in) cases where this cannot be done, use <CODE
CLASS="FUNCTION"
>lbm_hf_src_send_rcv_reset()</CODE
>.
		</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>		Your application must synchronize calling <CODE
CLASS="FUNCTION"
>lbm_hf_src_send_ex()</CODE
> or
		<CODE
CLASS="FUNCTION"
>lbm_hf_src_sendv_ex()</CODE
> with all threads sending on the same source. (One symptom of
		not doing so is messages appearing at the receiver as inside intentional gaps and being erroneously
		discarded.)
		</P
></BLOCKQUOTE
></DIV
><P
>		Please be aware that non-HF receivers created for an HF topic receive multiple copies of each message.
		We recommend you establish local conventions regarding the use of HF sources, such as including "HF" in
		the topic name.
		</P
><P
>		For an example source application, see <TT
CLASS="LITERAL"
>lbmhfsrc</TT
> in the 
		<A
HREF="../example/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Examples Page</A
>.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="IMPLEMENTING-HFRCVRS"
>5.8.2. Implementing Hot Failover Receivers</A
></H4
><P
>		You create HF receivers with <CODE
CLASS="FUNCTION"
>lbm_hf_rcv_create()</CODE
>, and delete them using
		<CODE
CLASS="FUNCTION"
>lbm_hf_rcv_delete()</CODE
> and <CODE
CLASS="FUNCTION"
>lbm_hf_rcv_delete_ex()</CODE
>.
		</P
><P
>		Incoming messages have an <TT
CLASS="LITERAL"
>hf_sequence_number</TT
> field containing the sequence number,
		and a message flag (<TT
CLASS="LITERAL"
>LBM_MSG_FLAG_HF_32</TT
> or <TT
CLASS="LITERAL"
>LBM_MSG_FLAG_HF_64</TT
>)
		noting the bit size.
		<DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>		Previous <B
CLASS="APPLICATION"
>UM</B
> versions used sequence_number for HF message identification. This field holds a 32-bit value
		and is still set for backwards compatibility, but if the HF sequence numbers are 64-bit lengths, this
		non-HF sequence number is set to 0. Also, you can retrieve the original (non-HF) topic sequence number
		via <CODE
CLASS="FUNCTION"
>lbm_msg_retrieve_original_sequence_number()</CODE
> or, in Java and .NET, via
		<CODE
CLASS="FUNCTION"
>LBMMessage.osqn()</CODE
>.
		</P
></BLOCKQUOTE
></DIV
>
		</P
><P
>		For the maximum time period to recover lost messages, the HF receiver uses the minimum of the LBT-RM and
		LBT-RU NAK generation intervals (<TT
CLASS="LITERAL"
>transport_lbtrm_nak_generation_interval</TT
>,
		<TT
CLASS="LITERAL"
>transport_lbtru_nak_generation_interval</TT
>). Each transport protocol is configured as normal, but the lost
		message recovery timer is the minimum of the two settings.
		</P
><P
>		Some <TT
CLASS="LITERAL"
>lbm_msg_t</TT
> objects coming from HF receivers may be flagged as having "passed through" the HF
		receiver. This means that the message has not been ordered with other HF messages. These messages have
		the <TT
CLASS="LITERAL"
>LBM_MSG_FLAG_HF_PASS_THROUGH</TT
> flag set. <B
CLASS="APPLICATION"
>UM</B
> flags messages sent from HF sources using
		<TT
CLASS="LITERAL"
>lbm_src_send()</TT
>
		in this manner, as do all non-HF sources. Also, <B
CLASS="APPLICATION"
>UM</B
> flags EOS, no source notification, and requests in
		this manner as well.
		</P
><P
>		For an example receiver application, see <TT
CLASS="LITERAL"
>lbmhfrcv</TT
> in the 
		<A
HREF="../example/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Examples Page</A
>.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="IMPLEMENTING-HFWCRCVRS"
>5.8.3. Implementing Hot Failover Wildcard Receivers</A
></H4
><P
>		To create an HF wildcard receiver, set option <TT
CLASS="LITERAL"
>hf_receiver</TT
> to 1, then create a wildcard receiver with
		<CODE
CLASS="FUNCTION"
>lbm_wildcard_rcv_create()</CODE
>. This actually creates individual HF receivers on a per-topic basis, so that
		each topic can have its own set of HF sequence numbers. Once the HF wildcard receiver detects that all
		sources for a particular topic are gone it closes the individual topic HF receivers and discards the HF
		sequence information (unlike a standard HF receiver). You can extend or control the delete timeout
		period of individual HF receivers with option <TT
CLASS="LITERAL"
>resolver_no_source_linger_timeout</TT
>.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="HF-JAVA-NET"
>5.8.4. Java and .NET</A
></H4
><P
>		For information on implement the HF feature in a Java application, go to <B
CLASS="APPLICATION"
>UM</B
> Java API and see the
		documentation for classes <TT
CLASS="LITERAL"
>LBMHotFailoverReceiver</TT
> and <TT
CLASS="LITERAL"
>LBMHotFailoverSource</TT
>.
		</P
><P
>		For information on implement the HF feature in a .NET application, go to <B
CLASS="APPLICATION"
>UM</B
> .NET API and navigate to
		Namespaces -&#62; com.latencybusters.lbm -&#62; LBMHotFailoverReceiver and LBMHotFailoverSource.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="HF-UMP"
>5.8.5. Using Hot Failover with UMP</A
></H4
><P
>		When implementing Hot Failover with <B
CLASS="APPLICATION"
>UMP</B
>, you must consider the following impact on hardware resources:
		</P
><P
></P
><UL
><LI
><P
>			Additional storage space required for a <B
CLASS="APPLICATION"
>UMP</B
> disk store
		</P
></LI
><LI
><P
>			Higher disk activity
		</P
></LI
><LI
><P
>			Higher network activity
		</P
></LI
><LI
><P
>			Increased application complexity regarding message filtering
		</P
></LI
></UL
><P
>		Also note that you must enable UME explicit ACKs and Hot Failover duplicate delivery in each Hot
		Failover receiving application.
		</P
><P
>		For detailed information on using Hot Failover with <B
CLASS="APPLICATION"
>UMP</B
>, see the Knowledge Base article <A
HREF="https://communities.informatica.com/infakb/faq/5/Pages/80173.aspx?docid=80173&#38;amp;type=external&#38;amp;index=1"
TARGET="_top"
>                <B
CLASS="APPLICATION"
>UMP</B
> Hot Failover</A
>.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="HF-INTENTIONAL-GAP"
>5.8.6. Hot Failover Intentional Gap Support</A
></H4
><P
>		<B
CLASS="APPLICATION"
>UM</B
> supports intentional gaps in HF message streams. Your HF sources can supply 
		message sequence numbers with number gaps up to 1073741824. HF receivers automatically 
		detect the gaps and consider any missing message sequence numbers as not sent and do  
		not attempt recovery for these missing sequence numbers. See the following example.
		</P
><PRE
CLASS="SCREEN"
>HF source 1 sends message sequence numbers: 10, 11, 12, 13, 25, 26, 38
HF source 2 sends message sequence numbers: 10, 11, 12, 13, 25, 26, 38
 
HF receiver 1 receives message sequence numbers in order with no pause between any messages: 
                                            10, 11, 12, 13, 25, 26, 38
		</PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="OPTIONAL-HF-MESSAGES"
>5.8.7. Hot Failover Optional Messages</A
></H4
><P
>		Hot Failover sources can send optional messages that HF receivers can be configured to 
		receive or not receive (<A
HREF="../Config/hotfailoveroperationoptions.html#RECEIVERHFOPTIONALMESSAGES"
TARGET="_top"
>		hf_optional_messages</A
>). HF receivers detect an optional message by checking 
		<CODE
CLASS="FUNCTION"
>lbm_msg_t.flags</CODE
> for LBM_MSG_FLAG_HF_OPTIONAL. 
		HF sources indicate an optional message by passing 
		LBM_SRC_SEND_EX_FLAG_HF_OPTIONAL in the 
		<CODE
CLASS="FUNCTION"
>lbm_src_send_ex_info_t.flags</CODE
> field to 
		<CODE
CLASS="FUNCTION"
>lbm_hf_src_send_ex()</CODE
> or <CODE
CLASS="FUNCTION"
>lbm_hf_src_sendv_ex()</CODE
>. 
		In the examples below, optional messages appear with an "o" after the sequence number.
		</P
><PRE
CLASS="SCREEN"
>HF source 1 sends message sequence numbers: 10, 11, 12, 13o, 14o, 15, 16o, 17o, 18o, 19o, 20
HF source 2 sends message sequence numbers: 10, 11, 12, 13o, 14o, 15, 16o, 17o, 18o, 19o, 20
 
HF receiver 1 receives:                     10, 11, 12, 13o, 14o, 15, 16o, 17o, 18o, 19o, 20
HF receiver 2, configured to ignore optional messages, receives: 
                                            10, 11, 12,           15,                     20
		</PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="HF-ORDERED-DELIVERY"
>5.8.8. Using Hot Failover with Ordered Delivery</A
></H4
><P
>		An HF receiver takes some of its operating parameters directly from the receive topic attributes. The
		<TT
CLASS="LITERAL"
>ordered_delivery</TT
> setting indicates the ordering for the HF receiver. Please see
	 	<A
HREF="#ORDERED-DELIVERY"
><I
>Ordered Delivery</I
></A
>
		for information on the different modes of delivery order.
		</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>		<B
CLASS="APPLICATION"
>UM</B
> supports Arrival Order with HF only when all sources use the same transport type.
		</P
></BLOCKQUOTE
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="HFX"
>5.8.9. Hot Failover Across Multiple Contexts</A
></H4
><P
>		If you have a receiving application on a multi-homed machine receiving HF messages from 
		HF sources, you can set up the Hot Failover Across Contexts (HFX) feature. This involves 
		setting up a separate <B
CLASS="APPLICATION"
>UM</B
> context to receive HF messages over each NIC and then 
		creating an HFX Object, which drops duplicate HF messages arriving over all contexts. Your 
		receiving application then receives only one copy of each HF message. The HFX feature 
		achieves the same effect across multiple contexts as the normal Hot Failover feature does 
		within a single context. 
			</P
><P
>		The following diagram displays Hot Failover operation across <B
CLASS="APPLICATION"
>UM</B
> contexts.
			</P
><DIV
CLASS="FIGURE"
><A
NAME="HFX-OPERATION"
></A
><P
><B
>Figure 13. Hot Failover Across Multiple Contexts</B
></P
><P
><IMG
SRC="Hot_Failover_X.png"
ALIGN="CENTER"></P
></DIV
><P
>		For each context that receives HF messages, create one HFX Receiver per topic. Each 
		HFX Receiver can be configured independently by passing in a <B
CLASS="APPLICATION"
>UM</B
> Receiver attributes 
		object during creation. A unique client data pointer can also be associated with each HFX 
		Receiver. The HFX Object is a special Ultra Messaging object and does not live in any 
		<B
CLASS="APPLICATION"
>UM</B
> context.
			</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>		You never have to call <CODE
CLASS="FUNCTION"
>lbm_topic_lookup()</CODE
> for a HFX Receiver. 
		If you are creating HFX Receivers along with normal <B
CLASS="APPLICATION"
>UM</B
> receivers for the same topic, 
		do not interleave the calls. For example, call <CODE
CLASS="FUNCTION"
>lbm_hfx_create()</CODE
> and 
		<CODE
CLASS="FUNCTION"
>lbm_hfx_rcv_create()</CODE
> for the topic. Then call 
		<CODE
CLASS="FUNCTION"
>lbm_topic_lookup()</CODE
> and <CODE
CLASS="FUNCTION"
>lbm_rcv_create()</CODE
> for 
		the topic to create the normal <B
CLASS="APPLICATION"
>UM</B
> receivers.
			</P
></BLOCKQUOTE
></DIV
><P
>		The following outlines the general procedure for HFX.
			</P
><P
></P
><OL
TYPE="1"
><LI
><P
>		Create an HFX Object for every HF topic of interest with <CODE
CLASS="FUNCTION"
>lbm_hfx_create()</CODE
>, 
		passing in an attributes object created with <CODE
CLASS="FUNCTION"
>lbm_hfx_attr_create()</CODE
> 
		to specify any attributes desired.	
			</P
></LI
><LI
><P
>		Create a context for the first NIC receiving HF messages with 
		<CODE
CLASS="FUNCTION"
>lbm_context_create()</CODE
>.	
			</P
></LI
><LI
><P
>		Create a HFX Receiver for every HF topic with <CODE
CLASS="FUNCTION"
>lbm_hfx_rcv_create()</CODE
>, 
		passing in <B
CLASS="APPLICATION"
>UM</B
> Receive Topic Attributes.	
			</P
></LI
><LI
><P
>		Repeat steps 2 and 3 for all NICs receiving HF message	
			</P
></LI
><LI
><P
>		Receive messages. The HFX Object identifies and drops all duplicates, delivering messages 
		through a single callback (and optional event queue) specified when you created the HFX Object.	
			</P
></LI
></OL
><P
>		Delete each HFX Receiver with <CODE
CLASS="FUNCTION"
>lbm_hfx_rcv_delete()</CODE
> or 
		<CODE
CLASS="FUNCTION"
>lbm_hfx_rcv_delete_ex()</CODE
>. Delete the HFX Object with 
		<CODE
CLASS="FUNCTION"
>lbm_hfx_delete()</CODE
>.
			</P
><P
>		<DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>		When writing source-side HF applications for HFX, be aware that HFX receivers do not support
		<TT
CLASS="LITERAL"
>hf_sequence</TT
>, 64-bit sequence numbers, the
		<CODE
CLASS="FUNCTION"
>lbm_hf_src_send_rcv_reset()</CODE
> function, or HF wildcard receivers.
		</P
></BLOCKQUOTE
></DIV
>
		See also ...
			</P
><P
></P
><UL
><LI
><P
>		<A
HREF="../Config/hotfailoveroperationoptions.html"
TARGET="_top"
>Hot Failover Operation Options</A
> 
		for HFX Configuration Options.
			</P
></LI
><LI
><P
>		<TT
CLASS="LITERAL"
>LBMHFX*.java</TT
> in <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Java API</A
>.
			</P
></LI
><LI
><P
>		<TT
CLASS="LITERAL"
>LBMHFX*.cs</TT
> in <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> .NET API</A
>.
			</P
></LI
></UL
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="MONITORING"
>6. Monitoring UMS</A
></H2
><P
></P
><UL
><LI
><P
>		<A
HREF="#MON-INTRODUCTION"
><I
>Introduction</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#LBM-API-FUNCTIONS"
><I
>UMS API Functions and Data Structures</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#LBM-MONITORING-API"
><I
>UMS Monitoring API</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#AUTOMONITOR"
><I
>Automatic Monitoring</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#MONITORING-EXAMPLES"
><I
>Monitoring Examples</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#INTERPRETING-LBT-RM-SOURCE-STATISTICS"
><I
>Interpreting LBT-RM Source Statistics</I
></A
>      
		</P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="MON-INTRODUCTION"
>6.1. Introduction</A
></H3
><P
>	 Messaging systems often employ real-time monitoring and rapid human intervention to 
	 prevent the system from becoming unstable. The design of <B
CLASS="APPLICATION"
>UM</B
> encourages stable operation 
	 by allowing you to pre-configure how <B
CLASS="APPLICATION"
>UM</B
> will use resources under all traffic and 
	 network conditions. Hence manual intervention is not required when those conditions 
	 occur.
	 </P
><P
>	 Monitoring <B
CLASS="APPLICATION"
>UM</B
> still fills important roles other than maintaining stable operation. 
	 Chiefly among these are capacity planning and a better understanding of the latency 
	 added by <B
CLASS="APPLICATION"
>UM</B
> as it recovers from loss. Collecting accumulated statistics from all 
	 sources and all receivers once per day is generally adequate for these purposes.
	 </P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="WHY-MONITOR"
>6.1.1. Why Monitor?</A
></H4
><P
>	 Monitoring can aid different groups within an organization. 
	 </P
><P
></P
><UL
><LI
><P
>	 Developers can spot bugs that impact system performance.
		</P
></LI
><LI
><P
>	 Performance tuning groups can pinpoint under-performing receivers.
		</P
></LI
><LI
><P
>	 Testing groups can understand the reaction of a system to stresses like random packet 
	 loss during pre-production testing.
		</P
></LI
><LI
><P
>	 Network or middleware management groups can use monitoring to ensure a production 
	 system continues to operate within its design criteria.
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="WHAT-TO-MONITOR"
>6.1.2. What to Monitor</A
></H4
><P
>	 Before discussing the monitoring statistics that are built into <B
CLASS="APPLICATION"
>UM</B
>, we mention two 
	 things that are probably more important to monitor: connectivity and latency. <B
CLASS="APPLICATION"
>UM</B
> 
	 provides some assistance for monitoring these, but the final responsibility rests 
	 with your applications.
	 </P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="CONNECTIVITY"
>6.1.2.1. Connectivity</A
></H5
><P
>	 If you monitor only one thing, monitor connectivity, defined as the ability of your 
	 system components to talk to each other when needed Connectivity failures generally 
	 indicate a software, hardware, or network failure and generally require prompt attention. 
	 <B
CLASS="APPLICATION"
>UM</B
> features like End Of Source (EOS) events, new source notifications, and 
	 receiver connect/disconnect events may help in application connectivity monitoring. 
	 See the lbmprice.c example to see techniques for using these to build an awareness of 
	 when components of the system come and go.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="MESSAGE-LATENCY"
>6.1.2.2. Message Latency</A
></H5
><P
>	 If you monitor only two things, monitor connectivity and the latency of every 
	 message. Connectivity monitoring will catch the hard failures and latency monitoring 
	 will catch the soft failures. Many impending hard failures in hardware, software, and 
	 networks show up first as rises in average latency or as latency spikes. See our white 
	 paper Pragmatic Advice for Handling Market Data Rate Increases for additional comments 
	 on the importance of measuring latency.
	 </P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="MONITOR-METHODS"
>6.1.2.3. Monitoring Methods</A
></H5
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> provides the following four methods to monitor your <B
CLASS="APPLICATION"
>UM</B
> activities.
	 </P
><P
></P
><UL
><LI
><P
>	 Use <B
CLASS="APPLICATION"
>UM</B
> API function calls within your applications to retrieve statistics and 
	 deliver them to your monitoring application.
		</P
></LI
><LI
><P
>	 Use the <B
CLASS="APPLICATION"
>UM</B
> Monitoring API to more easily retrieve and send statistics 
	 to your monitoring application.
		</P
></LI
><LI
><P
>	 Use Automatic Monitoring to easily employ the <B
CLASS="APPLICATION"
>UM</B
> Monitoring API to monitor 
	 <B
CLASS="APPLICATION"
>UM</B
> activity at an <B
CLASS="APPLICATION"
>UM</B
> context level.
		</P
></LI
><LI
><P
>	 Use the <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> <B
CLASS="APPLICATION"
>SNMP Agent</B
> and MIB to monitor statistics through a Network 
	 Management System. The <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> <B
CLASS="APPLICATION"
>SNMP Agent</B
> is purchased separately. 
		</P
></LI
></UL
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="LBM-API-FUNCTIONS"
>6.2. UMS API Functions and Data Structures</A
></H3
><P
>The <B
CLASS="APPLICATION"
>UM</B
> API contains functions that retrieve various 
	 statistics for a context, event queue, source or receiver. This section lists the 
	 functions and constructors you can use to retrieve statistics, along with the 
	 data structures <B
CLASS="APPLICATION"
>UM</B
> uses to deliver the statistics. 
	 Refer to the UMS API documentation (
	 <A
HREF="../API/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> C API</A
>, 
	 <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> Java API</A
> or
	 <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
><B
CLASS="APPLICATION"
>UM</B
> .NET API</A
>) for specific 
	 information about the functions and constructors. Links to the data structures 
	 appear in the tables to provide quick access to the specific statistics available.
	 </P
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="CONTEXTSTATS"
>6.2.1. Context Statistics</A
></H4
><P
>	 Context statistics help you monitor topic resolution activity, along with the number of 
	 unknown messages received and the number of sends and responses that were blocked or 
	 returned EWOULDBLOCK. Context statistics also contain transport statistics for 
	 Multicast Immediate Messaging (MIM) activity and transport statistics for all the 
	 sources or receivers in a context.
	 </P
><DIV
CLASS="INFORMALTABLE"
><P
></P
><A
NAME="AEN2916"
></A
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL
WIDTH="312"><COL
WIDTH="240"><COL
WIDTH="216"><THEAD
><TR
><TH
>C API Function</TH
><TH
>Java or .NET API Constructor</TH
><TH
>Data Structure</TH
></TR
></THEAD
><TBODY
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_context_retrieve_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMContextStatistics(LBMContext ctx)</TT
></TD
><TD
><A
HREF="../API/structlbm__context__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_context_stats_t</TT
></A
></TD
></TR
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_context_retrieve_rcv_transport_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMReceiverStatistics(LBMContext int maxStats)</TT
></TD
><TD
><A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
></TD
></TR
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_context_retrieve_src_transport_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMSourceStatistics(LBMContext int maxStats)</TT
></TD
><TD
><A
HREF="../API/structlbm__src__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_t</TT
></A
></TD
></TR
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_context_retrieve_mim_rcv_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMMIMReceiverStatistics(LBMContext ctx)</TT
></TD
><TD
><A
HREF="../API/structlbm__rcv__transport__stats__lbtrm__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_lbtrm_t</TT
></A
></TD
></TR
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_context_retrieve_mim_src_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMMIMSourceStatistics(LBMContext ctx)</TT
></TD
><TD
><A
HREF="../API/structlbm__src__transport__stats__lbtrm__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_lbtrm_t</TT
></A
></TD
></TR
></TBODY
></TABLE
><P
></P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="EVENTQSTATS"
>6.2.2. Event Queue Statistics</A
></H4
><P
>	 Event Queue statistics help you monitor the number of events currently on the queue, 
	 how long it takes to service them (maximum, minimum and mean service times) and 
	 the total number of events for the monitoring period. 
	 These statistics are available for the following types of events. 
	 </P
><P
></P
><UL
><LI
><P
>	 Data messages
		</P
></LI
><LI
><P
>	 Request messages
		</P
></LI
><LI
><P
>	 Immediate messages
		</P
></LI
><LI
><P
>	 Wildcard receiver messages
		 </P
></LI
><LI
><P
>	 I/O events
		</P
></LI
><LI
><P
>	 Timer events  
		</P
></LI
><LI
><P
>	 Source events
		</P
></LI
><LI
><P
>	 Unblock events
		 </P
></LI
><LI
><P
>	 Cancel events
		</P
></LI
><LI
><P
>	 Callback events
		</P
></LI
><LI
><P
>	 Context source events
		</P
></LI
><LI
><P
>	 Total events
		</P
></LI
><LI
><P
>	 Age of events  
		 </P
></LI
></UL
><P
>	 When monitoring Event Queue statistics you must enable the Event Queue <B
CLASS="APPLICATION"
>UM</B
> 
	 Configuration Options, 
	 <A
HREF="../Config/eventqueueoptions.html#EVENTQUEUEQUEUEAGEENABLED"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>queue_age_enabled</TT
></A
>, 
	 <A
HREF="../Config/eventqueueoptions.html#EVENTQUEUEQUEUECOUNTENABLED"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>queue_count_enabled </TT
></A
> and 
	 <A
HREF="../Config/eventqueueoptions.html#EVENTQUEUEQUEUESERVICETIMEENABLED"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>queue_service_time_enabled </TT
></A
>. <B
CLASS="APPLICATION"
>UM</B
> disables these 
	 options by default, which produces no event queue statistics.
	 </P
><DIV
CLASS="INFORMALTABLE"
><P
></P
><A
NAME="AEN3006"
></A
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL
WIDTH="312"><COL
WIDTH="240"><COL
WIDTH="216"><THEAD
><TR
><TH
>C API Function</TH
><TH
>Java or .NET API Constructor</TH
><TH
>Data Structure</TH
></TR
></THEAD
><TBODY
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_event_queue_retrieve_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMEventQueueStatistics(LBMEventQueue evq)</TT
></TD
><TD
><A
HREF="../API/structlbm__event__queue__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_event_queue_stats_t</TT
></A
></TD
></TR
></TBODY
></TABLE
><P
></P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="TRANSPORTSTATS"
>6.2.3. Transport Statistics</A
></H4
><P
>	 You can retrieve transport statistics for different types of transports 
	 (TCP, LBT-RU, LBT-RM, LBT-IPC, LBT-RDMA). In addition, you can limit these transport statistics 
	 to a specifc source sending on the particular transport or a specifc receiver receiving 
	 messages over the transport. 
	 Source statistics for LBT-RM, for example, include the 
	 number of messages (datagrams) sent and the number of retransmissions sent.  For 
	 receiver LBT-RM, statistics include, for example, the number of messages (datagrams) 
	 received and number of <B
CLASS="APPLICATION"
>UM</B
> messages received. 
	 </P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 None of the three types of transport statistics (all, source, or receiver) are 
	 topic level statistics. Currently UM does not provide topic-specific transport statistics.
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="INFORMALTABLE"
><P
></P
><A
NAME="AEN3031"
></A
><TABLE
BORDER="1"
CLASS="CALSTABLE"
><COL
WIDTH="312"><COL
WIDTH="240"><COL
WIDTH="216"><THEAD
><TR
><TH
>C API Function</TH
><TH
>Java or .NET API Constructor</TH
><TH
>Data Structure</TH
></TR
></THEAD
><TBODY
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_rcv_retrieve_transport_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMReceiverStatistics(LBMReceiver lbmrcv source)</TT
></TD
><TD
><A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
></TD
></TR
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_rcv_retrieve_all_transport_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMReceiverStatistics(LBMReceiver lbmrcv int maxStats)</TT
></TD
><TD
><A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
></TD
></TR
><TR
><TD
><TT
CLASS="LITERAL"
>lbm_src_retrieve_transport_stats()</TT
></TD
><TD
><TT
CLASS="LITERAL"
>LBMSourceStatistics(LBMSource lbmsrc)</TT
></TD
><TD
><A
HREF="../API/structlbm__src__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_t</TT
></A
></TD
></TR
></TBODY
></TABLE
><P
></P
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="LBM-MONITORING-API"
>6.3. UMS Monitoring API</A
></H3
><P
>	 This section discusses the following topics.
		</P
><P
></P
><UL
><LI
><P
>		<A
HREF="#LBM-MONITORING-PROCESS-FLOW"
><I
>UMS Monitoring Process Flow</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#API-FRAMEWORK-FLEXIBILITY"
><I
>API Framework Flexibility</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#INITIAL-MONITORING-QUESTIONS"
><I
>Initial Monitoring Questions</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#CREATING-MONITORING-SOURCE"
><I
>Creating a Monitoring Source</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#SPECIFYING-OBJECT-TO-MONITOR"
><I
>Specifying the Object to Monitor</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#RECEIVING-MONITORING-DATA"
><I
>Receiving Monitoring Data</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#LBM-TRANSPORT-MODULE"
><I
>The UMS Transport Module</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#UDP-TRANSPORT-MODULE"
><I
>The UDP Transport Module</I
></A
>
		</P
></LI
><LI
><P
>		<A
HREF="#SNMP-TRANSPORT-MODULE"
><I
>The SNMP Transport Module</I
></A
>
		</P
></LI
></UL
><P
>	 The <B
CLASS="APPLICATION"
>UM</B
> Monitoring API 
	 (see <A
HREF="../API/lbmmon_8h.html"
TARGET="_top"
><TT
CLASS="LITERAL"
>lbmmon.h</TT
></A
> or the 
	 <TT
CLASS="LITERAL"
>LBMMonitor</TT
> classes in the 
	 <A
HREF="../JavaAPI/html/index.html"
TARGET="_top"
>Java API</A
> and the 
	 <A
HREF="../DotNetAPI/doc/Index.html"
TARGET="_top"
>.NET API</A
>) provides a framework 
	 to easily gather UMS transport statistics and send them to a monitoring or 
	 reporting application. Transport sessions 
	 for sources and receivers, along with all transport sessions for a given context can 
	 be monitored. This API can be implemented in one of two ways.
	 </P
><P
></P
><UL
><LI
><P
>	 Build monitoring into your application with the <B
CLASS="APPLICATION"
>UM</B
> Monitoring API functions.
		</P
></LI
><LI
><P
>	 Turn on Automatic Monitoring with UMS configuration options. See 
	 <A
HREF="#AUTOMONITOR"
><I
>Automatic Monitoring</I
></A
>.  
		</P
></LI
></UL
><P
>	 An application requesting transport monitoring is called a 
	 <B
CLASS="APPLICATION"
>monitor source</B
>, and an application accepting statistics is a 
	 <B
CLASS="APPLICATION"
>monitor receiver</B
>. These monitoring objects 
	 deal only with transport session statistics and should not be confused with <B
CLASS="APPLICATION"
>UM</B
> 
	 sources and <B
CLASS="APPLICATION"
>UM</B
> receivers, which deal with <B
CLASS="APPLICATION"
>UM</B
> messages. Statistics for both <B
CLASS="APPLICATION"
>UM</B
> 
	 sources and <B
CLASS="APPLICATION"
>UM</B
> receivers can be forwarded by a monitor source application.
	 </P
><P
>	 Both a monitor source and monitor receiver comprise three modules:
	 </P
><P
></P
><UL
><LI
><P
>	 A <B
CLASS="APPLICATION"
>format</B
> module, responsible for serializing and 
	 de-serializing the statistics. 
	 The proper transmission between monitor source and monitor receiver requires this 
	 serialization.
		</P
></LI
><LI
><P
>	 A <B
CLASS="APPLICATION"
>transport</B
> module that is responsible for sending and 
	 receiving statistics data.
		</P
></LI
><LI
><P
>	 A <B
CLASS="APPLICATION"
>control</B
> module, responsible for gathering the 
	 statistics, and calling the appropriate functions from the format and transport modules.
		</P
></LI
></UL
><P
>	 You can substitute format and transport modules of your own choosing or creation. 
	 <B
CLASS="APPLICATION"
>UM</B
> Monitoring provides the following sample modules:
		</P
><P
></P
><UL
><LI
><P
>	 LBMMON CSV format module
		</P
></LI
><LI
><P
>	 LBMMON UMS transport module
		</P
></LI
><LI
><P
>	 LBMMON UDP transport module
		</P
></LI
><LI
><P
>	 LBMMON SNMP transport module
		</P
></LI
></UL
><P
>	 To view the source code for all LBMMON transport modules, see 
	 <A
HREF="../API/lbmmon_examples.html"
TARGET="_top"
>LBMMON Example Source Code</A
> found on the 
	 Related Pages tab in the C Application Programmer's Interface. 
		</P
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 The LBMMON SNMP transport module can be used for non-SNMP based monitoring. The 
	 <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> <B
CLASS="APPLICATION"
>SNMP Agent</B
> is not required for its use.
		</P
></BLOCKQUOTE
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="LBM-MONITORING-PROCESS-FLOW"
>6.3.1. UMS Monitoring Process Flow</A
></H4
><P
>	 The overall process flow appears in the diagram below.
	 </P
><DIV
CLASS="FIGURE"
><A
NAME="LBMMONPROCESS"
></A
><P
><B
>Figure 14. UMS Monitoring Process Flow</B
></P
><P
><IMG
SRC="lbmmon.png"
ALIGN="CENTER"></P
></DIV
><P
></P
><OL
TYPE="1"
><LI
><P
>		Your application creates the monitor source controller, specifying the format 
		and transport modules to use. It also calls lbmmon functions to start monitoring 
		an <B
CLASS="APPLICATION"
>UM</B
> context, <B
CLASS="APPLICATION"
>UM</B
> source or <B
CLASS="APPLICATION"
>UM</B
> receiver.
		</P
></LI
><LI
><P
>		The monitor source controller passes those statistics to the format module 
		serialization function.
		</P
></LI
><LI
><P
>		The monitor source controller passes the resulting serialized data to the 
		transport module send function.
		</P
></LI
><LI
><P
>		The transport module transmits the data over some transport medium (such as 
		a network).
		</P
></LI
><LI
><P
>		The monitor receiver controller transport module receives the serialized data. 
		(Your monitoring application has already created the monitor receiver controller 
		specifying the format and transport modules to use, along with the application 
		callback functions to use upon the receipt of <B
CLASS="APPLICATION"
>UM</B
> source or <B
CLASS="APPLICATION"
>UM</B
> receiver statistics data.)
		</P
></LI
><LI
><P
>		The monitor receiver controller calls the  format module's de-serialization function.
		</P
></LI
><LI
><P
>		Finally, the monitor receiver controller passes the statistics to your 
		monitoring application via the specified application callback functions.
		</P
></LI
></OL
><P
>		Your applications only calls functions in the controller modules, which calls 
		the appropriate functions in the transport and format modules.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="API-FRAMEWORK-FLEXIBILITY"
>6.3.2. API Framework Flexibility</A
></H4
><P
>	 The segregation of <B
CLASS="APPLICATION"
>UM</B
> Monitoring into control, format, and transport modules 
	 provides flexibility for monitor receivers in two ways. 
		</P
><P
></P
><UL
><LI
><P
>	 Allows you to use languages for which no <B
CLASS="APPLICATION"
>UM</B
> API or binding exists.
		</P
></LI
><LI
><P
>	 Allows you to use monitoring products which do not integrate with <B
CLASS="APPLICATION"
>UM</B
>.
		</P
></LI
></UL
><P
>	 As an example, assume you have a Perl application which currently gathers 
	 statistics from other network applications (or, you are simply most comfortable 
	 working in Perl for such tasks). There is no Perl binding for <B
CLASS="APPLICATION"
>UM</B
>. However, Perl 
	 can handle UDP packets very nicely, and can pick apart CSV data easily. By 
	 implementing a UDP transport module to be used by the monitor sources, your Perl 
	 application can read the UDP packets and process the statistics.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="INITIAL-MONITORING-QUESTIONS"
>6.3.3. Initial Monitoring Questions</A
></H4
><P
>	 If you can answer the following questions, you're already on your way.
		</P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 What format module will you use? LBMMON CSV Format module or a different one.
	 </P
></LI
><LI
><P
>	 What transport module will you use? One of the 3 LBMMON modules or a different one.
	 </P
></LI
><LI
><P
>	 Do you want to monitor individual sources/receivers, or an entire context? The 
	 difference is in how the statistics are aggregated.</P
><P
></P
><UL
><LI
><P
>		Monitoring a context aggregates transport statistics for all sources and 
		receivers associated with a context, by transport. Note that this is not by 
		transport type. The default configuration for TCP, for example, allocates up 
		to 10 ports, forming up to 10 separate transport sessions. Absent any specific 
		instructions, <B
CLASS="APPLICATION"
>UM</B
> allocates sources and receivers to these 10 transports in a 
		round-robin fashion. So the statistics for a specific transport on a context 
		will aggregate all sources and receivers which use that specific transport.
		</P
></LI
><LI
><P
>		<B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> recommends that you monitor either a context or source/receiver, but not both.
		For example if Topic1 and Topic2 are mapped to the same transport session (which is the
		only transport session for the context) and 
		you monitor both the receivers and the context, you will get 3 identical sets of 
		statistics: one for Topic1 reporting the stats for it's transport session, one for 
		Topic2 reporting the stats for the same transport session, and one for 
		the transport session via the context.
		</P
></LI
><LI
><P
>		In the case of wildcard receivers, only the context may be monitored. <B
CLASS="APPLICATION"
>UM</B
> 
		creates wildcard receivers dynamically as it detects topics which match the 
		wildcard pattern. The application does not have access to these dynamically-created 
		receivers. So the only way to monitor a wildcard receiver is to monitor the 
		context on which it was created.
		</P
></LI
></UL
></LI
><LI
><P
>		Should statistics be sent automatically, or on demand?</P
><P
></P
><UL
><LI
><P
>Automatic sending of statistics is by far the simplest approach. 
		You simply indicate how often the statistics should be gathered and sent. The 
		rest is taken care of.
		</P
></LI
><LI
><P
>		On-demand is somewhat more involved. Your application decides when statistics 
		should be gathered and sent. If you intend to use the arrival of statistics as 
		a type of heartbeat, this is the method you should use.
		</P
></LI
></UL
></LI
></OL
><P
>		The following sections present more discussion and sample source code about 
		starting monitor sources, monitor receivers and the LBMMON format and transport modules.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="CREATING-MONITORING-SOURCE"
>6.3.4. Creating a Monitoring Source</A
></H4
><P
>		The following examples demonstrate how to use the <B
CLASS="APPLICATION"
>UM</B
> Monitoring API to enable 
		monitoring in your application. 
		</P
><P
>		First, create a monitoring source controller:
		</P
><PRE
CLASS="PROGRAMLISTING"
>lbm_context_t * ctx;
lbm_src_t * src;
lbm_rcv_t * rcv;
lbmmon_sctl_t * monctl;

if (lbmmon_sctl_create(&amp;monctl, lbmmon_format_csv_module(), NULL, lbmmon_transport_lbm_module(), NULL) == -1)
{
		fprintf(stderr, "lbmmon_sctl_create() failed\n");
		exit(1);
}</PRE
><P
>	 The above code tacitly assumes that the <TT
CLASS="LITERAL"
>ctx</TT
>, <TT
CLASS="LITERAL"
>src</TT
>, 
	 and <TT
CLASS="LITERAL"
>rcv</TT
> variables have been previously assigned via the appropriate 
	 <B
CLASS="APPLICATION"
>UM</B
> API calls. 
		</P
><P
>	 The monitoring source controller object must be passed to subsequent calls to 
	 reference a specific source controller. One implication of this is that it is 
	 possible to have multiple monitoring source controllers within a single 
	 application, each perhaps monitoring a different set of objects.
		</P
><P
>	 In the above example, the default CSV format module and default <B
CLASS="APPLICATION"
>UM</B
> transport 
	 module are specified via the provided module functions 
	 <TT
CLASS="LITERAL"
>lbmmon_format_csv_module()</TT
> and 
	 <TT
CLASS="LITERAL"
>lbmmon_transport_lbm_module()</TT
>. 
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="SPECIFYING-OBJECT-TO-MONITOR"
>6.3.5. Specifying the Object to Monitor</A
></H4
><P
>	 Once a monitoring source controller is created, the application can monitor a 
	 specific context using:
	 </P
><PRE
CLASS="PROGRAMLISTING"
>if (lbmmon_context_monitor(monctl, ctx, NULL, 10) == -1)
{
		fprintf(stderr, "lbmmon_context_monitor() failed\n");
		exit(1);
}</PRE
><P
>	 The above example indicates that statistics for all transports on the 
	 specified context will be gathered and sent every 10 seconds.
		</P
><P
>	 A <B
CLASS="APPLICATION"
>UM</B
> source can be monitored using: 
		</P
><PRE
CLASS="PROGRAMLISTING"
>if (lbmmon_src_monitor(monctl, src, NULL, 10) == -1)
{
		fprintf(stderr, "lbmmon_src_monitor() failed\n");
		exit(1);
}</PRE
><P
>	 Finally, an <B
CLASS="APPLICATION"
>UM</B
> receiver can be monitored using: 
		</P
><PRE
CLASS="PROGRAMLISTING"
>if (lbmmon_rcv_monitor(monctl, rcv, NULL, 10) == -1)
{
		fprintf(stderr, "lbmmon_rcv_monitor() failed\n");
		exit(1);
}</PRE
><P
>	 The two above examples also request that statistics for all transports on the 
	 specified source or receiver be gathered and sent every 10 seconds. 
		</P
><P
>	 Statistics can also be gathered and sent in an on-demand manner. Passing 0 for 
	 the Seconds parameter to <TT
CLASS="LITERAL"
>lbmmon_context_monitor()</TT
>, 
	 <TT
CLASS="LITERAL"
>lbmmon_src_monitor()</TT
>, or <TT
CLASS="LITERAL"
>lbmmon_rcv_monitor()</TT
> 
	 prevents the automatic gathering and sending of statistics. To trigger the 
	 gather/send process, use:
		</P
><PRE
CLASS="PROGRAMLISTING"
>lbmmon_sctl_sample(monctl);</PRE
><P
>	 Such a call will perform a single gather/send action on all monitored objects (contexts, sources, and receivers) which were registered as on-demand.
		</P
><P
>	 As part of application cleanup, the created monitoring objects should be destroyed. 
	 Each individual object can be de-registered using <TT
CLASS="LITERAL"
>lbmmon_context_unmonitor()</TT
>, 
	 <TT
CLASS="LITERAL"
>lbmmon_src_unmonitor()</TT
>, or <TT
CLASS="LITERAL"
>lbmmon_rcv_unmonitor()</TT
>. 
	 Finally, the monitoring source controller can be destroyed using:
		</P
><PRE
CLASS="PROGRAMLISTING"
>lbmmon_sctl_destroy(monctl);</PRE
><P
>	 Any objects which are still registered will be automatically de-registered 
	 by <TT
CLASS="LITERAL"
>lbmmon_sctl_destroy()</TT
>.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="RECEIVING-MONITORING-DATA"
>6.3.6. Receiving Monitoring Data</A
></H4
><P
>	 To make use of the statistics, an application must be running which receives the 
	 monitor data. This application creates a monitoring receive controller, and 
	 specifies callback functions which are called upon the receipt of source or receiver 
	 statistics data. 
		</P
><P
>	 Use the following to create a monitoring receive controller: 
		</P
><PRE
CLASS="PROGRAMLISTING"
>lbmmon_rctl_t * monctl;
lbmmon_rctl_attr_t * attr;
lbmmon_rcv_statistics_func_t rcvcb = { rcv_statistics_cb };
lbmmon_src_statistics_func_t srccb = { src_statistics_cb };
lbmmon_evq_statistics_func_t evqcb = { evq_statistics_cb };
lbmmon_ctx_statistics_func_t ctxcb = { ctx_statistics_cb };

if (lbmmon_rctl_attr_create(&amp;attr) != 0)
{
	fprintf(stderr, "call to lbmmon_rctl_attr_create() failed, %s\n", lbmmon_errmsg());
	exit(1);
}
if (lbmmon_rctl_attr_setopt(attr, LBMMON_RCTL_RECEIVER_CALLBACK, (void *) &amp;rcvcb, sizeof(rcvcb)) != 0)
{
	fprintf(stderr, "call to lbmmon_rctl_attr_setopt() failed, %s\n", lbmmon_errmsg());
	exit(1);
}
if (lbmmon_rctl_attr_setopt(attr, LBMMON_RCTL_SOURCE_CALLBACK, (void *) &amp;srccb, sizeof(srccb)) != 0)
{
	fprintf(stderr, "call to lbmmon_rctl_attr_setopt() failed, %s\n", lbmmon_errmsg());
	exit(1);
}
if (lbmmon_rctl_attr_setopt(attr, LBMMON_RCTL_EVENT_QUEUE_CALLBACK, (void *) &amp;evqcb, sizeof(evqcb)) != 0)
{
	fprintf(stderr, "call to lbmmon_rctl_attr_setopt() failed, %s\n", lbmmon_errmsg());
	exit(1);
}
if (lbmmon_rctl_attr_setopt(attr, LBMMON_RCTL_CONTEXT_CALLBACK, (void *) &amp;sctxcb, sizeof(ctxcb)) != 0)
{
	fprintf(stderr, "call to lbmmon_rctl_attr_setopt() failed, %s\n", lbmmon_errmsg());
	exit(1);
}
if (lbmmon_rctl_create(&amp;monctl, lbmmon_format_csv_module(), NULL, lbmmon_transport_lbm_module(), (void *) 
transport_options, attr) != 0)
{
	fprintf(stderr, "call to lbmmon_rctl_create() failed, %s\n", lbmmon_errmsg());
	exit(1);
}
if (lbmmon_rctl_attr_delete(attr) != 0)
{
	fprintf(stderr, "call to lbmmon_rctl_attr_delete() failed, %s\n", lbmmon_errmsg());
	exit(1);
}</PRE
><P
>	 As in the earlier example, the default CSV format module and default 
	 <B
CLASS="APPLICATION"
>UM</B
> transport module are specified via the provided module functions 
	 <TT
CLASS="LITERAL"
>lbmmon_format_csv_module()</TT
> and 
	 <TT
CLASS="LITERAL"
>lbmmon_transport_lbm_module()</TT
>.
		</P
><P
>As an example of minimal callback functions, consider the following example:
		</P
><PRE
CLASS="PROGRAMLISTING"
>void rcv_statistics_cb(const void * AttributeBlock, const lbm_rcv_transport_stats_t * Statistics)
{
	lbm_ulong_t source = LBMMON_ATTR_SOURCE_NORMAL;
	if (lbmmon_attr_get_source(AttributeBlock, &amp;source) != 0)
	{
		source = LBMMON_ATTR_SOURCE_NORMAL;
	}
	switch (Statistics-&#62;type)
	{
		case LBM_TRANSPORT_STAT_TCP:
			handle_rcv_tcp_statistics();
			break; 
		case LBM_TRANSPORT_STAT_LBTRM:
			switch (source)
			{
				case LBMMON_ATTR_SOURCE_IM:
					handle_rcv_im_lbtrm_statistics();
					break;
				default:
					handle_rcv_lbtrm_statistics();
					break;
			}
			break;
		case LBM_TRANSPORT_STAT_LBTRU:
			handle_rcv_lbtru_statistics();
			break;
	}
}

void src_statistics_cb(const void * AttributeBlock, const lbm_src_transport_stats_t * Statistics)
{
	lbm_ulong_t source = LBMMON_ATTR_SOURCE_NORMAL;
	if (lbmmon_attr_get_source(AttributeBlock, &amp;source) != 0)
	{
		source = LBMMON_ATTR_SOURCE_NORMAL;
	}
	switch (Statistics-&#62;type)
	{
		case LBM_TRANSPORT_STAT_TCP:
			handle_src_tcp_statistics();
			break;
		case LBM_TRANSPORT_STAT_LBTRM:
			switch (source)
			{
				case LBMMON_ATTR_SOURCE_IM:
					handle_src_im_lbtrm_statistics();
					break;
				default:
					handle_src_lbtrm_statistics();
					break;
			}
			break;
		case LBM_TRANSPORT_STAT_LBTRU:
			handle_src_lbtru_statistics();
			break;
	}
}

void ctx_statistics_cb(const void * AttributeBlock, const lbm_context_stats_t * Statistics)
{
	/* Handle context stats */
}

void evq_statistics_cb(const void * AttributeBlock, const lbm_event_queue_stats_t * Statistics)
{
	/* Handle event queue stats */
}</PRE
><P
>	 Upon receipt of a statistics message, the appropriate callback function is called. 
	 The application can then do whatever is desired with the statistics data, which 
	 might include writing it to a file or database, performing calculations, or whatever 
	 is appropriate. 
		</P
><P
>	 Beyond the actual statistics, several additional pieces of data are sent with each 
	 statistics packet. These data are stored in an attribute block, and are accessible 
	 via the <TT
CLASS="LITERAL"
>lbmmon_attr_get_*()</TT
> functions. Currently, these data include 
	 the IPV4 address of machine which sent the statistics data, the timestamp (as a time_t) 
	 at which the statistics were generated, and the application ID string supplied by 
	 the sending application at the time the object was registered for monitoring. See 
	 <TT
CLASS="LITERAL"
>lbmmon_attr_get_ipv4sender()</TT
>, 
	 <TT
CLASS="LITERAL"
>lbmmon_attr_get_timestamp()</TT
>, and 
	 <TT
CLASS="LITERAL"
>lbmmon_attr_get_appsourceid()</TT
> for more information. 
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="LBM-TRANSPORT-MODULE"
>6.3.7. The UMS Transport Module</A
></H4
><P
>	 The <B
CLASS="APPLICATION"
>UM</B
> transport module understands several options which may be used to customize 
	 your use of the module. The options are passed via the TransportOptions parameter to 
	 the <TT
CLASS="LITERAL"
>lbmmon_sctl_create()</TT
> and <TT
CLASS="LITERAL"
>lbmmon_rctl_create()</TT
>
	 functions, as a null-terminated string containing semicolon-separated name/value pairs.
		</P
><P
>	 The following options are available:</P
><P
></P
><UL
><LI
><P
>	 <TT
CLASS="LITERAL"
>config</TT
> specifies a configuration file. This file is processed in 
	 a manner similar to <TT
CLASS="LITERAL"
>lbm_config()</TT
>. However, unlike 
	 <TT
CLASS="LITERAL"
>lbm_config()</TT
>, the current default attributes are not changed. 
	 Instead, the options parsed from the configuration file are applied only to the 
	 <B
CLASS="APPLICATION"
>UM</B
> objects created by the module.
		</P
></LI
><LI
><P
>	 <TT
CLASS="LITERAL"
>topic</TT
> specifies the topic name to use for sending and receiving 
	 statistics. By default, the topic <TT
CLASS="LITERAL"
>/29west/statistics</TT
> is used.
		</P
></LI
><LI
><P
>	 <TT
CLASS="LITERAL"
>wctopic</TT
> specifies (for monitor receivers only) a wildcard pattern 
	 to be used to receive statistics.
		</P
></LI
></UL
><P
>	  As an example, assume your application needs to use a special configuration file 
	  for statistics. The following call allows your application to customize the <B
CLASS="APPLICATION"
>UM</B
> 
	  transport module using the configuration file <TT
CLASS="LITERAL"
>stats.cfg</TT
>.
		 </P
><PRE
CLASS="PROGRAMLISTING"
>lbmmon_sctl_t * monctl;
const char * tropt = "config=stats.cfg";
if (lbmmon_sctl_create(&amp;smp;monctl, lbmmon_format_csv_module(), NULL, 
lbmmon_transport_lbm_module(), tropt) == -1)
{
		fprintf(stderr, "lbmmon_sctl_create() failed\n");
		exit(1);
}</PRE
><P
>	 If your application also needs to use a specific topic for statistics, the following 
	 code specifies that, in addition to the configuration file, the topic 
	 <TT
CLASS="LITERAL"
>StatisticsTopic</TT
> be used for statistics.
		</P
><PRE
CLASS="PROGRAMLISTING"
>lbmmon_sctl_t * monctl;
const char * tropt = "config=stats.cfg;topic=StatisticsTopic";
if (lbmmon_sctl_create(&amp;monctl, lbmmon_format_csv_module(), NULL, lbmmon_transport_lbm_module(), 
tropt) == -1)
{
		fprintf(stderr, "lbmmon_sctl_create() failed\n");
		exit(1);
}</PRE
><P
>	 It is important to use the same topic and configuration for both monitor sources 
	 and receivers. Otherwise your applications may send the statistics, but the monitor 
	 receiver won't be able to receive them.
		</P
><P
>	 To view the source code for all LBMMON transport modules, see 
	 <A
HREF="../API/lbmmon_examples.html"
TARGET="_top"
>LBMMON Example Source Code</A
> found on the 
	 Related Pages tab in the C Application Programmer's Interface. 
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="UDP-TRANSPORT-MODULE"
>6.3.8. The UDP Transport Module</A
></H4
><P
>		The UDP transport module understands several options which may be used to 
		customize your use of the module. The options are passed via the 
		<CODE
CLASS="PARAMETER"
>TransportOptions</CODE
> parameter to the 
		<TT
CLASS="LITERAL"
>lbmmon_sctl_create()</TT
> and 
		<TT
CLASS="LITERAL"
>lbmmon_rctl_create()</TT
> functions, as a null-terminated 
		string containing semicolon-separated name/value pairs. 
		</P
><P
>		The UDP module supports sending and receiving via UDP unicast, UDP broadcast, 
		and UDP multicast. The following options are available.
		</P
><P
></P
><UL
><LI
><P
>		<TT
CLASS="LITERAL"
>address</TT
> specifies the unicast IP address to which statistics 
		are sent via UDP. Applicable to sender only.
		</P
></LI
><LI
><P
>		<TT
CLASS="LITERAL"
>port</TT
> is the IP port packets are sent to. Defaults to 2933.
		</P
></LI
><LI
><P
>		<TT
CLASS="LITERAL"
>interface</TT
> specifies the network interface over which multicast 
		UDP is sent or received.
		</P
></LI
><LI
><P
>		<TT
CLASS="LITERAL"
>mcgroup</TT
> is the multicast group on which to send and receive 
		UDP packets.
		</P
></LI
><LI
><P
>		<TT
CLASS="LITERAL"
>bcaddress</TT
> specified the broadcast address to which UDP packets 
		are sent. Applicable to sender only.
		</P
></LI
><LI
><P
>		<TT
CLASS="LITERAL"
>ttl</TT
> specifies the TTL for each multicast UDP packet. Applicable 
		to sender only.
		</P
></LI
></UL
><P
>	 To view the source code for all LBMMON transport modules, see 
	 <A
HREF="../API/lbmmon_examples.html"
TARGET="_top"
>LBMMON Example Source Code</A
> found on the 
	 Related Pages tab in the C Application Programmer's Interface. 
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="SNMP-TRANSPORT-MODULE"
>6.3.9. The SNMP Transport Module</A
></H4
><P
>	 The SNMP transport modules operates in identical fashion to the 
	 UMS Transport Module. 
	 See <A
HREF="#LBM-TRANSPORT-MODULE"
><I
>The UMS Transport Module</I
></A
>
	 </P
><P
>	 To view the source code for all LBMMON transport modules, see 
	 <A
HREF="../API/lbmmon_examples.html"
TARGET="_top"
>LBMMON Example Source Code</A
> found on the 
	 Related Pages tab in the C Application Programmer's Interface. 
		</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="AUTOMONITOR"
>6.4. Automatic Monitoring</A
></H3
><P
>	 Instead of building a monitoring capability into your application 
	 using the <B
CLASS="APPLICATION"
>UM</B
> Monitoring API, automatic monitoring allows you to 
	 easily produce monitoring statistics with the <B
CLASS="APPLICATION"
>UM</B
> Monitoring API 
	 by setting a few simple <B
CLASS="APPLICATION"
>UM</B
> configuration options. Automatic 
	 monitoring does not require any changes to your application. 
	 You control Automatic Monitoring with eight 
	 <A
HREF="../Config/automaticmonitoringoptions.html"
TARGET="_top"
>Automatic Monitoring Options</A
>.
		</P
><P
>	 You can enable Automatic Monitoring for either or both of the following.
		</P
><P
></P
><UL
><LI
><P
>	 <B
CLASS="APPLICATION"
>Transport Statistics</B
> - Automatic 
	 monitoring of transport statistics reflect data for all the transport sessions within 
	 the <B
CLASS="APPLICATION"
>UM</B
> context. You cannot, however, receive statistics for an individual 
	 transport session. Essentially, you turn on automatic monitoring of a context's
	 transport sessions by specifying a 
	 <A
HREF="../Config/automaticmonitoringoptions.html#CONTEXTMONITORINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>context monitor_interval</TT
></A
>. 
	 The use of the <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> <B
CLASS="APPLICATION"
>SNMP Agent</B
> requires the 
	 <TT
CLASS="LITERAL"
>lbmsnmp</TT
> 
	 <A
HREF="../Config/automaticmonitoringoptions.html#CONTEXTMONITORTRANSPORT"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>monitor_transport</TT
></A
>.
		</P
></LI
><LI
><P
>	 <B
CLASS="APPLICATION"
>Event Queue Statistics</B
> - Automatic Monitoring of 
	 Event Queues provides statistics for all the Event Queues within the <B
CLASS="APPLICATION"
>UM</B
> context. 
	 You turn on automatic monitoring of a context's Event Queues by specifying a 
	 <A
HREF="../Config/automaticmonitoringoptions.html#CONTEXTMONITORINTERVAL"
TARGET="_top"
>	 <TT
CLASS="LITERAL"
>event_queue monitor_interval</TT
></A
>. 
		</P
></LI
></UL
><P
>	 You can also set environment variables to turn on automatic monitoring 
	 for all <B
CLASS="APPLICATION"
>UM</B
> contexts (transports and event queues). See 
	 <A
HREF="../Config/automaticmonitoringoptions.html"
TARGET="_top"
>Automatic Monitoring Options</A
> 
	 for more information.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="MONITORING-EXAMPLES"
>6.5. Monitoring Examples</A
></H3
><P
>	 This section demonstrates the use of the two <B
CLASS="APPLICATION"
>UM</B
> monitoring example applications 
	 described in /doc/example/index.html. We present 
	 advice based on what we have seen productively monitored by customers and our own 
	 knowledge of transport statistics that might be of interest. Of course, what you 
	 choose to monitor depends on your needs so merge these thoughts with your own needs 
	 to determine what is best for you.
		</P
><P
></P
><UL
><LI
><P
>	 <A
HREF="#LBMMON"
><I
>lbmmon.c</I
></A
>
	 </P
></LI
><LI
><P
>	 <A
HREF="#LBMMONUDP"
><I
>lbmmonudp.c and lbmmondiag.pl</I
></A
>
	 </P
></LI
></UL
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="LBMMON"
>6.5.1. lbmmon.c</A
></H4
><P
>	 The example application <B
CLASS="APPLICATION"
>lbmmon.c</B
> acts as a Monitor Receiver 
	 and is provided in both executable and source form. It writes monitoring 
	 statistics to the screen and can be used in conjunction with other example applications 
	 (which act as the Monitor Sources).
	 The following procedure uses <B
CLASS="APPLICATION"
>lbmrcv</B
> and 
	 <B
CLASS="APPLICATION"
>lbmsrc</B
> 
	 to create messaging traffic and adds a configuration file in order to specify 
	 the LBT-RM transport instead of the TCP default. (The LBT-RM transport displays 
	 more statistics than TCP.)
		</P
><P
>	 Since <B
CLASS="APPLICATION"
>UM</B
> does not generate monitoring statistics by default, you must activate 
	 monitoring in your application. For the example application, use the 
	 <TT
CLASS="LITERAL"
>--monitor-ctx=n</TT
> option where <TT
CLASS="LITERAL"
>n</TT
> is the number 
	 of seconds between reports. The following procedure activates monitoring on the 
	 receiver, specifying the context (ctx) to create a complete set of receiver 
	 statistics. You could activate monitoring in a similar fashion on the source 
	 and create source statistics.
		</P
><P
>	 To use <B
CLASS="APPLICATION"
>lbmmon</B
> to view statistics from sample application output:
		</P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Create configuration file with the single option of 
	 <TT
CLASS="LITERAL"
>source transport lbtrm</TT
> and name it <TT
CLASS="LITERAL"
>LBTRM.cfg</TT
>.
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmmon --transport-opts="config=LBTRM.cfg"</TT
>
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmrcv -c LBTRM.cfg --monitor-ctx=5 Arizona</TT
>
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmsrc -c LBTRM.cfg Arizona</TT
>
		</P
></LI
></OL
><P
>	 After <B
CLASS="APPLICATION"
>lbmsrc</B
> completes, the final output for 
	 <B
CLASS="APPLICATION"
>lbmmon</B
> should closely resemble the following. 
		</P
><PRE
CLASS="SCREEN"
>Receiver statistics received from C:\Program Files\29West\UME_1.2.1\Win2k-i386\bin\lbmrcv.exe 
at 10.29.1.78, sent Wed Jan 09 14:25:49 2008
Source: LBTRM:10.29.1.78:4391:323382d8:224.10.10.10:4400
Transport: LBT-RM
LBT-RM messages received                                 : 45455
Bytes received                                           : 370000000
LBT-RM NAK packets sent                                  : 0
LBT-RM NAKs sent                                         : 0
Lost LBT-RM messages detected                            : 0
NCFs received (ignored)                                  : 0
NCFs received (shed)                                     : 0
NCFs received (retransmit delay)                         : 0
NCFs received (unknown)                                  : 0
Loss recovery minimum time                               : 4294967295ms
Loss recovery mean time                                  : 0ms
Loss recovery maximum time                               : 0ms
Minimum transmissions per individual NAK                 : 4294967295
Mean transmissions per individual NAK                    : 0
Maximum transmissions per individual NAK                 : 0
Duplicate LBT-RM data messages received                  : 0
LBT-RM messages unrecoverable (window advance)           : 0
LBT-RM messages unrecoverable (NAK generation expiration): 0
LBT-RM LBM messages received                             : 10000000
LBT-RM LBM messages received with no topic               : 0
LBT-RM LBM requests received                             : 0
		</PRE
><P
>	 Notes:
		</P
><P
></P
><UL
><LI
><P
>	 Since this procedure was done on a single machine. No packets were lost and 
	 therefore <B
CLASS="APPLICATION"
>lbmrcv</B
> did not generate any NAKs and 
	 <B
CLASS="APPLICATION"
>lbmsrc</B
> did not send any NCFs. If you run this procedure 
	 across a network, packets may be lost and you would see statistics for NAKs, 
	 NCFs and loss recovery.
		</P
></LI
><LI
><P
>	 This procedure activates monitoring on the receiver, specifying the context 
	 (<TT
CLASS="LITERAL"
>--monitor-ctx</TT
>) to create a complete set of receiver transport 
	 statistics. You could activate monitoring in a similar fashion on the source and 
	 create source statistics. Each set of statistics shows one side of the transmission. 
	 For example, source statistics contain information about NAKs received by the source 
	 (ignored, shed, retransmit delay, etc.) where receiver statistics contain data about 
	 NCFs received. Each view can be helpful.
		</P
></LI
><LI
><P
>	 Moreover, as explained earlier in Specifying the Object to Monitor, individual 
	 receivers or sources can be monitored instead of all transport activity for a context. 
	 For this procedure, use <TT
CLASS="LITERAL"
>--monitor-rcv</TT
> or <TT
CLASS="LITERAL"
>--monitor-src</TT
>.
		</P
></LI
><LI
><P
>	 You could run this procedure again specifying a different transport (LBT-RU or TCP) 
	 in the configuration file and receive a different set of statistics. 
	 For descriptions of all the transport statistics, refer to the transport 
	 statistics data structures in the C Application Programmer's Interface.
	 Click on the Data Structures tab at the top and click on 
	 <A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
> 
	 or 
	 <A
HREF="../API/structlbm__src__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_t</TT
></A
>.
		</P
></LI
></UL
></DIV
><DIV
CLASS="SECTION"
><HR><H4
CLASS="SECTION"
><A
NAME="LBMMONUDP"
>6.5.2. lbmmonudp.c and lbmmondiag.pl</A
></H4
><P
>	 The example application, <B
CLASS="APPLICATION"
>lbmmonudp.c</B
> receives <B
CLASS="APPLICATION"
>UM</B
> statistics and 
	 forwards them as CSV data over a UDP transport. The Perl script, 
	 <B
CLASS="APPLICATION"
>lbmmondiag.pl</B
>, can 
	 read UDP packets and process the statistics, reporting Severity 1 and Severity 2 
	 events. This script only reports on LBT-RM transports.
		</P
><P
>	 To run  <B
CLASS="APPLICATION"
>lbmmonudp.c</B
> with <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
>, 
	 use the following procedure.
	 </P
><P
></P
><OL
TYPE="1"
><LI
><P
>	 Create configuration file with the single option of <TT
CLASS="LITERAL"
>source transport lbtrm</TT
> and name it <TT
CLASS="LITERAL"
>LBTRM.cfg</TT
>.
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmmonudp -a 127.0.0.1 --transport-opts="config=LBTRM.cfg"</TT
>
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmrcv -c LBTRM.cfg --monitor-ctx=5 Arizona</TT
>
		</P
></LI
><LI
><P
>	 Run <TT
CLASS="LITERAL"
>lbmsrc -c LBTRM.cfg Arizona</TT
>
		</P
></LI
><LI
><P
>	 Run  <TT
CLASS="LITERAL"
>lbmmondiag.pl</TT
>
		</P
></LI
></OL
><P
>	 The following sections discuss some of the possible results of this procedure. 
	 Your results will vary depending upon conditions in your network or if you run the 
	 procedure on a single machine.
		</P
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="UNRECOVERABLE-LOSS"
>6.5.2.1. Severity 1 -- Monitoring Unrecoverable Loss</A
></H5
><P
>	 The most severe system problems are often due to unrecoverable datagram loss at 
	 the reliable transport level. These are reported as severity 1 events by the 
	 <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> example script. Many of the scalability and latency 
	 benefits of <B
CLASS="APPLICATION"
>UM</B
> come from the use of reliable transport protocols like LBT-RM and 
	 LBT-RU. These protocols provide loss detection, retransmission, and recovery up to 
	 the limits specified by an application. Unrecoverable loss is reported by the transport 
	 when loss repair is impossible within the specified limits.
		</P
><P
>	 Unrecoverable transport loss often (but not always) leads to unrecoverable message 
	 loss so it is very significant to applications that benefit from lossless message delivery.
		</P
><P
>	 Unrecoverable loss can be declared by receivers when the 
	 <A
HREF="../Config/transportlbt-rmreliabilityoptions.html#RECEIVERTRANSPORTLBTRMNAKGENERATIONINTERVAL"
TARGET="_top"
>	 <CODE
CLASS="PARAMETER"
>transport_lbtrm_nak_generation_interval</CODE
></A
> has ended without 
	 receipt of repair. Each such loss event is recorded by incrementing the 
	 <TT
CLASS="LITERAL"
>unrecovered_tmo</TT
> field in 
	 <A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
>. 
	 Output from <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> might look like this:
		</P
><PRE
CLASS="SCREEN"
>	 Sev1: 34 datagrams unrecovered due to NAK generation interval ending
		</PRE
><P
>	 Unrecoverable loss can also be triggered at receivers by notice from a source 
	 that the lost datagram has passed out of the source's transmission window. Each 
	 such loss event is recorded by incrementing the <TT
CLASS="LITERAL"
>unrecovered_txw</TT
> 
	 field in <A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
>. Output from 
	 <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> might look like this:
		</P
><PRE
CLASS="SCREEN"
>	 Sev1: 249 datagrams unrecovered due to transmission window advancement
		</PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RATE-CONTROLLER"
>6.5.2.2. Severity 2 -- Monitoring Rate Controller Activity</A
></H5
><P
>	 The data and retransmission rate controllers built into LBT-RM provide for stable 
	 operation under all traffic conditions. These rate controllers introduce some 
	 latency at the source since that is generally preferable to the alternative of 
	 NAK storms or other unstable states. The <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> example 
	 script reports this activity as a severity 2 event since latency is normally the 
	 only effect of their operation.
	 </P
><P
>	 Activity of the rate controller indicates that a source tried to send faster than 
	 the configured <A
HREF="../Config/transportlbt-rmoperationoptions.html#CONTEXTTRANSPORTLBTRMDATARATELIMIT"
TARGET="_top"
>	 <CODE
CLASS="PARAMETER"
>transport_lbtrm_data_rate_limit</CODE
></A
>. Normally, this 
	 limit is set to the speed of the fastest receivers. Sending faster than this rate 
	 would induce loss in all receivers so it is generally best to add latency at the 
	 source or avoid sending in such situations.
	 </P
><P
>	 The current number of datagrams queued by the rate controller is given in the 
	 <TT
CLASS="LITERAL"
>rctlr_data_msgs</TT
> field in  
	 <A
HREF="../API/structlbm__src__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_t</TT
></A
>. No more than 10 datagrams are 
	 ever queued. Output from <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> might look like this:
	 </P
><PRE
CLASS="SCREEN"
>	 Sev2: 10 datagrams queued by data rate controller
	 </PRE
><P
>	 Activity of the retransmission rate controller indicates that receivers have 
	 requested retransmissions in excess of the configured <A
HREF="../Config/transportlbt-rmoperationoptions.html#CONTEXTTRANSPORTLBTRMRETRANSMITRATELIMIT"
TARGET="_top"
>	 <CODE
CLASS="PARAMETER"
>transport_lbtrm_retransmit_rate_limit</CODE
></A
>. Latency is added to 
	 retransmission requests in excess of the limit to control the amount of latency 
	 they may add to messages being sent the first time. This behavior avoids NAK storms.
	 </P
><P
>	 The current number of datagrams queued by the retransmission rate controller is 
	 given in the <TT
CLASS="LITERAL"
>rctlr_rx_msgs</TT
> field in  
	 <A
HREF="../API/structlbm__src__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_t</TT
></A
>. No more than 101 datagrams 
	 are ever queued. Output from <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> might look like this:
	 </P
><PRE
CLASS="SCREEN"
>	 Sev2: 101 datagrams queued by retransmission rate controller
	 </PRE
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="RECEIVER-RECOVERY"
>6.5.2.3. Severity 2 -- Monitoring Loss Recovery Activity 
	 for a Receiver</A
></H5
><P
>	 It is important to monitor loss recovery activity because it always adds latency 
	 if the loss is successfully repaired. <B
CLASS="APPLICATION"
>UM</B
> defaults generally provide for quite a 
	 bit of loss recovery activity before loss would become unrecoverable. Statistics 
	 on such activity are maintained at both the source and receiver. Unrecoverable loss 
	 will normally be preceded by a burst of such activity.
		</P
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> receivers measure the amount of time required to repair each loss detected. For 
	 each transport session, an exponentially weighted moving average is computed from 
	 repair times and the maximum and minimum times are tracked.
		</P
><P
>	 The total number of losses detected appears in the lost field in 
	 <A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
>. It may be multiplied by the 
	 average repair time given in the <TT
CLASS="LITERAL"
>nak_stm_mean</TT
> field in 
	 <A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
> to estimate of the amount of 
	 latency that was added to repair loss. This is probably the single most important 
	 metric to track for those interested in minimizing repair latency. The 
	 <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> script reports this whenever the lost field changes 
	 and the average repair time is nonzero. Output might look like this:
		</P
><PRE
CLASS="SCREEN"
>	 Sev2: 310 datagrams lost
	 Sev2: 112.236 seconds estimated total latency due to repair of 564 losses
		</PRE
><DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>	 This estimate only includes latency added in the recovery of lost messages. 
	 Requiring ordered delivery also adds latency for all messages that arrive after 
	 the time of loss and before the time that repair arrives. See the 
	 <CODE
CLASS="PARAMETER"
>ordered_delivery</CODE
> option to control this.
		</P
></BLOCKQUOTE
></DIV
><P
>	 In addition to counting losses detected, <B
CLASS="APPLICATION"
>UM</B
> reliable receivers also count the 
	 number of NAKs generated in the <TT
CLASS="LITERAL"
>naks_sent</TT
> field in 
	 <A
HREF="../API/structlbm__rcv__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_rcv_transport_stats_t</TT
></A
>. Output from 
	 <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> might look like this:
		</P
><PRE
CLASS="SCREEN"
>	 Sev2: 58 NAKs sent
		</PRE
><P
>	 Those who are new to reliable multicast protocols are sometimes surprised to 
	 learn that losses detected do not always lead to NAK generation. If a datagram 
	 is lost in the network close to the source, it is common for many receivers to 
	 detect loss simultaneously when a datagram following the loss arrives. Scalability 
	 would suffer if all receivers that detected loss reported it by generating a NAK 
	 at the same time. To improve scalability, a random delay is added to NAK generation 
	 at each receiver. Since retransmissions are multicast, often only one NAK is 
	 generated to repair the loss for all receivers. Thus it is common for the number 
	 of losses detected to be much larger than the number of NAKs sent, especially when 
	 there are many receivers with similar loss patterns.
		</P
></DIV
><DIV
CLASS="SECTION"
><HR><H5
CLASS="SECTION"
><A
NAME="SOURCE-RECOVERY"
>6.5.2.4. Severity 2 -- Monitoring Loss Recovery Activity 
	 for a Source</A
></H5
><P
>	 For sources, the principal concern is often understanding how much the retransmission 
	 of messages already sent at least once slowed down the source. Obviously, bandwidth 
	 and CPU time spent servicing retransmission requests cannot be used to send new messages. 
	 This is the way that lossy receivers add latency for lossless receivers.
		</P
><P
>	 <B
CLASS="APPLICATION"
>UM</B
> sources track the number of NAKs received in the <TT
CLASS="LITERAL"
>naks_rcved</TT
> 
	 field in <A
HREF="../API/structlbm__src__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_t</TT
></A
>. The number of datagrams that 
	 they retransmit to repair loss is recorded in the <TT
CLASS="LITERAL"
>rxs_sent</TT
> 
	 field in <A
HREF="../API/structlbm__src__transport__stats__t__stct.html"
TARGET="_top"
>		<TT
CLASS="LITERAL"
>lbm_src_transport_stats_t</TT
></A
>.
		</P
><P
>	 The number of retransmitted datagrams may be multiplied by the average datagram 
	 size and divided by the wire speed to estimate the amount of latency added to new 
	 messages by retransmission. Output from the example <TT
CLASS="FILENAME"
>lbmmondiag.pl</TT
> 
	 script might look like this:
		</P
><PRE
CLASS="SCREEN"
>	 Sev2: 7478 NAKs received
	 Sev2: 50 retransmissions sent
	 Sev2: 0.015056 seconds estimated total latency due to retransmissions
		</PRE
></DIV
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H3
CLASS="SECTION"
><A
NAME="INTERPRETING-LBT-RM-SOURCE-STATISTICS"
>6.6. Interpreting LBT-RM Source Statistics</A
></H3
><P
>LBT-RM sources maintain many statistics that can be useful
	 in diagnosing reliable multicast problems.
	 See the <B
CLASS="APPLICATION"
>UM</B
> API documentation
	 <A
HREF="../API/structlbm__src__transport__stats__lbtrm__t__stct.html"
TARGET="_top"
><CODE
CLASS="FUNCTION"
>lbm_src_transport_stats_lbtrm_t</CODE
>
	 Structure Reference</A
> for a description of the fields.
	 The remainder of this section gives advice on interpreting
	 the statistics.</P
><P
>Divide <CODE
CLASS="FUNCTION"
>naks_rcved</CODE
> by
	 <CODE
CLASS="FUNCTION"
>msgs_sent</CODE
> to find the likelihood that
	 sending a message resulted in a NAK being received.
	 Expect no more than a few percent on a network with reasonable
	 loss levels.</P
><P
>	 </P
><P
>Divide <CODE
CLASS="FUNCTION"
>rxs_sent</CODE
> by
	 <CODE
CLASS="FUNCTION"
>msgs_sent</CODE
> to find the ratio of retransmissions
	 to new data.
	 Many NAKs arriving at a source will cause many retransmissions.</P
><P
>Divide <CODE
CLASS="FUNCTION"
>naks_shed</CODE
> by
	 <CODE
CLASS="FUNCTION"
>naks_rcved</CODE
> to find the likelihood that excessive
	 NAKs were ignored.
	 Consider reducing loss to avoid NAK generation.</P
><P
>Divide <CODE
CLASS="FUNCTION"
>naks_rcved</CODE
> by
	 <CODE
CLASS="FUNCTION"
>nak_pckts_rcved</CODE
> to find the likelihood that
	 NAKs arrived individually (~1&nbsp;-&#62;&nbsp;individual NAKs likely;
	 ~0&nbsp;-&#62;&nbsp;NAKs likely to have arrived grouped in a single packet).
	 Individual NAKs often indicate sporadic loss while grouped NAKs
	 often indicate burst loss.</P
><P
>Divide <CODE
CLASS="FUNCTION"
>naks_rx_delay_ignored</CODE
> by
	 <CODE
CLASS="FUNCTION"
>naks_ignored</CODE
> to find the likelihood that
	 NAKs arrived during the ignore interval following a retransmission.
	 The configuration option
	  <A
HREF="../Config/transportlbt-rmreliabilityoptions.html#SOURCETRANSPORTLBTRMIGNOREINTERVAL"
TARGET="_top"
>		  <CODE
CLASS="PARAMETER"
>transport_lbtrm_ignore_interval</CODE
>
	  </A
>
	 controls the length of this interval.</P
></DIV
></DIV
><DIV
CLASS="SECTION"
><HR><H2
CLASS="SECTION"
><A
NAME="LBMRD-MANPAGE"
>7. Manpage for lbmrd</A
></H2
><DIV
CLASS="TOC"
><DL
><DT
><B
>Table of Contents</B
></DT
><DT
><A
HREF="#LBMRD"
>lbmrd</A
>&nbsp;--&nbsp;UMS Resolver Daemon, for unicast topic resolution</DT
></DL
></DIV
><H1
><A
NAME="LBMRD"
></A
>lbmrd</H1
><DIV
CLASS="REFNAMEDIV"
><A
NAME="AEN3571"
></A
><H2
>Name</H2
>lbmrd&nbsp;--&nbsp;UMS Resolver Daemon, for unicast topic resolution</DIV
><DIV
CLASS="REFSYNOPSISDIV"
><A
NAME="AEN3574"
></A
><H2
>Synopsis</H2
><P
><TT
CLASS="COMMAND"
>lbmrd</TT
> [<CODE
CLASS="OPTION"
>-a</CODE
>] [<CODE
CLASS="OPTION"
>--activity</CODE
>] [<CODE
CLASS="OPTION"
>-d</CODE
>] [<CODE
CLASS="OPTION"
>--dump-dtd</CODE
>] [<CODE
CLASS="OPTION"
>-h</CODE
>] [<CODE
CLASS="OPTION"
>--help</CODE
>] [<CODE
CLASS="OPTION"
>-i</CODE
>] [<CODE
CLASS="OPTION"
>--interface</CODE
>] [<CODE
CLASS="OPTION"
>-L</CODE
>] [<CODE
CLASS="OPTION"
>--logfile</CODE
>] [<CODE
CLASS="OPTION"
>-p</CODE
>] [<CODE
CLASS="OPTION"
>--port</CODE
>] [<CODE
CLASS="OPTION"
>-t</CODE
>] [<CODE
CLASS="OPTION"
>--ttl</CODE
>] [<CODE
CLASS="OPTION"
>-v</CODE
>] [<CODE
CLASS="OPTION"
>--validate</CODE
>]  <TT
CLASS="REPLACEABLE"
><I
>config-file</I
></TT
> </P
></DIV
><DIV
CLASS="REFSECT1"
><A
NAME="AEN3611"
></A
><H2
>Description</H2
><P
>Resolver services for <B
CLASS="APPLICATION"
>UM</B
> messaging products are provided by
		<TT
CLASS="COMMAND"
>lbmrd</TT
>. 
		</P
><P
>		The <CODE
CLASS="OPTION"
>-i</CODE
> and <CODE
CLASS="OPTION"
>-p</CODE
> (or <CODE
CLASS="OPTION"
>--interface</CODE
>
		and <CODE
CLASS="OPTION"
>--port</CODE
>) options identify the network interface IP address and
		port that <TT
CLASS="COMMAND"
>lbmrd</TT
> opens to listen for unicast topic resolution traffic.
		The defaults are <TT
CLASS="LITERAL"
>INADDR_ANY</TT
> and <TT
CLASS="LITERAL"
>15380</TT
>, respectively.
		</P
><P
>		The <CODE
CLASS="OPTION"
>-a</CODE
> and <CODE
CLASS="OPTION"
>-t</CODE
> (or <CODE
CLASS="OPTION"
>--activity</CODE
> and
		<CODE
CLASS="OPTION"
>--ttl</CODE
>) options interact to detect and remove "dead" clients, i.e., UMS/UME
		client applications that are in the <TT
CLASS="COMMAND"
>lbmrd</TT
> active client list, but have
		stopped sending topic resolution queries, advertisements, or keepalives, usually due to
		early termination or looping. These are described in detail below.
		</P
><P
>		Option <CODE
CLASS="OPTION"
>-t</CODE
> describes the length of time (in seconds), 
		during which no messages have been received from a given client, that will cause that
		client to be marked "dead" and removed from the active client list. <B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> recommends a
		value at least 5 seconds longer than the longest network outage you wish to tolerate.
		</P
><P
>		Option <CODE
CLASS="OPTION"
>-a</CODE
> describes a repeating time interval (in 
		milliseconds) after which <TT
CLASS="COMMAND"
>lbmrd</TT
> checks for these "dead" clients.
		<B
CLASS="APPLICATION"
><SPAN
CLASS="TRADEMARK"
>Ultra Messaging</SPAN
></B
> recommends a value not larger than <CODE
CLASS="OPTION"
>-t * 1000</CODE
>.
		</P
><P
>		NOTE: Even clients that send no topic resolution advertisements or queries will still
		send keepalive messages to <TT
CLASS="COMMAND"
>lbmrd</TT
> every 5 seconds. This value is hard-coded
		and not configurable.
		</P
><P
>		The output will be written to a log file if either -L or --logfile is supplied.
		</P
><P
>		The DTD used to validate a configuration file will be dumped to standard output with
		the <CODE
CLASS="OPTION"
>-d</CODE
> or <CODE
CLASS="OPTION"
>--dump-dtd</CODE
> option. After dumping the DTD,
		<TT
CLASS="COMMAND"
>lbmrd</TT
> exits immediately.
		</P
><P
>		The configuration file will be validated against the DTD if either the <CODE
CLASS="OPTION"
>-v</CODE
> or
		<CODE
CLASS="OPTION"
>--validate</CODE
> options are given. After attempting validation,
		<TT
CLASS="COMMAND"
>lbmrd</TT
> exits immediately. The exit status will be 0 for a configuration
		file validated by the DTD and non-zero otherwise.
		</P
><P
>Command line help is available with <CODE
CLASS="OPTION"
>-h</CODE
> or <CODE
CLASS="OPTION"
>--help</CODE
>.
		</P
></DIV
><DIV
CLASS="REFSECT1"
><A
NAME="AEN3654"
></A
><H2
>Exit Status</H2
><P
>The exit status from <TT
CLASS="COMMAND"
>lbmrd</TT
> is 0 for
		success and some non-zero value for failure.
		</P
></DIV
></DIV
></DIV
><hr><p
align="center"
>Copyright (c) 2004 - 2014 Informatica Corporation. All rights reserved.</p
></BODY
></HTML
>
